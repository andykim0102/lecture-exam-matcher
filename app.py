import time
import streamlit as st
import google.generativeai as genai
import fitz  # PyMuPDF
from PIL import Image
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# ==========================================
# 0. íŽ˜ì´ì§€ ì„¤ì •
# ==========================================
st.set_page_config(page_title="Med-Study OS", layout="wide", page_icon="ðŸ©º")
st.caption("ðŸ“Œ ì‚¬ìš© íë¦„: ì¡±ë³´ í•™ìŠµ â†’ ê°•ì˜ íŽ˜ì´ì§€ ë¶„ì„ â†’ ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¶„ì„")

# ==========================================
# 1. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ==========================================
if "db" not in st.session_state:
    st.session_state.db = []

if "lecture_doc" not in st.session_state:
    st.session_state.lecture_doc = None

if "lecture_filename" not in st.session_state:
    st.session_state.lecture_filename = None

if "current_page" not in st.session_state:
    st.session_state.current_page = 0

if "text_models" not in st.session_state:
    st.session_state.text_models = []

if "best_text_model" not in st.session_state:
    st.session_state.best_text_model = None

if "api_key_ok" not in st.session_state:
    st.session_state.api_key_ok = False

# ==========================================
# 1.5. ì¡±ë³´ ê·¼ê±° íŒë‹¨ ìž„ê³„ê°’
# ==========================================
# ë°ëª¨ ì¶”ì²œ: 0.70~0.75 ì‚¬ì´. ë„ˆë¬´ ë†’ìœ¼ë©´ "ì—†ìŒ"ì´ ìžì£¼ ëœ¸.
JOKBO_THRESHOLD = 0.72

def has_jokbo_evidence(related: list[dict]) -> bool:
    """ê´€ë ¨ ì¡±ë³´ê°€ 'ìžˆë‹¤'ê³  íŒë‹¨í•  ìµœì†Œ ì¡°ê±´"""
    return bool(related) and related[0]["score"] >= JOKBO_THRESHOLD


# ==========================================
# 2. PDF/ìž„ë² ë”©/ê²€ìƒ‰ í•¨ìˆ˜
# ==========================================
def extract_text_from_pdf(file):
    """PDFë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (fitz ì‚¬ìš©)"""
    doc = fitz.open(stream=file.read(), filetype="pdf")
    pages = []
    for i, page in enumerate(doc):
        text = page.get_text() or ""
        if text.strip():
            pages.append({"page": i + 1, "text": text, "source": file.name})
    return pages


def get_embedding(text: str):
    """ìž„ë² ë”© ìƒì„± (ê°€ëŠ¥í•˜ë©´ text-embedding-004, ì•„ë‹ˆë©´ embedding-001)"""
    text = (text or "").strip()
    if not text:
        return []

    # ë°ëª¨ ì•ˆì •ì„±: ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ ì»·
    text = text[:12000]

    try:
        return genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="retrieval_document",
        )["embedding"]
    except Exception:
        try:
            return genai.embed_content(
                model="models/embedding-001",
                content=text,
                task_type="retrieval_document",
            )["embedding"]
        except Exception:
            return []


def find_relevant_jokbo(query_text: str, db: list[dict], top_k: int = 3):
    """ìœ ì‚¬ë„ ê²€ìƒ‰"""
    if not db:
        return []

    query_emb = get_embedding(query_text)
    if not query_emb:
        return []

    valid_items = [item for item in db if item.get("embedding")]
    if not valid_items:
        return []

    db_embs = [item["embedding"] for item in valid_items]
    sims = cosine_similarity([query_emb], db_embs)[0]
    top_idxs = np.argsort(sims)[::-1][:top_k]

    return [{"score": float(sims[i]), "content": valid_items[i]} for i in top_idxs]


# ==========================================
# 3. ëª¨ë¸ ìžë™ ì„ íƒ + fallback
# ==========================================
@st.cache_data(show_spinner=False)
def list_text_models(api_key: str):
    genai.configure(api_key=api_key)
    models = genai.list_models()
    out = []
    for m in models:
        methods = getattr(m, "supported_generation_methods", []) or []
        if "generateContent" in methods:
            out.append(m.name)  # ë³´í†µ "models/..." í˜•íƒœ
    return out


def pick_best_text_model(model_names: list[str]):
    if not model_names:
        return None
    flash = [m for m in model_names if "flash" in m.lower()]
    return flash[0] if flash else model_names[0]


def generate_with_fallback(prompt: str, model_names: list[str]):
    last_err = None
    for name in model_names:
        if not name:
            continue
        try:
            model = genai.GenerativeModel(name)
            res = model.generate_content(prompt)
            text = getattr(res, "text", None)
            if text:
                return text, name
            return str(res), name
        except Exception as e:
            last_err = e
            continue
    raise last_err


# ==========================================
# 4. ê³¼ëª© ì„ íƒ(ê¸°íƒ€ í¬í•¨) + í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
# ==========================================
def resolve_subject(selected: str, custom: str) -> str:
    """UIì—ì„œ ì„ íƒëœ ê³¼ëª©ì„ ìµœì¢… ê³¼ëª©ëª…ìœ¼ë¡œ í™•ì •"""
    selected = (selected or "").strip()
    if selected != "ê¸°íƒ€":
        return selected
    custom = (custom or "").strip()
    return custom if custom else "ê¸°íƒ€(ë¯¸ìž…ë ¥)"


def get_subject_templates():
    """í•´ë¶€/ìƒë¦¬/ì•½ë¦¬ ì „ìš© í…œí”Œë¦¿ + ê¸°íƒ€(ë²”ìš©)"""
    return {
        "í•´ë¶€í•™": {
            "focus": [
                "êµ¬ì¡° ì´ë¦„(í•œê¸€+ì˜ì–´), ìœ„ì¹˜ ê´€ê³„(ì¸ì ‘ êµ¬ì¡°/ì¸µ), ì§€ë°° ì‹ ê²½/í˜ˆê´€",
                "ì†ìƒ/ë³‘ë³€ ì‹œ ìž„ìƒ ì§•í›„(ê·¼ë ¥ì €í•˜/ê°ê°ì €í•˜/ë°˜ì‚¬ ë“±)",
                "ê·¸ë¦¼/í‘œì§€(landmark), í†µê³¼ êµ¬ì¡°, êµ¬ë©/ê´€(Foramen/Canal) ì¶œì œ í¬ì¸íŠ¸",
            ],
            "question_style": "êµ¬ì¡°-ê¸°ëŠ¥-ìž„ìƒ ì—°ê²°, ìœ„ì¹˜/ì§€ë°°/í†µê³¼ êµ¬ì¡°ë¥¼ í—·ê°ˆë¦¬ê²Œ ë‚´ëŠ” ê°ê´€ì‹/ë‹¨ë‹µí˜•",
        },
        "ìƒë¦¬í•™": {
            "focus": [
                "ê¸°ì „ íë¦„(Aâ†’Bâ†’C), ì¡°ì ˆ(í”¼ë“œë°±), í•­ìƒì„± ì˜ë¯¸",
                "ë³€ìˆ˜ ë³€í™” ë°©í–¥(ì¦ê°€/ê°ì†Œ), ê·¸ëž˜í”„/í‘œë¡œ ë‚˜ì˜¬ í¬ì¸íŠ¸",
                "ëŒ€í‘œ ì˜ˆì™¸/í—·ê°ˆë¦¬ëŠ” ì¼€ì´ìŠ¤(ìˆ˜ìš©ì²´, í˜¸ë¥´ëª¬, êµê°/ë¶€êµê° ë“±)",
            ],
            "question_style": "ê¸°ì „ ìˆœì„œÂ·ë³€ìˆ˜ ë³€í™”Â·ê·¸ëž˜í”„ í•´ì„Â·ì‹¤í—˜ ìƒí™© ì¶”ë¡ ",
        },
        "ì•½ë¦¬í•™": {
            "focus": [
                "ìž‘ìš©ê¸°ì „(MOA) â†’ íš¨ê³¼ â†’ ë¶€ìž‘ìš© â†’ ê¸ˆê¸°/ì£¼ì˜",
                "ê°™ì€ ê³„ì—´/ìœ ì‚¬ ê¸°ì „ ì•½ë¬¼ ë¹„êµ(ì°¨ì´ì ) + ëŒ€í‘œ ì•½ë¬¼ëª…",
                "ìž„ìƒ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜(ë¶€ìž‘ìš© íšŒí”¼/ëŒ€ì²´ì•½ ì„ íƒ/ìƒí˜¸ìž‘ìš©)",
            ],
            "question_style": "ê¸°ì „-ë¶€ìž‘ìš© ë§¤ì¹­, ê³„ì—´ ë¹„êµ, ìž„ìƒ ì¼€ì´ìŠ¤ì—ì„œ ì•½ ì„ íƒ ë¬¸ì œ",
        },
        "__GENERIC__": {
            "focus": [
                "í•µì‹¬ ê°œë…ì„ ì‹œí—˜ í‚¤ì›Œë“œ ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½",
                "ìžì£¼ ì¶œì œë˜ëŠ” í—·ê°ˆ í¬ì¸íŠ¸(ê°œë… êµ¬ë¶„/ì •ì˜/ë¹„êµ)",
                "ê°ê´€ì‹/ë‹¨ë‹µí˜•ìœ¼ë¡œ ë‚˜ì˜¬ ë§Œí•œ â€˜ì •í™•í•œ í‘œí˜„â€™ ê°•ì¡°",
            ],
            "question_style": "ì •ì˜Â·ë¹„êµÂ·ê¸°ì „/íë¦„Â·ì˜ˆì™¸/í•¨ì • í¬ì¸íŠ¸ ì¤‘ì‹¬ì˜ ì „í˜•ì  ì˜ëŒ€ ì‹œí—˜ ìŠ¤íƒ€ì¼",
        },
    }


def build_exam_prompt(subject: str, lecture_text: str, jokbo_ctx: str, mode: str):
    """
    âš ï¸ ì´ í•¨ìˆ˜ëŠ” 'ì¡±ë³´ ê·¼ê±°ê°€ ìžˆì„ ë•Œë§Œ' í˜¸ì¶œë˜ë„ë¡ TAB2/TAB3ì—ì„œ ë§‰ì•„ë‘ .
    mode:
      - "page": ê°•ì˜ íŽ˜ì´ì§€ ë¶„ì„
      - "live": ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¶„ì„
    """
    templates = get_subject_templates()
    t = templates.get(subject, templates["__GENERIC__"])

    # ê¸°íƒ€ ê³¼ëª©ì´ë©´ "ë²”ìš© ì˜ëŒ€ ê³¼ëª©" í”„ë ˆì´ë° ì¶”ê°€
    if subject not in ["í•´ë¶€í•™", "ìƒë¦¬í•™", "ì•½ë¦¬í•™"]:
        subject_note = (
            f"ê³¼ëª©ëª…: {subject}\n"
            "ë„ˆëŠ” ì´ ê³¼ëª©ì˜ ì¼ë°˜ì ì¸ ì˜ëŒ€ ì‹œí—˜ ì¶œì œ ê´€ì (ì •ì˜/ë¹„êµ/ê¸°ì „/í•¨ì • í¬ì¸íŠ¸)ì„ ì ìš©í•´ ë¶„ì„í•˜ë¼.\n"
            "ê³¼ëª©ì´ ì •í™•ížˆ ë¬´ì—‡ì´ë“ , 'ì˜ëŒ€ ì‹œí—˜ ëŒ€ë¹„'ë¼ëŠ” ëª©ì ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ë¼."
        )
    else:
        subject_note = f"ê³¼ëª©ëª…: {subject}"

    base_rules = f"""
ë„ˆëŠ” ì˜ëŒ€ ì‹œí—˜ ì¶œì œìžì´ìž ì±„ì ìž(ê·¸ë¦¬ê³  ì¡°êµ)ë‹¤.
ì•„ëž˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€ì¼œë¼.

ì¤‘ìš” ì›ì¹™:
- ì•„ëž˜ [ê´€ë ¨ ì¡±ë³´ ë°œì·Œ]ì— ê·¼ê±°í•´ì„œë§Œ ë‹µí•˜ë¼.
- ìƒˆë¡œìš´ í•´ì„/ì¶”ì¸¡ì€ í•˜ì§€ ë§ˆë¼.

[1ï¸âƒ£ ì¡±ë³´ì—ì„œ ë‚˜ì˜¨ í˜•íƒœ]
- ì •ì˜/ê¸°ì „/ë¹„êµ/ë¬¸ì œìœ í˜• ì¤‘ ì–´ë–¤ í˜•íƒœì˜€ëŠ”ì§€ ëª…ì‹œ
- í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ

[2ï¸âƒ£ ê°•ì˜ ë‚´ìš©ê³¼ì˜ ì—°ê²°]
- ê°•ì˜ ë‚´ìš©ì´ ì¡±ë³´ ì–´ë””(p.ë²ˆí˜¸)ì— í•´ë‹¹í•˜ëŠ”ì§€ ì„¤ëª…
- ì¡±ë³´ ë°œì·Œì—ì„œ ê·¼ê±° ë¬¸ìž¥/í‚¤ì›Œë“œ 2ê°œ ì´ìƒ ì§§ê²Œ ì¸ìš©

[3ï¸âƒ£ ì‹œí—˜ ë³€í˜• ê°€ëŠ¥ì„±]
- ì¡±ë³´ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ ë³€í˜•í• ì§€ 2ê°€ì§€

[4ï¸âƒ£ ì˜ˆìƒ ë¬¸ì œ]
- ê°ê´€ì‹ 1ë¬¸í•­(ì¡±ë³´ ìŠ¤íƒ€ì¼ ìœ ì§€)
- ì •ë‹µ + í•´ì„¤(ì˜¤ë‹µ ì´ìœ  í¬í•¨)

{subject_note}

ê³¼ëª© ê´€ì (í•„ìˆ˜ í¬í•¨):
- {t["focus"][0]}
- {t["focus"][1]}
- {t["focus"][2]}
""".strip()

    if mode == "page":
        body = f"""
---
[ê°•ì˜ íŽ˜ì´ì§€ í…ìŠ¤íŠ¸]
{lecture_text}

[ê´€ë ¨ ì¡±ë³´ ë°œì·Œ]
{jokbo_ctx}
""".strip()
    else:
        body = f"""
---
[ì‹¤ì‹œê°„ ìž…ë ¥ í…ìŠ¤íŠ¸]
{lecture_text}

[ê´€ë ¨ ì¡±ë³´ ë°œì·Œ]
{jokbo_ctx}
""".strip()

    return base_rules + "\n" + body


# ==========================================
# 5. ì‘ë‹µ íŒŒì„œ + ì„¹ì…˜ ë Œë”ëŸ¬ (ì„œë¹„ìŠ¤ UIí™”)
# ==========================================
def parse_ai_sections(text: str) -> dict:
    keys = ["ì¡±ë³´ì—ì„œ ë‚˜ì˜¨ í˜•íƒœ", "ê°•ì˜ ë‚´ìš©ê³¼ì˜ ì—°ê²°", "ì‹œí—˜ ë³€í˜• ê°€ëŠ¥ì„±", "ì˜ˆìƒ ë¬¸ì œ"]
    sections = {k: "" for k in keys}
    current = None

    for raw in (text or "").splitlines():
        line = raw.strip()

        if "ì¡±ë³´ì—ì„œ" in line and ("í˜•íƒœ" in line or "ë‚˜ì˜¨" in line):
            current = "ì¡±ë³´ì—ì„œ ë‚˜ì˜¨ í˜•íƒœ"
            continue
        if "ê°•ì˜" in line and ("ì—°ê²°" in line or "í•´ë‹¹" in line):
            current = "ê°•ì˜ ë‚´ìš©ê³¼ì˜ ì—°ê²°"
            continue
        if "ë³€í˜•" in line:
            current = "ì‹œí—˜ ë³€í˜• ê°€ëŠ¥ì„±"
            continue
        if "ì˜ˆìƒ" in line and "ë¬¸ì œ" in line:
            current = "ì˜ˆìƒ ë¬¸ì œ"
            continue

        if current:
            sections[current] += raw + "\n"

    return sections


def render_sections(sections: dict):
    st.markdown("### ðŸ§¾ ì¡±ë³´ ê¸°ë°˜ ë¶„ì„ ê²°ê³¼")

    st.subheader("1) ì¡±ë³´ì—ì„œ ë‚˜ì˜¨ í˜•íƒœ")
    st.markdown(sections.get("ì¡±ë³´ì—ì„œ ë‚˜ì˜¨ í˜•íƒœ", "").strip() or "_(ì—†ìŒ)_")

    st.subheader("2) ê°•ì˜ ë‚´ìš©ê³¼ì˜ ì—°ê²°")
    st.markdown(sections.get("ê°•ì˜ ë‚´ìš©ê³¼ì˜ ì—°ê²°", "").strip() or "_(ì—†ìŒ)_")

    st.subheader("3) ì‹œí—˜ ë³€í˜• ê°€ëŠ¥ì„±")
    st.markdown(sections.get("ì‹œí—˜ ë³€í˜• ê°€ëŠ¥ì„±", "").strip() or "_(ì—†ìŒ)_")

    st.subheader("4) ì˜ˆìƒ ë¬¸ì œ")
    st.markdown(sections.get("ì˜ˆìƒ ë¬¸ì œ", "").strip() or "_(ì—†ìŒ)_")


# ==========================================
# 6. ì‚¬ì´ë“œë°” (ìƒíƒœ / ì„¤ì •)
# ==========================================
with st.sidebar:
    st.title("ðŸ©º Med-Study ìƒíƒœ")

    api_key = st.text_input("Gemini API Key", type="password")

    if api_key:
        try:
            genai.configure(api_key=api_key)
            available_models = list_text_models(api_key)

            if not available_models:
                st.session_state.api_key_ok = False
                st.error("generateContent ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.session_state.api_key_ok = True
                st.session_state.text_models = available_models
                st.session_state.best_text_model = pick_best_text_model(available_models)
                st.success("AI ì—°ê²° ì™„ë£Œ")
                st.caption(f"ì‚¬ìš© ëª¨ë¸(ìžë™): {st.session_state.best_text_model}")

        except Exception as e:
            st.session_state.api_key_ok = False
            st.error(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    st.divider()
    st.caption(f"ðŸ“Š í•™ìŠµëœ ì¡±ë³´ íŽ˜ì´ì§€ ìˆ˜: **{len(st.session_state.db)}**")

    if st.button("ì¡±ë³´ DB ì´ˆê¸°í™”"):
        st.session_state.db = []
        st.rerun()


# ==========================================
# 7. ë©”ì¸ UI
# ==========================================
tab1, tab2, tab3 = st.tabs(
    ["ðŸ“‚ ì¡±ë³´ í•™ìŠµ", "ðŸ“– ê°•ì˜ ê³µë¶€", "âŒ¨ï¸ ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¶„ì„"]
)

# ==================================================
# TAB 1 â€” ì¡±ë³´ í•™ìŠµ
# ==================================================
with tab1:
    st.header("ðŸ“‚ ì¡±ë³´ í•™ìŠµ")
    st.info("ê³¼ê±° ì‹œí—˜ ì¡±ë³´ë¥¼ í•™ìŠµì‹œì¼œ, ê°•ì˜ ë‚´ìš©ê³¼ ì‹œí—˜ ì¶œì œ í¬ì¸íŠ¸ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.")

    files = st.file_uploader(
        "ì¡±ë³´ PDF ì—…ë¡œë“œ", type="pdf", accept_multiple_files=True
    )

    col_a, col_b = st.columns([1, 2])
    with col_a:
        max_pages = st.number_input(
            "íŒŒì¼ë‹¹ ìµœëŒ€ í•™ìŠµ íŽ˜ì´ì§€(ë°ëª¨ìš©)",
            min_value=1, max_value=200, value=30, step=1
        )
    with col_b:
        st.caption("ë°ëª¨ ì•ˆì •ì„±ì„ ìœ„í•´ íŒŒì¼ë‹¹ í•™ìŠµ íŽ˜ì´ì§€ë¥¼ ì œí•œí•˜ëŠ” ê²ƒì„ ê¶Œìž¥í•©ë‹ˆë‹¤.")

    if st.button("ðŸ“š ì‹œí—˜ ëŒ€ë¹„ DB êµ¬ì¶• ì‹œìž‘"):
        if not api_key or not st.session_state.api_key_ok:
            st.error("ì‚¬ì´ë“œë°”ì—ì„œ ìœ íš¨í•œ API Keyë¥¼ ë¨¼ì € ì„¤ì •í•˜ì„¸ìš”.")
            st.stop()
        if not files:
            st.warning("ì¡±ë³´ PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            st.stop()

        bar = st.progress(0)
        status = st.empty()
        new_db = []
        total_files = len(files)

        for i, f in enumerate(files):
            status.text(f"ðŸ“– íŒŒì¼ ì²˜ë¦¬ ì¤‘: {f.name}")
            pages = extract_text_from_pdf(f)[: int(max_pages)]

            for j, p in enumerate(pages):
                status.text(
                    f"ðŸ§  DB êµ¬ì¶• ì¤‘: {f.name} ({j+1}/{len(pages)} íŽ˜ì´ì§€)"
                )
                emb = get_embedding(p["text"])
                if emb:
                    p["embedding"] = emb
                    new_db.append(p)
                time.sleep(0.8)  # 429 ì™„í™”

            bar.progress((i + 1) / total_files)

        st.session_state.db.extend(new_db)
        status.text("âœ… í•™ìŠµ ì™„ë£Œ")
        st.success(f"ì´ {len(new_db)} íŽ˜ì´ì§€ í•™ìŠµ ì™„ë£Œ")
        st.info("ðŸ‘‰ ë‹¤ìŒ: **ê°•ì˜ ê³µë¶€** íƒ­ì—ì„œ ê°•ì˜ PDFë¥¼ ì—´ê³  ë¶„ì„í•˜ì„¸ìš”.")


# ==================================================
# TAB 2 â€” ê°•ì˜ ê³µë¶€ (ì¡±ë³´ ê·¼ê±° â†’ AI)
# ==================================================
with tab2:
    st.header("ðŸ“– ê°•ì˜ ê³µë¶€")
    st.info("ê°•ì˜ íŽ˜ì´ì§€ ë‚´ìš©ì´ ì¡±ë³´ì—ì„œ ì–´ë–»ê²Œ ë‚˜ì™”ëŠ”ì§€ë§Œ í™•ì¸í•©ë‹ˆë‹¤.")

    # ê³¼ëª© ì„ íƒ + ê¸°íƒ€ ìž…ë ¥
    c1, c2 = st.columns([1, 2])
    with c1:
        subject_choice = st.selectbox(
            "ê³¼ëª©", ["í•´ë¶€í•™", "ìƒë¦¬í•™", "ì•½ë¦¬í•™", "ê¸°íƒ€"], index=1
        )
    with c2:
        custom_subject = st.text_input(
            "ê¸°íƒ€ ê³¼ëª©ëª…", disabled=(subject_choice != "ê¸°íƒ€")
        )

    subject_final = resolve_subject(subject_choice, custom_subject)
    st.caption(f"í˜„ìž¬ ê³¼ëª©: **{subject_final}**")

    lec_file = st.file_uploader("ê°•ì˜ë¡ PDF", type="pdf", key="lec")

    if lec_file:
        if (
            st.session_state.lecture_doc is None
            or st.session_state.lecture_filename != lec_file.name
        ):
            st.session_state.lecture_doc = fitz.open(
                stream=lec_file.read(), filetype="pdf"
            )
            st.session_state.lecture_filename = lec_file.name
            st.session_state.current_page = 0

        doc = st.session_state.lecture_doc
        col_view, col_ai = st.columns([6, 4])

        # ---------- PDF Viewer ----------
        with col_view:
            b1, b2, b3 = st.columns([1, 2, 1])

            if b1.button("â—€"):
                if st.session_state.current_page > 0:
                    st.session_state.current_page -= 1

            b2.markdown(
                f"<center>{st.session_state.current_page+1}/{len(doc)}</center>",
                unsafe_allow_html=True
            )

            if b3.button("â–¶"):
                if st.session_state.current_page < len(doc) - 1:
                    st.session_state.current_page += 1

            page = doc.load_page(st.session_state.current_page)
            pix = page.get_pixmap(dpi=150)
            st.image(
                Image.frombytes("RGB", [pix.width, pix.height], pix.samples),
                use_container_width=True
            )

            page_text = (page.get_text() or "").strip()
            if not page_text:
                st.warning("ì´ íŽ˜ì´ì§€ì—ëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # ---------- AI Analyzer ----------
        with col_ai:
            st.subheader("ðŸ”Ž ì¡±ë³´ ê·¼ê±°")

            if st.button("ì´ íŽ˜ì´ì§€ ë¶„ì„"):
                if not st.session_state.db:
                    st.error("ì¡±ë³´ DBê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()
                if not page_text:
                    st.error("ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()

                related = find_relevant_jokbo(
                    page_text, st.session_state.db, top_k=3
                )

                # âœ… ì¡±ë³´ ê·¼ê±° ì—†ìœ¼ë©´ AI í˜¸ì¶œ ìŠ¤í‚µ
                if not has_jokbo_evidence(related):
                    st.warning("ðŸ“Œ ê´€ë ¨ ì¡±ë³´ ê·¼ê±°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (AI ë¶„ì„ ìƒëžµ)")
                    st.stop()

                # 1) ì¡±ë³´ ê·¼ê±° ë¨¼ì € í‘œì‹œ
                for i, r in enumerate(related):
                    with st.expander(
                        f"ì¡±ë³´ ê·¼ê±° #{i+1} (ìœ ì‚¬ë„ {r['score']:.3f})"
                    ):
                        st.write(f"íŽ˜ì´ì§€ {r['content']['page']}")
                        st.write(r["content"]["text"])

                jokbo_ctx = "\n".join(
                    f"- (p{r['content']['page']}) {r['content']['text'][:300]}"
                    for r in related
                )

                prompt = build_exam_prompt(
                    subject=subject_final,
                    lecture_text=page_text,
                    jokbo_ctx=jokbo_ctx,
                    mode="page"
                )

                models = st.session_state.text_models or []
                fallback = models + ["models/gemini-1.5-flash-latest"]

                with st.spinner("ì¡±ë³´ ê¸°ë°˜ ë¶„ì„ ì¤‘..."):
                    result, used = generate_with_fallback(prompt, fallback)
                    st.caption(f"ì‚¬ìš© ëª¨ë¸: {used}")
                    sections = parse_ai_sections(result)
                    render_sections(sections)


# ==================================================
# TAB 3 â€” ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¶„ì„ (ì¡±ë³´ ê·¼ê±° ìžˆì„ ë•Œë§Œ)
# ==================================================
with tab3:
    st.header("âŒ¨ï¸ ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¶„ì„")
    st.info("ì¡±ë³´ì— ê·¼ê±°ê°€ ìžˆì„ ë•Œë§Œ ì‹œí—˜ í¬ì¸íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

    c1, c2 = st.columns([1, 2])
    with c1:
        subject_choice_live = st.selectbox(
            "ê³¼ëª©", ["í•´ë¶€í•™", "ìƒë¦¬í•™", "ì•½ë¦¬í•™", "ê¸°íƒ€"], index=1
        )
    with c2:
        custom_subject_live = st.text_input(
            "ê¸°íƒ€ ê³¼ëª©ëª…", disabled=(subject_choice_live != "ê¸°íƒ€")
        )

    subject_final_live = resolve_subject(
        subject_choice_live, custom_subject_live
    )
    st.caption(f"í˜„ìž¬ ê³¼ëª©: **{subject_final_live}**")

    user_text = st.text_area(
        "ê°•ì˜ ì¤‘ ì¤‘ìš”í•œ ë¬¸ìž¥ì„ ê·¸ëŒ€ë¡œ ìž…ë ¥",
        height=140,
        placeholder="ì˜ˆ) ì´ ë‹¨ê³„ëŠ” ì‹œí—˜ì— ìžì£¼ ë‚˜ì˜¤ëŠ” í¬ì¸íŠ¸ë‹¤."
    )

    if st.button("ì¡±ë³´ ì—°ê²° í™•ì¸"):
        if not st.session_state.db:
            st.error("ì¡±ë³´ DBê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        query = (user_text or "").strip()
        if not query:
            st.error("í…ìŠ¤íŠ¸ë¥¼ ìž…ë ¥í•˜ì„¸ìš”.")
            st.stop()

        related = find_relevant_jokbo(
            query, st.session_state.db, top_k=3
        )

        # âœ… ì¡±ë³´ ê·¼ê±° ì—†ìœ¼ë©´ AI í˜¸ì¶œ ìŠ¤í‚µ
        if not has_jokbo_evidence(related):
            st.warning("ðŸ“Œ ê´€ë ¨ ì¡±ë³´ ê·¼ê±°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (AI ë¶„ì„ ìƒëžµ)")
            st.stop()

        for i, r in enumerate(related):
            with st.expander(
                f"ì¡±ë³´ ê·¼ê±° #{i+1} (ìœ ì‚¬ë„ {r['score']:.3f})"
            ):
                st.write(f"íŽ˜ì´ì§€ {r['content']['page']}")
                st.write(r["content"]["text"])

        jokbo_ctx = "\n".join(
            f"- (p{r['content']['page']}) {r['content']['text'][:300]}"
            for r in related
        )

        prompt = build_exam_prompt(
            subject=subject_final_live,
            lecture_text=query,
            jokbo_ctx=jokbo_ctx,
            mode="live"
        )

        models = st.session_state.text_models or []
        fallback = models + ["models/gemini-1.5-flash-latest"]

        with st.spinner("ì¡±ë³´ ê¸°ë°˜ ë¶„ì„ ì¤‘..."):
            result, used = generate_with_fallback(prompt, fallback)
            st.caption(f"ì‚¬ìš© ëª¨ë¸: {used}")
            sections = parse_ai_sections(result)
            render_sections(sections)
