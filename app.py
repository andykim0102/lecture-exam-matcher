import os
import re
import sqlite3
import joblib
import pandas as pd
import streamlit as st
import speech_recognition as sr
from pypdf import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# =========================
# 1. ì´ˆê¸° ì„¤ì • ë° DB ì—°ê²°
# =========================
st.set_page_config(page_title="Med-Study AI Assistant", layout="wide")
user_id = st.sidebar.text_input("User ID", "med_student_01")
DATA_DIR = f"data/{user_id}"
os.makedirs(DATA_DIR, exist_ok=True)

conn = sqlite3.connect(os.path.join(DATA_DIR, "med_study.db"))
conn.execute("CREATE TABLE IF NOT EXISTS exam_db (id INTEGER PRIMARY KEY, year TEXT, text TEXT)")
conn.commit()

# ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ (ë°ì´í„° íë¦„ ìœ ì§€)
if 'pre_analysis' not in st.session_state: st.session_state.pre_analysis = []
if 'is_listening' not in st.session_state: st.session_state.is_listening = False

# =========================
# 2. í•µì‹¬ ë¡œì§ (PDF ë¶„ì„ ë° ê²€ìƒ‰)
# =========================
def get_pdf_text(file):
    reader = PdfReader(file)
    return [page.extract_text() for page in reader.pages]

def build_exam_index():
    rows = conn.execute("SELECT id, text FROM exam_db").fetchall()
    if not rows: return None
    texts = [r[1] for r in rows]
    vectorizer = TfidfVectorizer(ngram_range=(1, 2))
    matrix = vectorizer.fit_transform(texts)
    return vectorizer, matrix, [r[0] for r in rows]

# =========================
# 3. UI êµ¬ì„± (ìˆ˜ì—… ì „ -> ìˆ˜ì—… ì¤‘)
# =========================
st.title("ğŸ©º ìŠ¤ë§ˆíŠ¸ ê°•ì˜ë¡-ì¡±ë³´ ë§¤ì¹­ ë¹„ì„œ")

tab1, tab2 = st.tabs(["ğŸ“… ìˆ˜ì—… ì „: ì¡±ë³´ ë§¤ì¹­ ë° ì‚¬ì „ ì •ë¦¬", "ğŸ¤ ìˆ˜ì—… ì¤‘: ì‹¤ì‹œê°„ ìŒì„± ì–´ì‹œìŠ¤í„´íŠ¸"])

# --- [Step 1: ìˆ˜ì—… ì „ ì‚¬ì „ ë¶„ì„] ---
with tab1:
    st.header("ì˜¤ëŠ˜ ìˆ˜ì—…í•  íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”")
    exam_files = st.file_uploader("ë¨¼ì € ë³´ê´€ ì¤‘ì¸ 'ì¡±ë³´' PDFë“¤ì„ ë“±ë¡í•˜ì„¸ìš” (ìµœì´ˆ 1íšŒ)", type="pdf", accept_multiple_files=True, key="exams")
    
    if st.button("ì¡±ë³´ DB ì—…ë°ì´íŠ¸"):
        for f in exam_files:
            texts = get_pdf_text(f)
            conn.executemany("INSERT INTO exam_db (year, text) VALUES (?, ?)", [("2024", t) for t in texts if t])
        conn.commit()
        st.success("ì¡±ë³´ ë°ì´í„°ë² ì´ìŠ¤ê°€ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.")

    st.divider()
    lecture_file = st.file_uploader("ì˜¤ëŠ˜ ìˆ˜ì—…ìš© 'ê°•ì˜ë¡' PDF ì—…ë¡œë“œ", type="pdf", key="lecture")
    
    if lecture_file and st.button("ìˆ˜ì—… ì „ ìë™ ë‹¨ê¶Œí™” ë¶„ì„ ì‹œì‘"):
        with st.spinner("ê°•ì˜ë¡ì˜ ê° í˜ì´ì§€ì™€ ì¡±ë³´ë¥¼ ëŒ€ì¡° ì¤‘..."):
            lecture_pages = get_pdf_text(lecture_file)
            vec, mat, pids = build_exam_index()
            
            analysis_results = []
            for i, page_text in enumerate(lecture_pages):
                if not page_text: continue
                qv = vec.transform([page_text])
                sims = cosine_similarity(qv, mat).flatten()
                if sims.max() > 0.3: # ìœ ì‚¬ë„ 0.3 ì´ìƒë§Œ ì¶”ì¶œ
                    best_idx = sims.argmax()
                    exam_row = conn.execute("SELECT text FROM exam_db WHERE id=?", (pids[best_idx],)).fetchone()
                    analysis_results.append({"page": i+1, "score": sims.max(), "exam_text": exam_row[0]})
            
            st.session_state.pre_analysis = analysis_results
            st.success(f"ë¶„ì„ ì™„ë£Œ! ì´ {len(analysis_results)}ê°œì˜ í˜ì´ì§€ê°€ ì¡±ë³´ì™€ ë§¤ì¹­ë©ë‹ˆë‹¤.")

    # ë¶„ì„ ê²°ê³¼ ì‹œê°í™”
    if st.session_state.pre_analysis:
        st.subheader("ğŸ“Š ì˜¤ëŠ˜ ê°•ì˜ ê¸°ì¶œ í¬ì¸íŠ¸ ë¦¬í¬íŠ¸")
        for res in st.session_state.pre_analysis:
            with st.expander(f"ğŸ“„ ê°•ì˜ë¡ {res['page']}í˜ì´ì§€ (ê¸°ì¶œ ìœ ì‚¬ë„: {int(res['score']*100)}%)"):
                st.info(f"**ê´€ë ¨ ì¡±ë³´ ì§€ë¬¸:** {res['exam_text'][:200]}...")

# --- [Step 2: ìˆ˜ì—… ì¤‘ ì‹¤ì‹œê°„ ìŒì„± ë§¤ì¹­] ---
with tab2:
    st.header("êµìˆ˜ë‹˜ ì„¤ëª… ì‹¤ì‹œê°„ íŠ¸ë˜í‚¹")
    st.write("êµìˆ˜ë‹˜ì˜ ì„¤ëª…ì„ ë“¤ìœ¼ë©° ê´€ë ¨ ì¡±ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— ë„ì›ë‹ˆë‹¤.")
    
    col_ctrl, col_view = st.columns([1, 2])
    
    with col_ctrl:
        if st.button("ğŸ¤ ìˆ˜ì—… ì‹œì‘ (ìŒì„± ì¸ì‹)"):
            r = sr.Recognizer()
            with sr.Microphone() as source:
                st.write("êµìˆ˜ë‹˜ ìŒì„± ì²­ì·¨ ì¤‘...")
                try:
                    audio = r.listen(source, timeout=5, phrase_time_limit=10)
                    text = r.recognize_google(audio, language='ko-KR')
                    st.session_state.live_text = text
                    st.success(f"ì¸ì‹ëœ ë‚´ìš©: {text}")
                except:
                    st.error("ìŒì„±ì´ ë“¤ë¦¬ì§€ ì•Šê±°ë‚˜ ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    with col_view:
        if 'live_text' in st.session_state:
            st.subheader("ğŸš¨ ì‹¤ì‹œê°„ ë§¤ì¹­ ì•Œë¦¼")
            # ì‚¬ì „ ë¶„ì„ëœ ê²°ê³¼ ì¤‘ì—ì„œ ì‹¤ì‹œê°„ ìŒì„± í‚¤ì›Œë“œì™€ ë§¤ì¹­ë˜ëŠ” í˜ì´ì§€ íƒìƒ‰
            matched = [res for res in st.session_state.pre_analysis if any(word in res['exam_text'] for word in st.session_state.live_text.split())]
            
            if matched:
                for m in matched:
                    st.warning(f"**ì§€ê¸ˆ ì„¤ëª…í•˜ì‹œëŠ” ë‚´ìš©ì´ ê°•ì˜ë¡ {m['page']}p ì¡±ë³´ì™€ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤!**")
                    st.write(f"ê¸°ì¶œ ë‚´ìš© ì¬í™•ì¸: {m['exam_text'][:150]}...")
            else:
                st.write("ì‹¤ì‹œê°„ ì¼ì¹˜ ë¬¸í•­ ì—†ìŒ")
