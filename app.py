import time
import streamlit as st
import google.generativeai as genai
import fitz  # PyMuPDF
from PIL import Image
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# ==========================================
# 0. í˜ì´ì§€ ì„¤ì •
# ==========================================
st.set_page_config(
    page_title="Med-Study OS",
    layout="wide",
    page_icon="ğŸ©º"
)

st.caption("ğŸ“Œ ì‚¬ìš© íë¦„: ì¡±ë³´ í•™ìŠµ â†’ ê°•ì˜ í˜ì´ì§€ ë¶„ì„ â†’ ì‹¤ì‹œê°„ ì‹œí—˜ í¬ì¸íŠ¸ ì •ë¦¬")

# ==========================================
# 1. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ==========================================
if "db" not in st.session_state:
    st.session_state.db = []

if "lecture_doc" not in st.session_state:
    st.session_state.lecture_doc = None

if "lecture_filename" not in st.session_state:
    st.session_state.lecture_filename = None

if "current_page" not in st.session_state:
    st.session_state.current_page = 0

if "text_models" not in st.session_state:
    st.session_state.text_models = []

if "best_text_model" not in st.session_state:
    st.session_state.best_text_model = None

if "api_key_ok" not in st.session_state:
    st.session_state.api_key_ok = False


# ==========================================
# 2. í•µì‹¬ ë¡œì§ í•¨ìˆ˜
# ==========================================
def extract_text_from_pdf(file):
    doc = fitz.open(stream=file.read(), filetype="pdf")
    pages = []
    for i, page in enumerate(doc):
        text = page.get_text() or ""
        if text.strip():
            pages.append({
                "page": i + 1,
                "text": text,
                "source": file.name
            })
    return pages


def get_embedding(text):
    text = (text or "").strip()[:12000]
    if not text:
        return []

    try:
        return genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="retrieval_document"
        )["embedding"]
    except Exception:
        try:
            return genai.embed_content(
                model="models/embedding-001",
                content=text,
                task_type="retrieval_document"
            )["embedding"]
        except Exception:
            return []


def find_relevant_jokbo(query, db, top_k=3):
    if not db:
        return []

    query_emb = get_embedding(query)
    if not query_emb:
        return []

    valid = [d for d in db if d.get("embedding")]
    if not valid:
        return []

    embs = [d["embedding"] for d in valid]
    sims = cosine_similarity([query_emb], embs)[0]
    idxs = np.argsort(sims)[::-1][:top_k]

    return [
        {"score": float(sims[i]), "content": valid[i]}
        for i in idxs
    ]


@st.cache_data(show_spinner=False)
def list_text_models(api_key):
    genai.configure(api_key=api_key)
    models = genai.list_models()
    return [
        m.name for m in models
        if "generateContent" in (m.supported_generation_methods or [])
    ]


def pick_best_text_model(names):
    flash = [n for n in names if "flash" in n.lower()]
    return flash[0] if flash else (names[0] if names else None)


def generate_with_fallback(prompt, model_names):
    last_err = None
    for name in model_names:
        try:
            model = genai.GenerativeModel(name)
            res = model.generate_content(prompt)
            return res.text, name
        except Exception as e:
            last_err = e
    raise last_err


# ==========================================
# 3. ì‚¬ì´ë“œë°” (ì‹œìŠ¤í…œ ìƒíƒœ)
# ==========================================
with st.sidebar:
    st.title("ğŸ©º Med-Study ìƒíƒœ")

    api_key = st.text_input("Gemini API Key", type="password")

    if api_key:
        try:
            genai.configure(api_key=api_key)
            models = list_text_models(api_key)
            if not models:
                st.session_state.api_key_ok = False
                st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì—†ìŒ")
            else:
                st.session_state.api_key_ok = True
                st.session_state.text_models = models
                st.session_state.best_text_model = pick_best_text_model(models)
                st.success("AI ì—°ê²° ì™„ë£Œ")
        except Exception as e:
            st.session_state.api_key_ok = False
            st.error(f"ì—°ê²° ì‹¤íŒ¨: {e}")

    st.divider()
    st.caption(
        f"""
ğŸ“Š ì‹œìŠ¤í…œ í˜„í™©  
- ì¡±ë³´ í˜ì´ì§€ ìˆ˜: {len(st.session_state.db)}  
- ì‚¬ìš© ëª¨ë¸: {st.session_state.best_text_model or "ë¯¸ì„ íƒ"}
"""
    )

    if st.button("ì¡±ë³´ DB ì´ˆê¸°í™”"):
        st.session_state.db = []
        st.rerun()


# ==========================================
# 4. ë©”ì¸ UI
# ==========================================
tab1, tab2, tab3 = st.tabs([
    "ğŸ“‚ ì¡±ë³´ í•™ìŠµ",
    "ğŸ“– ê°•ì˜ ê³µë¶€",
    "âŒ¨ï¸ ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¶„ì„"
])


# ==================================================
# TAB 1 â€” ì¡±ë³´ í•™ìŠµ
# ==================================================
with tab1:
    st.header("ğŸ“‚ ì¡±ë³´ í•™ìŠµ")
    st.info("ê³¼ê±° ì‹œí—˜ ì¡±ë³´ë¥¼ í•™ìŠµì‹œì¼œ, ê°•ì˜ ë‚´ìš©ê³¼ ìë™ ì—°ê²°í•©ë‹ˆë‹¤.")

    files = st.file_uploader(
        "ì¡±ë³´ PDF ì—…ë¡œë“œ",
        type="pdf",
        accept_multiple_files=True
    )

    max_pages = st.number_input(
        "íŒŒì¼ë‹¹ ìµœëŒ€ í•™ìŠµ í˜ì´ì§€ (ë°ëª¨ìš©)",
        min_value=1,
        max_value=200,
        value=30
    )

    if st.button("ğŸ“š ì‹œí—˜ ëŒ€ë¹„ DB êµ¬ì¶• ì‹œì‘"):
        if not api_key:
            st.error("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            st.stop()

        progress = st.progress(0)
        status = st.empty()
        new_db = []

        for i, f in enumerate(files or []):
            pages = extract_text_from_pdf(f)[:max_pages]

            for j, p in enumerate(pages):
                status.text(
                    f"ğŸ§  ì‹œí—˜ ëŒ€ë¹„ DB êµ¬ì¶• ì¤‘: {f.name} "
                    f"({j+1}/{len(pages)} í˜ì´ì§€)"
                )
                emb = get_embedding(p["text"])
                if emb:
                    p["embedding"] = emb
                    new_db.append(p)
                time.sleep(0.8)

            progress.progress((i + 1) / len(files))

        st.session_state.db.extend(new_db)
        st.success(f"âœ… ì´ {len(new_db)} í˜ì´ì§€ í•™ìŠµ ì™„ë£Œ")

        st.info(
            "ë‹¤ìŒ ë‹¨ê³„ ğŸ‘‰ **ê°•ì˜ ê³µë¶€ íƒ­**ì—ì„œ ê°•ì˜ í˜ì´ì§€ë¥¼ ì—´ê³  ë¶„ì„í•˜ì„¸ìš”."
        )
# ==================================================
# TAB 2 â€” ê°•ì˜ ê³µë¶€ (í˜ì´ì§€ ë¶„ì„)
# ==================================================
with tab2:
    st.header("ğŸ“– ê°•ì˜ ê³µë¶€")
    st.info("ê°•ì˜ í˜ì´ì§€ë¥¼ í•œ ì¥ì”© ë³´ë©´ì„œ, ì‹œí—˜ê³¼ì˜ ì—°ê²° í¬ì¸íŠ¸ë¥¼ ì¦‰ì‹œ ë¶„ì„í•©ë‹ˆë‹¤.")

    lec_file = st.file_uploader("ê°•ì˜ë¡ PDF ì—…ë¡œë“œ", type="pdf", key="lecture")

    if lec_file:
        # ìƒˆ íŒŒì¼ì´ë©´ ë‹¤ì‹œ ë¡œë“œ
        if (
            st.session_state.lecture_doc is None
            or st.session_state.lecture_filename != lec_file.name
        ):
            st.session_state.lecture_doc = fitz.open(
                stream=lec_file.read(),
                filetype="pdf"
            )
            st.session_state.lecture_filename = lec_file.name
            st.session_state.current_page = 0

        doc = st.session_state.lecture_doc
        col_view, col_ai = st.columns([6, 4])

        # ---------- ì™¼ìª½: PDF ë·°ì–´ ----------
        with col_view:
            nav1, nav2, nav3 = st.columns([1, 2, 1])

            if nav1.button("â—€ ì´ì „"):
                if st.session_state.current_page > 0:
                    st.session_state.current_page -= 1

            nav2.markdown(
                f"<center>{st.session_state.current_page + 1} / {len(doc)}</center>",
                unsafe_allow_html=True
            )

            if nav3.button("ë‹¤ìŒ â–¶"):
                if st.session_state.current_page < len(doc) - 1:
                    st.session_state.current_page += 1

            page = doc.load_page(st.session_state.current_page)
            pix = page.get_pixmap(dpi=150)
            st.image(
                Image.frombytes("RGB", [pix.width, pix.height], pix.samples),
                use_container_width=True
            )

            page_text = (page.get_text() or "").strip()

        # ---------- ì˜¤ë¥¸ìª½: AI ë¶„ì„ ----------
        with col_ai:
            st.subheader("ğŸ§  ì‹œí—˜ ëŒ€ë¹„ AI ë¶„ì„")

            if st.button("âš¡ ì´ í˜ì´ì§€ ë¶„ì„"):
                if not api_key or not st.session_state.api_key_ok:
                    st.error("API Key ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                    st.stop()

                if not st.session_state.db:
                    st.error("ì¡±ë³´ DBê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¡±ë³´ë¥¼ í•™ìŠµí•˜ì„¸ìš”.")
                    st.stop()

                if not page_text:
                    st.warning("ì´ í˜ì´ì§€ì—ëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤ (ìŠ¤ìº” ì´ë¯¸ì§€ ê°€ëŠ¥).")
                    st.stop()

                with st.spinner("ì‹œí—˜ í¬ì¸íŠ¸ ë¶„ì„ ì¤‘..."):
                    related = find_relevant_jokbo(
                        page_text,
                        st.session_state.db,
                        top_k=3
                    )

                    jokbo_ctx = "\n".join([
                        f"- (p{r['content']['page']}) {r['content']['text'][:200]}"
                        for r in related
                    ])

                    prompt = f"""
ë„ˆëŠ” ì˜ëŒ€ ì‹œí—˜ ëŒ€ë¹„ ì¡°êµë‹¤.
ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€ì¼œì„œ ë‹µë³€í•´.

[1ï¸âƒ£ í•µì‹¬ ê°œë…]
- bullet 5ê°œ

[2ï¸âƒ£ ì¡±ë³´ ì—°ê²°]
- ì¡±ë³´ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ë°˜ë“œì‹œ ì–¸ê¸‰
- 'ê¸°ì¶œ ë³€í˜• / ë°˜ë³µ ê°œë… / ìƒˆ ê°•ì¡°ì 'ìœ¼ë¡œ êµ¬ë¶„

[3ï¸âƒ£ ì˜ˆìƒ ë¬¸ì œ]
- ê°ê´€ì‹ 2ë¬¸í•­
- ë‹¨ë‹µí˜• 1ë¬¸í•­
- ê° ë¬¸ì œì˜ ì •ë‹µê³¼ í•´ì„¤ í¬í•¨

---
[ê°•ì˜ í˜ì´ì§€ í…ìŠ¤íŠ¸]
{page_text}

[ê´€ë ¨ ì¡±ë³´ ë°œì·Œ]
{jokbo_ctx if jokbo_ctx else "(ê´€ë ¨ ì¡±ë³´ ì—†ìŒ)"}
""".strip()

                    model_list = st.session_state.text_models or []
                    fallback = model_list + [
                        "models/gemini-1.5-flash-latest",
                        "models/gemini-1.5-pro-latest"
                    ]

                    try:
                        result, used = generate_with_fallback(prompt, fallback)
                        st.caption(f"ì‚¬ìš© ëª¨ë¸: {used}")

                        st.markdown("### ğŸ” ë¶„ì„ ê²°ê³¼")
                        st.markdown(result)

                    except Exception as e:
                        st.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")


# ==================================================
# TAB 3 â€” ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¶„ì„ (ê°•ì˜ ì¤‘ ë©”ëª¨ìš©)
# ==================================================
with tab3:
    st.header("âŒ¨ï¸ ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¶„ì„")
    st.info(
        "ê°•ì˜ ì¤‘ êµìˆ˜ë‹˜ì´ ê°•ì¡°í•œ ë¬¸ì¥ì„ ë°”ë¡œ ì…ë ¥í•˜ë©´, "
        "ì‹œí—˜ ì¶œì œ ê°€ëŠ¥ì„±ì„ ì¦‰ì‹œ ë¶„ì„í•©ë‹ˆë‹¤."
    )

    if not api_key or not st.session_state.api_key_ok:
        st.warning("ì‚¬ì´ë“œë°”ì—ì„œ API Keyë¥¼ ë¨¼ì € ì„¤ì •í•˜ì„¸ìš”.")
        st.stop()

    if not st.session_state.db:
        st.warning("ì¡±ë³´ DBê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¡±ë³´ë¥¼ í•™ìŠµí•˜ì„¸ìš”.")
        st.stop()

    user_input = st.text_area(
        "ğŸš¨ êµìˆ˜ë‹˜ì´ 'ì¤‘ìš”í•˜ë‹¤ / ì‹œí—˜ì— ë‚¼ ìˆ˜ ìˆë‹¤'ê³  ë§í•œ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì…ë ¥í•˜ì„¸ìš”",
        height=160,
        placeholder="ì˜ˆ) ì´ ê¸°ì „ì€ êµê³¼ì„œì—ëŠ” ì—†ì§€ë§Œ ì„ìƒì ìœ¼ë¡œ ì¤‘ìš”í•˜ë‹¤..."
    )

    if st.button("ğŸ“Š ì‹œí—˜ ì¶œì œ ê°€ëŠ¥ì„± ë¶„ì„"):
        query = user_input.strip()
        if not query:
            st.error("ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            st.stop()

        with st.spinner("ì¡±ë³´ ì—°ê²° ì¤‘..."):
            related = find_relevant_jokbo(query, st.session_state.db, top_k=3)

        st.subheader("ğŸ” ì¡±ë³´ì™€ì˜ ì—°ê²°")
        context_str = ""

        if not related:
            st.write("â†’ ê¸°ì¡´ ì¡±ë³´ì—ëŠ” ì—†ëŠ” ìƒˆë¡œìš´ ê°•ì¡°ì ì¼ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.")
        else:
            for i, r in enumerate(related):
                with st.expander(
                    f"ê´€ë ¨ ì¡±ë³´ #{i+1} (ìœ ì‚¬ë„ {r['score']:.3f})"
                ):
                    st.write(f"í˜ì´ì§€ {r['content']['page']}")
                    st.write(r["content"]["text"])
                context_str += (
                    f"- (í˜ì´ì§€ {r['content']['page']}) "
                    f"{r['content']['text']}\n"
                )

        st.divider()
        st.subheader("ğŸ©º Med-Study ì‹œí—˜ ì¸ì‚¬ì´íŠ¸")

        final_prompt = f"""
ìƒí™©: ì˜ëŒ€ ê°•ì˜ ì¤‘ ì‹¤ì‹œê°„ ì‹œí—˜ ëŒ€ë¹„ ì •ë¦¬.

êµìˆ˜ë‹˜ ë°œì–¸:
{query}

ê´€ë ¨ ì¡±ë³´:
{context_str if context_str else "(ê´€ë ¨ ì¡±ë³´ ì—†ìŒ)"}

ë¯¸ì…˜:
1. ì´ ë°œì–¸ì´ ì‹œí—˜ì— ë‚˜ì˜¬ ê°€ëŠ¥ì„±ì„ â˜…â˜†â˜†â˜†â˜†~â˜…â˜…â˜…â˜…â˜…ë¡œ í‰ê°€.
2. ê·¸ ì´ìœ ë¥¼ ì¡±ë³´ ê´€ì ì—ì„œ ì„¤ëª….
3. ì˜ˆìƒ ë¬¸ì œ 2ê°œ + ì •ë‹µ/í•´ì„¤.
4. ë°”ë¡œ ì™¸ìš¸ ìˆ˜ ìˆëŠ” 'ì•”ê¸° í¬ì¸íŠ¸' 5ì¤„.
""".strip()

        model_list = st.session_state.text_models or []
        fallback = model_list + [
            "models/gemini-1.5-flash-latest",
            "models/gemini-1.5-pro-latest"
        ]

        try:
            result, used = generate_with_fallback(final_prompt, fallback)
            st.caption(f"ì‚¬ìš© ëª¨ë¸: {used}")
            st.markdown(result)
        except Exception as e:
            st.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
