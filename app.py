# app.py
# ==============================================================================
#  Med-Study OS: ì˜ëŒ€ìƒì„ ìœ„í•œ ìŠ¤ë§ˆíŠ¸ í•™ìŠµ ì–´ì‹œìŠ¤í„´íŠ¸ (Premium Version)
#  ê¸°ëŠ¥: ì¡±ë³´ ë¬¸í•­ë³„ ìë™ ë¶„ë¦¬, AI ì •ë°€ ë¶„ì„, í”„ë¦¬ë¯¸ì—„ ì¹´ë“œ UI
# ==============================================================================

import time
import re
import json
import random
import numpy as np
import fitz  # PyMuPDF
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st
import google.generativeai as genai
from google.api_core import retry, exceptions

# ------------------------------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì • ë° ë””ìì¸ (CSS)
# ------------------------------------------------------------------------------
st.set_page_config(
    page_title="Med-Study OS",
    layout="wide",
    page_icon="ğŸ©º",
    initial_sidebar_state="expanded"
)

# í”„ë¦¬ë¯¸ì—„ ë””ìì¸ CSS ì ìš©
st.markdown("""
<style>
    /* 1. Global Fonts & Colors */
    @import url("https://cdn.jsdelivr.net/gh/orioncactus/pretendard@v1.3.8/dist/web/static/pretendard.css");
    
    .stApp { 
        background-color: #f8f9fa; 
        font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, system-ui, Roboto, sans-serif;
    }
    
    h1, h2, h3, h4, h5, h6, .stMarkdown { color: #2c3e50 !important; }
    
    /* 2. Premium Card Style (Photo-Like) */
    div[data-testid="stVerticalBlockBorderWrapper"] {
        background-color: #ffffff;
        border: 1px solid #eef2f6;
        border-radius: 16px;
        padding: 24px;
        box-shadow: 0 4px 20px rgba(200, 210, 230, 0.25); /* ë¶€ë“œëŸ¬ìš´ ê·¸ë¦¼ì */
        margin-bottom: 20px;
        transition: transform 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
    }
    div[data-testid="stVerticalBlockBorderWrapper"]:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(200, 210, 230, 0.4);
        border-color: #007aff;
    }

    /* 3. Badges (Pill Shape) */
    .badge {
        display: inline-flex;
        align-items: center;
        justify-content: center;
        padding: 4px 10px;
        border-radius: 99px;
        font-size: 0.75rem;
        font-weight: 700;
        margin-right: 6px;
        margin-bottom: 8px;
        letter-spacing: -0.3px;
    }
    .badge-blue { background-color: #e3f2fd; color: #1565c0; border: 1px solid #bbdefb; }
    .badge-red { background-color: #ffebee; color: #c62828; border: 1px solid #ffcdd2; }
    .badge-gray { background-color: #f5f5f5; color: #616161; border: 1px solid #eeeeee; }
    
    /* 4. Question Typography */
    .q-header {
        font-size: 1.1rem;
        font-weight: 800;
        color: #1a1a1a;
        margin-top: 4px;
        margin-bottom: 12px;
        line-height: 1.4;
    }
    .q-body {
        font-size: 0.95rem;
        color: #495057;
        line-height: 1.7;
        background-color: #fafafa; /* ì•„ì£¼ ì—°í•œ íšŒìƒ‰ ë°•ìŠ¤ */
        padding: 16px;
        border-radius: 10px;
        border: 1px solid #f1f3f5;
        white-space: pre-wrap;
    }

    /* 5. Separator (Dashed) */
    .dashed-line {
        border-top: 2px dashed #e0e0e0;
        margin: 20px 0;
        width: 100%;
        height: 0;
    }

    /* 6. Expander Styling */
    .streamlit-expanderHeader {
        font-size: 0.85rem;
        font-weight: 600;
        color: #555;
        background-color: #ffffff;
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        padding: 8px 12px;
    }
    .streamlit-expanderHeader:hover {
        color: #007aff;
        border-color: #007aff;
        background-color: #f8f9fa;
    }
    div[data-testid="stExpander"] {
        border: none;
        box-shadow: none;
    }
    div[data-testid="stExpanderDetails"] {
        padding: 12px;
        border: 1px solid #eee;
        border-radius: 8px;
        margin-top: 8px;
        background-color: #fafafa;
    }

    /* 7. Buttons */
    div.stButton > button {
        border-radius: 10px;
        font-weight: 600;
        border: none;
        height: 2.8rem;
        transition: 0.2s;
        box-shadow: none;
        background-color: #f1f3f5;
    }
    div.stButton > button:hover {
        background-color: #e9ecef;
        transform: scale(1.01);
    }
    div.stButton > button[kind="primary"] {
        background: linear-gradient(135deg, #007aff 0%, #0062cc 100%);
        box-shadow: 0 4px 12px rgba(0,122,255,0.25);
        color: white;
    }
    div.stButton > button[kind="primary"] p { color: white !important; }

    /* Login Animation */
    .login-logo { font-size: 5rem; animation: bounce 2s infinite; display: inline-block; margin-bottom: 20px; }
    @keyframes bounce { 0%, 100% {transform: translateY(0);} 50% {transform: translateY(-15px);} }

    /* Layout */
    .block-container { padding-top: 2rem; max-width: 1200px; }
    header { visibility: hidden; }
</style>
""", unsafe_allow_html=True)


# ------------------------------------------------------------------------------
# 2. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (State Management)
# ------------------------------------------------------------------------------
state_defaults = {
    "logged_in": False, "db": [], "api_key": None, "api_key_ok": False,
    "text_models": [], "embedding_models": [], "best_text_model": None, "best_embedding_model": None,
    "lecture_doc": None, "lecture_filename": None, "current_page": 0,
    "edit_target_subject": None, "subject_detail_view": None, "t2_selected_subject": None,
    "transcribed_text": "", "chat_history": [],
    "last_page_sig": None, "last_ai_sig": None, "last_ai_data": None, "last_related": [],
    "tr_res": None,
    "analysis_cache": {} 
}

for k, v in state_defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v


# ------------------------------------------------------------------------------
# 3. í•µì‹¬ ë¡œì§ & AI í•¨ìˆ˜ (Core Logic)
# ------------------------------------------------------------------------------

def ensure_configured():
    if st.session_state.get("api_key"):
        genai.configure(api_key=st.session_state["api_key"])

@st.cache_data(show_spinner=False)
def list_available_models(api_key: str):
    try:
        genai.configure(api_key=api_key)
        all_models = list(genai.list_models())
        text_mods = [m.name for m in all_models if "generateContent" in getattr(m, "supported_generation_methods", [])]
        embed_mods = [m.name for m in all_models if "embedContent" in getattr(m, "supported_generation_methods", [])]
        return text_mods, embed_mods
    except: return [], []

def get_best_model(models, keywords):
    if not models: return None
    for k in keywords:
        found = [m for m in models if k in m]
        if found: return found[0]
    return models[0]

# [Text Segmentation] ë¬¸í•­ë³„ ë¶„ë¦¬ í•¨ìˆ˜ (í•µì‹¬ ê¸°ëŠ¥)
def split_text_into_questions(text):
    """
    í…ìŠ¤íŠ¸ì—ì„œ '1.', '2.' ë“±ì˜ íŒ¨í„´ì„ ì°¾ì•„ ë¬¸í•­ë³„ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    """
    if not text: return []
    
    # ì •ê·œì‹: ì¤„ë°”ê¿ˆ í˜¹ì€ ì‹œì‘ ë¶€ë¶„ì˜ ìˆ«ì+ì /ê´„í˜¸ (ì˜ˆ: 1. 2. 1) 2) )
    # (?:\n|^) : ì¤„ë°”ê¿ˆì´ë‚˜ ë¬¸ì¥ ì‹œì‘
    # \s* : ê³µë°± í—ˆìš©
    # (\d+[\.\)]) : ìˆ«ì ë’¤ì— ì ì´ë‚˜ ê´„í˜¸ ìº¡ì³
    pattern = r'(?:\n|^)\s*(\d+[\.\)])\s+'
    
    parts = re.split(pattern, text)
    
    questions = []
    # parts[0]ì€ ì²« ë¬¸ì œ ì „ì˜ ì„œë¡ ì¼ ìˆ˜ ìˆìŒ. parts[1]ì€ ë²ˆí˜¸, parts[2]ëŠ” ë‚´ìš©...
    if len(parts) < 2:
        return [text.strip()] # ë¶„ë¦¬ ì‹¤íŒ¨ì‹œ í†µì§¸ë¡œ ë°˜í™˜
        
    current_q = parts[0].strip()
    if current_q: questions.append(current_q) # ì„œë¡ ì´ ìˆë‹¤ë©´ ì¶”ê°€
    
    for i in range(1, len(parts), 2):
        num = parts[i]
        content = parts[i+1] if i+1 < len(parts) else ""
        full_q = f"{num} {content.strip()}"
        questions.append(full_q)
        
    return questions

# [Text Beautifier] - ì¡±ë³´ ê°€ë…ì„± í–¥ìƒ
def clean_jokbo_text(text):
    if not text: return ""
    # 1. ë¬¸í•­ ë²ˆí˜¸ ê°•ì¡°
    text = re.sub(r'(\n|^)(\d+)\.', r'\n\n**\2.**', text)
    # 2. ë³´ê¸° ê°€ë…ì„± (â‘ , (1) ë“± ì¤„ë°”ê¿ˆ)
    text = re.sub(r'(\s)(â‘ |â‘¡|â‘¢|â‘£|â‘¤|â¶|â·|â¸|â¹|âº|\(1\)|\(2\)|\(3\)|\(4\)|\(5\)|1\)|2\)|3\)|4\)|5\))', r'\n\2', text)
    # 3. ë¶ˆí•„ìš”í•œ ì¤„ë°”ê¿ˆ ì œê±°
    text = re.sub(r'\n{3,}', '\n\n', text)
    # 4. í˜ì´ì§€ ë²ˆí˜¸ ì œê±°
    text = re.sub(r'(?m)^\d+\s*$', '', text) 
    return text.strip()

# [Robust Embedding]
def get_embedding_robust(text: str):
    text = (text or "").strip()
    if len(text) < 10: return None, "text_too_short" # ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
    ensure_configured()
    
    if not st.session_state.embedding_models:
        _, embs = list_available_models(st.session_state.api_key)
        st.session_state.embedding_models = embs
    
    candidates = st.session_state.embedding_models
    if not candidates: return None, "No models"
    
    # ìµœì‹  ëª¨ë¸ ìš°ì„ 
    sorted_candidates = sorted(candidates, key=lambda x: 0 if 'text-embedding-004' in x else 1)
    
    for model_name in sorted_candidates[:2]:
        for attempt in range(3):
            try:
                time.sleep(1.0)
                if "004" in model_name:
                    res = genai.embed_content(model=model_name, content=text, task_type="retrieval_document")
                else:
                    res = genai.embed_content(model=model_name, content=text)
                if res and "embedding" in res: return res["embedding"], None
            except Exception as e:
                if "429" in str(e): time.sleep(2 * (attempt + 1))
                elif "404" in str(e): break
                else: time.sleep(1)
    return None, "API Error"

def filter_db_by_subject(subject: str, db: list[dict]):
    if not db: return []
    if subject in ["ì „ì²´", "ALL", ""]: return db
    return [x for x in db if x.get("subject") == subject]

def find_relevant_jokbo(query_text: str, db: list[dict], top_k: int = 10):
    if not db: return []
    query_emb, _ = get_embedding_robust(query_text)
    if not query_emb: return []
    
    valid_items = [item for item in db if item.get("embedding")]
    if not valid_items: return []
    db_embs = [item["embedding"] for item in valid_items]
    
    sims = cosine_similarity([query_emb], db_embs)[0]
    top_idxs = np.argsort(sims)[::-1][:top_k]
    return [{"score": float(sims[i]), "content": valid_items[i]} for i in top_idxs]

# [AI JSON Generator with Retry]
def generate_json_response_robust(prompt: str):
    ensure_configured()
    target_model = st.session_state.best_text_model or "gemini-1.5-flash"
    
    text_result = None
    for attempt in range(3):
        try:
            config = genai.GenerationConfig(temperature=0.3, response_mime_type="application/json")
            model = genai.GenerativeModel(target_model, generation_config=config)
            res = model.generate_content(prompt)
            text_result = res.text
            break
        except Exception as e:
            if "429" in str(e): time.sleep(2 * (attempt + 1)); continue
            try: # Text mode fallback
                model = genai.GenerativeModel(target_model)
                res = model.generate_content(prompt)
                text_result = res.text
                break
            except: pass
    
    if not text_result:
        return {"explanation": "AI ì—°ê²° ì‹¤íŒ¨", "direction": "ë¶„ì„ ë¶ˆê°€", "twin_question": "ìƒì„± ë¶ˆê°€"}

    text_result = re.sub(r"```json\s*", "", text_result)
    text_result = re.sub(r"```\s*$", "", text_result)
    text_result = text_result.strip()

    try:
        match = re.search(r'\{.*\}', text_result, re.DOTALL)
        if match: text_result = match.group(0)
        return json.loads(text_result)
    except json.JSONDecodeError:
        return {"explanation": text_result, "direction": "íŒŒì‹± ì˜¤ë¥˜", "twin_question": "ì˜¤ë¥˜"}

def generate_text_response(prompt: str):
    ensure_configured()
    target_model = st.session_state.best_text_model or "gemini-1.5-flash"
    for attempt in range(3):
        try:
            model = genai.GenerativeModel(target_model)
            res = model.generate_content(prompt)
            return res.text
        except Exception as e:
            if "429" in str(e): time.sleep(2 * (attempt + 1)); continue
            return f"Error: {e}"
    return "AI ì‘ë‹µ ì‹¤íŒ¨"

def transcribe_image_to_text(image, api_key):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content([
            "Extract all text from this image exactly as is. Organize by question number.",
            image
        ])
        return response.text
    except: return None

def transcribe_audio_gemini(audio_bytes, api_key):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
        res = model.generate_content(["Transcribe accurately.", {"mime_type": "audio/wav", "data": audio_bytes}])
        return res.text
    except: return None

def parse_metadata_from_filename(filename):
    year_match = re.search(r'(20\d{2})', filename)
    year = year_match.group(1) if year_match else ""
    exam_type = "ê¸°ì¶œ"
    if "ì¤‘ê°„" in filename: exam_type = "ì¤‘ê°„"
    elif "ê¸°ë§" in filename: exam_type = "ê¸°ë§"
    elif "ëª¨ì˜" in filename: exam_type = "ëª¨ì˜"
    elif "êµ­ì‹œ" in filename: exam_type = "êµ­ì‹œ"
    return f"{year} {exam_type}".strip() or "ê¸°ì¶œ"

# --- Prompts ---
def build_page_analysis_prompt_json(lecture_text, related_jokbo, subject):
    jokbo_ctx = "\n".join([f"- {r['content']['text'][:300]}" for r in related_jokbo[:3]])
    return f"""
    Role: Medical Tutor. 
    Task: Analyze lecture content vs jokbo(exam questions).
    Subject: {subject}
    
    [Jokbo Questions]
    {jokbo_ctx}
    
    [Lecture Page]
    {lecture_text[:1500]}
    
    Output JSON (Korean):
    {{
        "direction": "ì‹œí—˜ ì¶œì œ í¬ì¸íŠ¸ 1~2ë¬¸ì¥ (í•µì‹¬ ì•”ê¸° ì‚¬í•­)",
        "twin_question": "ì¡±ë³´ì™€ ìœ ì‚¬í•œ ê°ê´€ì‹ ë³€í˜• ë¬¸ì œ 1ê°œ (ë³´ê¸° í¬í•¨)",
        "explanation": "ìœ„ ë³€í˜• ë¬¸ì œì˜ ì •ë‹µ ë° ìƒì„¸ í•´ì„¤"
    }}
    """

def build_chat_prompt(hist, ctx, rel, q):
    return f"ì§ˆë¬¸: {q}\nê°•ì˜: {ctx[:1000]}\nì¡±ë³´: {rel}\në‹µë³€í•´ì£¼ì„¸ìš”."

def build_transcript_prompt(chunks, packs, subj):
    return f"ê°•ì˜ ë‚´ìš©ì„ ì¡±ë³´ì™€ ì—°ê³„í•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”. ê³¼ëª©: {subj}"

def chunk_transcript(text): return [text[i:i+900] for i in range(0, len(text), 900)]
def extract_text_from_pdf(uploaded_file):
    try:
        return fitz.open(stream=uploaded_file.getvalue(), filetype="pdf")
    except: return None

def get_subject_files(subject):
    files = {}
    for item in st.session_state.db:
        if item.get("subject") == subject:
            src = item.get("source", "Unknown")
            files[src] = files.get(src, 0) + 1
    return files

def get_subject_stats():
    stats = {}
    for item in st.session_state.db:
        subj = item.get("subject", "ê¸°íƒ€")
        if subj not in stats: stats[subj] = {"count": 0}
        stats[subj]["count"] += 1
    return stats

def has_jokbo_evidence(related: list[dict]) -> bool:
    return bool(related) and related[0]["score"] >= 0.70


# ==============================================================================
# 4. ë©”ì¸ UI (Main App UI)
# ==============================================================================

if not st.session_state.logged_in:
    login()
    st.stop()

# [Sidebar]
with st.sidebar:
    st.markdown("### ğŸ‘¤ ë‚´ í”„ë¡œí•„")
    with st.container(border=True):
        c1, c2 = st.columns([1, 3])
        c1.markdown("## ğŸ‘¨â€âš•ï¸")
        c2.markdown("**Student Admin**\n\n<span style='color:gray; font-size:0.8em'>ë³¸ê³¼ 2í•™ë…„</span>", unsafe_allow_html=True)
        if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True): logout()

    st.markdown("### ğŸ“š ë‚´ í•™ìŠµ ê³¼ëª©")
    my_subjects = sorted({x.get("subject", "ê¸°íƒ€") for x in st.session_state.db})
    if my_subjects:
        for s in my_subjects:
            st.markdown(f"<div style='background:white; padding:10px; border-radius:10px; border:1px solid #eee; margin-bottom:5px; font-weight:600;'>ğŸ“˜ {s}</div>", unsafe_allow_html=True)
    else: st.caption("ë“±ë¡ëœ ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.divider()

    st.markdown("### âš™ï¸ ì„¤ì •")
    with st.container(border=True):
        api_key_input = st.text_input("Gemini API Key", type="password", key="api_key_input")
        if api_key_input: st.session_state.api_key = api_key_input.strip()
            
        if st.button("ğŸ”„ ëª¨ë¸ ì—°ê²° (í•„ìˆ˜)", use_container_width=True):
            if not st.session_state.api_key: st.error("API Key í•„ìš”")
            else:
                with st.spinner("ì—°ê²° ì¤‘..."):
                    t_mods, e_mods = list_available_models(st.session_state.api_key)
                    if t_mods and e_mods:
                        st.session_state.api_key_ok = True
                        st.session_state.text_models = t_mods
                        st.session_state.embedding_models = e_mods
                        st.session_state.best_text_model = get_best_model(t_mods, ["flash", "pro"])
                        st.session_state.best_embedding_model = get_best_model(e_mods, ["text-embedding-004", "004"])
                        st.success(f"âœ… ì—°ê²° ì„±ê³µ! ({st.session_state.best_text_model})")
                    else: st.error("ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("### ğŸ“Š DB í˜„í™©")
    with st.container(border=True):
        st.metric("ì´ í•™ìŠµ ë¬¸í•­", len(st.session_state.db))
        if st.button("DB ì´ˆê¸°í™”"): st.session_state.db = []; st.session_state.analysis_cache = {}; st.rerun()

st.title("Med-Study OS")
tab1, tab2, tab3 = st.tabs(["ğŸ“‚ ì¡±ë³´ ê´€ë¦¬", "ğŸ“– ê°•ì˜ ë¶„ì„", "ğŸ™ï¸ ê°•ì˜ ë…¹ìŒ/ë¶„ì„"])

# ------------------------------------------------------------------------------
# TAB 1: ì¡±ë³´ ê´€ë¦¬ (í•™ìŠµ - ë¬¸í•­ë³„ ë¶„ë¦¬ ì ìš©)
# ------------------------------------------------------------------------------
with tab1:
    if st.session_state.subject_detail_view:
        target_subj = st.session_state.subject_detail_view
        c_back, c_title = st.columns([1, 5])
        if c_back.button("â† ëª©ë¡"): st.session_state.subject_detail_view = None; st.rerun()
        c_title.markdown(f"### ğŸ“‚ {target_subj} íŒŒì¼ ëª©ë¡")
        st.divider()
        file_map = get_subject_files(target_subj)
        for fname, count in file_map.items():
            meta = parse_metadata_from_filename(fname)
            with st.container(border=True):
                c1, c2 = st.columns([5, 1])
                c1.markdown(f"**ğŸ“„ {fname}**")
                c1.markdown(f"<span class='badge badge-blue'>{meta}</span>", unsafe_allow_html=True)
                c2.caption(f"{count} items")
    else:
        col_upload, col_list = st.columns([1, 2])
        with col_upload:
            with st.container(border=True):
                st.markdown("#### â• ì¡±ë³´ ì¶”ê°€")
                up_subj = st.selectbox("ê³¼ëª©", ["í•´ë¶€í•™", "ìƒë¦¬í•™", "ì•½ë¦¬í•™", "ì§ì ‘ì…ë ¥"], key="up_subj")
                final_subj = st.text_input("ê³¼ëª©ëª…", placeholder="ì˜ˆ: ë³‘ë¦¬í•™") if up_subj == "ì§ì ‘ì…ë ¥" else up_subj
                
                files = st.file_uploader("PDF ì„ íƒ", accept_multiple_files=True, type="pdf")
                
                if st.button("í•™ìŠµ ì‹œì‘", type="primary", use_container_width=True):
                    if not st.session_state.api_key_ok: st.error("ì™¼ìª½ ì„¤ì •ì—ì„œ ëª¨ë¸ì„ ì—°ê²°í•´ì£¼ì„¸ìš”.")
                    elif not files: st.warning("íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    else:
                        bar = st.progress(0)
                        log_area = st.empty()
                        logs = []
                        def log(m): logs.append(m); log_area.markdown("\n".join([f"- {l}" for l in logs[-5:]]))
                        
                        new_db = []
                        for i, f in enumerate(files):
                            try:
                                log(f"ğŸ“‚ {f.name} ë¶„ì„ ì¤‘...")
                                doc = fitz.open(stream=f.getvalue(), filetype="pdf")
                                for p_idx, page in enumerate(doc):
                                    text = page.get_text().strip()
                                    
                                    # OCR Fallback
                                    if len(text) < 50:
                                        try:
                                            pix = page.get_pixmap()
                                            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                                            ocr_text = transcribe_image_to_text(img, st.session_state.api_key)
                                            if ocr_text: text = ocr_text; log(f"âœ¨ P.{p_idx+1} OCR ì™„ë£Œ")
                                        except: pass
                                    
                                    # [NEW] ë¬¸í•­ë³„ ë¶„ë¦¬ ë¡œì§ ì ìš©
                                    questions = split_text_into_questions(text)
                                    
                                    for q_idx, q_text in enumerate(questions):
                                        q_text = clean_jokbo_text(q_text)
                                        if len(q_text) < 10: continue # ë„ˆë¬´ ì§§ì€ ì¡°ê°ì€ íŒ¨ìŠ¤
                                        
                                        emb, err = get_embedding_robust(q_text)
                                        if emb:
                                            new_db.append({
                                                "page": p_idx+1,
                                                "q_num": q_idx+1,
                                                "text": q_text,
                                                "source": f.name,
                                                "embedding": emb,
                                                "subject": final_subj
                                            })
                                    
                                    if not questions: log(f"âŒ P.{p_idx+1} í…ìŠ¤íŠ¸ ì—†ìŒ")
                                log(f"âœ… {f.name} ì™„ë£Œ")
                            except Exception as e: log(f"Error: {e}")
                            bar.progress((i+1)/len(files))
                        
                        if new_db:
                            st.session_state.db.extend(new_db)
                            st.success(f"{len(new_db)}ê°œ ë¬¸í•­ í•™ìŠµ ì™„ë£Œ!"); time.sleep(1); st.rerun()
                        else: st.warning("ë°ì´í„° ì—†ìŒ")

        with col_list:
            st.markdown("#### ğŸ“š í•™ìŠµ ë°ì´í„°")
            stats = get_subject_stats()
            subjects = sorted(stats.keys())
            for i in range(0, len(subjects), 2):
                cols = st.columns(2)
                for j in range(2):
                    if i + j < len(subjects):
                        s = subjects[i+j]
                        with cols[j]:
                            with st.container(border=True):
                                c1, c2 = st.columns([4, 1])
                                if c1.button(f"## {s}", key=f"v_{s}"): st.session_state.subject_detail_view = s; st.rerun()
                                st.markdown(f"**{stats[s]['count']}** items")

# ------------------------------------------------------------------------------
# TAB 2: ê°•ì˜ ë¶„ì„ (ë¯¸ë¦¬ ë¶„ì„ + ì¹´ë“œ UI)
# ------------------------------------------------------------------------------
with tab2:
    if st.session_state.t2_selected_subject is None:
        st.info("ê³¼ëª©ì„ ì„ íƒí•˜ì„¸ìš”.")
        stats = get_subject_stats()
        cols = st.columns(3)
        for i, s in enumerate(stats):
            if cols[i%3].button(f"## {s}", key=f"t2_{s}", use_container_width=True):
                st.session_state.t2_selected_subject = s
                st.rerun()
    else:
        target_subj = st.session_state.t2_selected_subject
        c_back, c_head = st.columns([1, 5])
        if c_back.button("â† ë’¤ë¡œ"): st.session_state.t2_selected_subject = None; st.rerun()
        c_head.markdown(f"#### ğŸ“– {target_subj} ë¶„ì„")
        
        with st.expander("ğŸ“‚ ê°•ì˜ PDF ì—´ê¸°", expanded=(st.session_state.lecture_doc is None)):
            l_file = st.file_uploader("PDF", type="pdf", key="t2_f", label_visibility="collapsed")
            if l_file and l_file.name != st.session_state.lecture_filename:
                st.session_state.lecture_doc = fitz.open(stream=l_file.getvalue(), filetype="pdf")
                st.session_state.lecture_filename = l_file.name
                st.session_state.current_page = 0
                st.session_state.analysis_cache = {} 
                
            if st.session_state.lecture_doc:
                if st.button("ğŸš€ ì „ì²´ í˜ì´ì§€ ë¯¸ë¦¬ ë¶„ì„í•˜ê¸° (ì†ë„ í–¥ìƒ)", use_container_width=True):
                    if not st.session_state.api_key_ok: st.error("API Key í•„ìš”")
                    else:
                        doc = st.session_state.lecture_doc
                        total = len(doc)
                        bar = st.progress(0)
                        sub_db = filter_db_by_subject(target_subj, st.session_state.db)
                        
                        for idx in range(total):
                            try:
                                page = doc.load_page(idx)
                                txt = page.get_text().strip()
                                if len(txt) < 50:
                                    pix = page.get_pixmap()
                                    img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                                    ocr = transcribe_image_to_text(img, st.session_state.api_key)
                                    if ocr: txt = ocr
                                
                                if txt:
                                    rel = find_relevant_jokbo(txt, sub_db, top_k=10)
                                    ai_res = None
                                    if has_jokbo_evidence(rel):
                                        prmt = build_page_analysis_prompt_json(txt, rel, target_subj)
                                        ai_res = generate_json_response_robust(prmt)
                                    
                                    st.session_state.analysis_cache[idx] = {
                                        "text": txt, "related": rel, "ai_data": ai_res
                                    }
                            except: pass
                            bar.progress((idx + 1) / total)
                        st.success("ë¶„ì„ ì™„ë£Œ!")

        if st.session_state.lecture_doc:
            doc = st.session_state.lecture_doc
            c_view, c_ai = st.columns([1.5, 1.2])
            
            with c_view:
                with st.container(border=True):
                    c1, c2, c3 = st.columns([1, 2, 1])
                    if c1.button("â—€"): st.session_state.current_page = max(0, st.session_state.current_page-1); st.rerun()
                    c2.markdown(f"<div style='text-align:center;'><b>Page {st.session_state.current_page+1}</b></div>", unsafe_allow_html=True)
                    if c3.button("â–¶"): st.session_state.current_page = min(len(doc)-1, st.session_state.current_page+1); st.rerun()
                    
                    page = doc.load_page(st.session_state.current_page)
                    pix = page.get_pixmap(dpi=150)
                    st.image(Image.frombytes("RGB", [pix.width, pix.height], pix.samples), use_container_width=True)

            with c_ai:
                ai_tab1, ai_tab2 = st.tabs(["ğŸ“ ì¡±ë³´ ë§¤ì¹­", "ğŸ’¬ ì§ˆì˜ì‘ë‹µ"])
                with ai_tab1:
                    cur_idx = st.session_state.current_page
                    cache_data = st.session_state.analysis_cache.get(cur_idx)
                    
                    p_text = ""
                    rel = []
                    res_ai = {}
                    
                    if cache_data:
                        p_text = cache_data["text"]
                        rel = cache_data["related"]
                        res_ai = cache_data["ai_data"] or {}
                    else:
                        page = doc.load_page(cur_idx)
                        p_text = page.get_text().strip()
                        if len(p_text) < 50:
                            try:
                                pix = page.get_pixmap()
                                img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                                ocr = transcribe_image_to_text(img, st.session_state.api_key)
                                if ocr: p_text = ocr
                            except: pass
                        
                        if p_text:
                            sub_db = filter_db_by_subject(target_subj, st.session_state.db)
                            rel = find_relevant_jokbo(p_text, sub_db, top_k=10)
                            if has_jokbo_evidence(rel) and st.session_state.api_key_ok:
                                with st.spinner("ì‹¤ì‹œê°„ ë¶„ì„ ì¤‘..."):
                                    prmt = build_page_analysis_prompt_json(p_text, rel, target_subj)
                                    res_ai = generate_json_response_robust(prmt)
                    
                    if not p_text: st.info("í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    elif not has_jokbo_evidence(rel): st.info("ê´€ë ¨ ê¸°ì¶œ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        high_rel_count = len([r for r in rel if r['score'] > 0.82])
                        
                        # ìƒìœ„ 2ê°œ ì¹´ë“œ ë Œë”ë§
                        for i, r in enumerate(rel[:2]):
                            score = r['score']
                            src = r['content'].get('source', 'Unknown')
                            txt = r['content'].get('text', '')
                            txt_clean = clean_jokbo_text(txt)[:400] # ë¯¸ë¦¬ë³´ê¸° ê¸¸ì´ ì œí•œ
                            meta = parse_metadata_from_filename(src)
                            
                            freq_html = ""
                            if i == 0 and high_rel_count >= 2:
                                freq_html = f"<span class='badge badge-red'>ğŸ”¥ {high_rel_count}íšŒ ì¶œì œ</span>"
                            elif score > 0.88:
                                freq_html = "<span class='badge badge-red'>â˜… ë§¤ìš° ìœ ì‚¬</span>"
                            
                            with st.container(border=True):
                                st.markdown(f"<div><span class='badge badge-blue'>ê¸°ì¶œ</span>{freq_html}<span class='badge badge-gray'>{meta}</span></div>", unsafe_allow_html=True)
                                st.markdown(f"<div class='q-header'>Q. (ê´€ë ¨ ë¬¸í•­)</div>", unsafe_allow_html=True)
                                st.markdown(f"<div class='q-body'>{txt_clean}...</div>", unsafe_allow_html=True)
                                st.markdown("<div class='dashed-line'></div>", unsafe_allow_html=True)
                                
                                c1, c2, c3 = st.columns(3)
                                with c1:
                                    with st.expander("ğŸ“ ì •ë‹µ/í•´ì„¤"):
                                        if i == 0: st.write(res_ai.get("explanation", "ë¶„ì„ ì¤‘..."))
                                        else: st.caption("ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì œì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
                                with c2:
                                    with st.expander("ğŸ¯ ì¶œì œí¬ì¸íŠ¸"):
                                        if i == 0: st.write(res_ai.get("direction", "ë¶„ì„ ì¤‘..."))
                                        else: st.caption("ë‚´ìš© ì—†ìŒ")
                                with c3:
                                    with st.expander("ğŸ”„ ìŒë‘¥ì´ë¬¸ì œ"):
                                        if i == 0: st.info(res_ai.get("twin_question", "ë¶„ì„ ì¤‘..."))
                                        else: st.caption("ë‚´ìš© ì—†ìŒ")
                                
                                # [CHANGED] ì „ì²´ ì¡±ë³´ ë³´ê¸°
                                with st.expander("ğŸ” ì „ì²´ ì¡±ë³´ ë³´ê¸°"):
                                    st.text(clean_jokbo_text(txt)) # ì „ì²´ í…ìŠ¤íŠ¸ í‘œì‹œ

                with ai_tab2:
                    for msg in st.session_state.chat_history:
                        with st.chat_message(msg["role"]): st.markdown(msg["content"])
                    if q := st.chat_input("ì§ˆë¬¸..."):
                        if st.session_state.api_key_ok:
                            st.session_state.chat_history.append({"role":"user", "content":q})
                            with st.chat_message("user"): st.markdown(q)
                            with st.chat_message("assistant"):
                                with st.spinner("ë‹µë³€ ì¤‘..."):
                                    prmt = build_chat_prompt(st.session_state.chat_history, p_text, rel, q)
                                    ans = generate_text_response(prmt)
                                    st.markdown(ans)
                                    st.session_state.chat_history.append({"role":"assistant", "content":ans})

# ------------------------------------------------------------------------------
# TAB 3: ë…¹ìŒ ë¶„ì„ (ì™„ì „í•œ ê¸°ëŠ¥ ë³µêµ¬)
# ------------------------------------------------------------------------------
with tab3:
    with st.container(border=True):
        st.markdown("#### ğŸ™ï¸ ê°•ì˜ ë…¹ìŒ/ë¶„ì„")
        c_in, c_out = st.columns(2)
        with c_in:
            sub_t3 = st.selectbox("ê³¼ëª©", ["ì „ì²´"] + sorted({x.get("subject", "") for x in st.session_state.db}), key="t3_s")
            t3_mode = st.radio("ì…ë ¥ ë°©ì‹", ["ğŸ¤ ë…¹ìŒ", "ğŸ“‚ í…ìŠ¤íŠ¸"], horizontal=True, label_visibility="collapsed")
            target_text = ""
            
            if t3_mode == "ğŸ¤ ë…¹ìŒ":
                av = st.audio_input("ë…¹ìŒ")
                if av and st.button("ë¶„ì„", key="bm"):
                    if st.session_state.api_key_ok:
                        ts = transcribe_audio_gemini(av.getvalue(), st.session_state.api_key)
                        if ts: st.session_state.transcribed_text = ts; target_text = ts
            else:
                ft = st.file_uploader("íŒŒì¼", type="txt"); at = st.text_area("ì…ë ¥")
                if st.button("ë¶„ì„", key="bt"): target_text = (ft.getvalue().decode() if ft else at).strip()
            
            if target_text:
                if st.session_state.api_key_ok:
                    with st.spinner("ë¶„ì„ ì¤‘..."):
                        sdb = filter_db_by_subject(sub_t3, st.session_state.db)
                        chks = chunk_transcript(target_text)[:10]
                        rels = [find_relevant_jokbo(c, sdb, top_k=3) for c in chks]
                        res = generate_text_response(build_transcript_prompt(chks, rels, sub_t3))
                        st.session_state.tr_res = res
                    st.success("ì™„ë£Œ")

        with c_out:
            if "tr_res" in st.session_state and st.session_state.tr_res:
                with st.container(border=True):
                    st.markdown("##### ğŸ“ ìš”ì•½ ë…¸íŠ¸"); st.info(st.session_state.tr_res)
                if st.session_state.transcribed_text:
                    with st.expander("ğŸ—£ï¸ ì „ì²´ ìŠ¤í¬ë¦½íŠ¸"): st.text(st.session_state.transcribed_text)
            else: st.info("ê²°ê³¼ ëŒ€ê¸° ì¤‘...")
