# app.py (Full Features Restored + UX Enhanced)
import time
import re
import json
import numpy as np
import fitz  # PyMuPDF
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st
import google.generativeai as genai

# ==========================================
# 0. Page Config & Design System
# ==========================================
st.set_page_config(
    page_title="Med-Study OS",
    layout="wide",
    page_icon="ğŸ©º",
    initial_sidebar_state="expanded"
)

# Custom CSS for polished, distraction-free studying
st.markdown("""
<style>
    /* Global Clean Look */
    .stApp { background-color: #f8f9fa; }
    h1, h2, h3 { font-family: 'Helvetica Neue', sans-serif; letter-spacing: -0.5px; color: #1c1c1e; }
    
    /* PDF Container styling */
    .pdf-container {
        border: 1px solid #e0e0e0;
        border-radius: 12px;
        overflow: hidden;
        box-shadow: 0 4px 12px rgba(0,0,0,0.05);
    }

    /* Question Card Styling */
    .q-card {
        background-color: white;
        border: 1px solid #edf2f7;
        border-radius: 12px;
        padding: 20px;
        margin-bottom: 16px;
        transition: all 0.2s ease;
        border-left: 4px solid #007aff;
    }
    .q-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 16px rgba(0,0,0,0.05);
    }
    .q-meta {
        font-size: 0.8rem;
        color: #8e8e93;
        margin-bottom: 8px;
        display: flex;
        justify-content: space-between;
        align-items: center;
    }
    .q-text {
        font-size: 1rem;
        font-weight: 500;
        line-height: 1.6;
        color: #1c1c1e;
        margin-bottom: 16px;
    }
    .q-badge {
        background-color: #e3f2fd;
        color: #1565c0;
        padding: 2px 8px;
        border-radius: 4px;
        font-weight: 700;
        font-size: 0.75rem;
    }

    /* Twin Problem Card Style (Restored) */
    .twin-card {
        background-color: #f5faff;
        border: 1px solid #bbdefb;
        border-radius: 12px;
        padding: 20px;
        margin-top: 15px;
        box-shadow: 0 2px 8px rgba(33,150,243,0.08);
    }
    .twin-badge {
        background-color: #2196f3;
        color: white;
        padding: 4px 8px;
        border-radius: 6px;
        font-weight: 700;
        font-size: 0.75rem;
        margin-bottom: 10px;
        display: inline-block;
    }

    /* Answer/Explanation Box */
    .ans-box {
        background-color: #f1f8e9;
        border-radius: 8px;
        padding: 16px;
        margin-top: 12px;
        border-left: 4px solid #7cb342;
        animation: fadeIn 0.3s ease-in-out;
    }
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(-5px); }
        to { opacity: 1; transform: translateY(0); }
    }

    /* Tabs & Buttons */
    div.stButton > button { border-radius: 8px; font-weight: 600; }
    .stTabs [data-baseweb="tab-list"] { background-color: transparent; border-bottom: 1px solid #e0e0e0; }
    .stTabs [data-baseweb="tab"] { font-weight: 600; color: #888; }
    .stTabs [aria-selected="true"] { color: #007aff !important; border-bottom: 2px solid #007aff; }
    
    /* Chat Styling */
    .stChatMessage { background-color: white; border-radius: 12px; padding: 10px; border: 1px solid #eee; }
</style>
""", unsafe_allow_html=True)


# ==========================================
# 1. State Management
# ==========================================
DEFAULT_STATE = {
    "logged_in": False,
    "db": [], 
    "bookmarks": [],
    "api_key": "",
    "lecture_doc": None,
    "lecture_filename": None,
    "current_page": 0,
    "selected_subject": None,
    "last_page_sig": None,
    "current_related_qs": [],
    "analyzed_data": {},  # { question_hash: {parsed: ..., twin: ...} }
    "chat_history": [],
    "hot_pages": [],      # For Hot Page Analysis
    "hot_pages_analyzed": False,
    "transcribed_text": "", # For Audio Tab
    "tr_res": None,         # For Transcript Analysis Result
    "api_key_ok": False     # To track API status
}

for k, v in DEFAULT_STATE.items():
    if k not in st.session_state:
        st.session_state[k] = v

# ==========================================
# 2. Core Logic Functions
# ==========================================

def get_embedding(text):
    """Robust embedding retrieval with error handling."""
    if not st.session_state.api_key: return None
    try:
        genai.configure(api_key=st.session_state.api_key)
        # Try primary model first, fallback if needed
        model = "models/text-embedding-004"
        result = genai.embed_content(model=model, content=text[:9000])
        return result.get("embedding")
    except Exception:
        try:
            # Fallback to older model
            result = genai.embed_content(model="models/embedding-001", content=text[:9000])
            return result.get("embedding")
        except:
            return None

def find_relevant_questions(query_text, subject, threshold=0.65, top_k=5):
    """Finds questions from DB relevant to the current page text."""
    if not st.session_state.db or not query_text: return []
    
    # Filter DB by subject
    subject_db = [item for item in st.session_state.db if item.get("subject") == subject]
    if not subject_db: return []

    # Get query embedding
    q_emb = get_embedding(query_text)
    if not q_emb: return []

    # Calculate Similarities
    db_embs = [item["embedding"] for item in subject_db]
    sims = cosine_similarity([q_emb], db_embs)[0]

    # Filter & Sort
    results = []
    top_idxs = np.argsort(sims)[::-1][:top_k]
    
    for idx in top_idxs:
        score = sims[idx]
        if score >= threshold:
            results.append({
                "score": float(score),
                "content": subject_db[idx]
            })
    
    return results

def generate_ai_analysis(question_text):
    """Generates structure (JSON) and Twin Problem using LLM."""
    if not st.session_state.api_key: return None
    genai.configure(api_key=st.session_state.api_key)
    model = genai.GenerativeModel("gemini-1.5-flash")
    
    prompt = f"""
    You are a medical tutor. Analyze this exam question.
    
    [Question Text]:
    {question_text}

    1. Extract the correct answer and a detailed explanation.
    2. Create a "Twin Problem" (similar concept, different scenario).
    
    Output ONLY valid JSON format:
    {{
        "answer": "String (e.g., 3)",
        "explanation": "String (Detailed logic)",
        "twin_problem": "String (Full question text with options)",
        "twin_answer": "String",
        "twin_explanation": "String"
    }}
    """
    try:
        res = model.generate_content(prompt)
        text = res.text.replace("```json", "").replace("```", "").strip()
        return json.loads(text)
    except:
        return None

def analyze_hot_pages(doc, subject):
    """Background analysis to find important pages in PDF."""
    hot_list = []
    subject_db = [item for item in st.session_state.db if item.get("subject") == subject]
    if not subject_db: return []
    
    db_embs = [item["embedding"] for item in subject_db]
    
    # Sample every page (or every 2nd page for speed if needed)
    for p_idx in range(len(doc)):
        try:
            page = doc.load_page(p_idx)
            txt = page.get_text().strip()
            if len(txt) > 50:
                emb = get_embedding(txt)
                if emb:
                    sims = cosine_similarity([emb], db_embs)[0]
                    max_score = max(sims)
                    if max_score >= 0.70: # Threshold for 'Hot'
                        hot_list.append({"page": p_idx, "score": max_score})
        except: pass
        
    return sorted(hot_list, key=lambda x: x["score"], reverse=True)[:15]

# --- Transcription & Analysis Helpers (Restored) ---
def transcribe_audio_gemini(audio_bytes):
    if not st.session_state.api_key: return None
    try:
        genai.configure(api_key=st.session_state.api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content([
            "Please transcribe the following audio file into text accurately. Do not add any conversational text, just the transcription.",
            {"mime_type": "audio/wav", "data": audio_bytes}
        ])
        return response.text
    except Exception as e:
        return f"Error: {str(e)}"

def chunk_transcript(text):
    """Splits long text into manageable chunks for AI analysis."""
    return [text[i:i+900] for i in range(0, len(text), 900)]

def build_transcript_prompt(chunks, related_packs, subject):
    """Constructs a prompt to summarize lecture based on Exam questions."""
    packed = ""
    for idx, (chunk, rel) in enumerate(zip(chunks, related_packs), 1):
        if not rel or rel[0]["score"] < 0.6: continue
        ctx = "\n".join([f"- {r['content']['text'][:200]}" for r in rel[:2]])
        packed += f"\n(êµ¬ê°„ {idx})\n[ê°•ì˜] {chunk}\n[ê´€ë ¨ ì¡±ë³´] {ctx}\n"
    
    if not packed: return "ì¡±ë³´ì™€ ë°€ì ‘í•œ ê´€ë ¨ì´ ìˆëŠ” ë‚´ìš©ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ìš”ì•½ì„ ì œê³µí•´ì£¼ì„¸ìš”."
    
    return f"""
    ë‹¹ì‹ ì€ ì˜ëŒ€ ì¡°êµì…ë‹ˆë‹¤. ê°•ì˜ ë…¹ìŒ ì „ì‚¬ë³¸ì„ ì¡±ë³´(ê¸°ì¶œë¬¸ì œ) ë°ì´í„°ì™€ ëŒ€ì¡°í•˜ì—¬ ìš”ì•½í–ˆìŠµë‹ˆë‹¤.
    
    [ê³¼ëª©]: {subject}
    [ë¶„ì„ ë‚´ìš©]:
    {packed}
    
    ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ì˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”:
    1. **ğŸ” ì¡±ë³´ ì ì¤‘ í¬ì¸íŠ¸**: ê°•ì˜ ë‚´ìš© ì¤‘ ê¸°ì¶œë¬¸ì œì™€ ì§ê²°ë˜ëŠ” í•µì‹¬ ê°œë….
    2. **ğŸ“ ê°•ì˜ ìš”ì•½**: ì „ì²´ì ì¸ íë¦„ ìš”ì•½.
    3. **âš ï¸ ì˜ˆìƒ ì¶œì œ ë¬¸ì œ**: ê°•ì˜ ë‚´ìš©ì— ê¸°ë°˜í•œ ì˜ˆìƒ ì§ˆë¬¸.
    """

# ==========================================
# 3. UI Components
# ==========================================

def sidebar_ui():
    with st.sidebar:
        st.markdown("### ğŸ©º Med-Study OS")
        
        # Profile
        if st.session_state.logged_in:
            st.success("ë¡œê·¸ì¸ë¨: Admin")
            if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True):
                st.session_state.logged_in = False
                st.rerun()
        st.divider()

        # Subject List
        st.markdown("**ğŸ“š ë‚´ ê³¼ëª© (My Subjects)**")
        subjects = sorted({x.get("subject", "ê¸°íƒ€") for x in st.session_state.db})
        if subjects:
            for s in subjects:
                if st.button(f"ğŸ“˜ {s}", key=f"nav_{s}", use_container_width=True):
                    st.session_state.selected_subject = s
                    st.rerun()
        else:
            st.info("ë“±ë¡ëœ ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

        st.divider()
        # Settings
        with st.expander("âš™ï¸ ì„¤ì • (API Key)"):
            key_input = st.text_input("Gemini API Key", value=st.session_state.api_key, type="password")
            if key_input: 
                st.session_state.api_key = key_input
                st.session_state.api_key_ok = True

def login_screen():
    c1, c2, c3 = st.columns([1,1,1])
    with c2:
        st.markdown("<div style='height:100px;'></div>", unsafe_allow_html=True)
        st.title("Med-Study OS")
        st.markdown("ìŠ¤ë§ˆíŠ¸í•œ ì˜ëŒ€ìƒì„ ìœ„í•œ í•™ìŠµ íŒŒíŠ¸ë„ˆ")
        with st.form("login_form"):
            uid = st.text_input("ID")
            pwd = st.text_input("PW", type="password")
            submitted = st.form_submit_button("Start Learning", type="primary", use_container_width=True)
            if submitted:
                if pwd == "1234":
                    st.session_state.logged_in = True
                    st.rerun()
                else:
                    st.error("ë¹„ë°€ë²ˆí˜¸: 1234")

def main_study_ui():
    if not st.session_state.selected_subject:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ í•™ìŠµí•  ê³¼ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    st.markdown(f"## ğŸ“– {st.session_state.selected_subject} í•™ìŠµ ëª¨ë“œ")
    
    col_pdf, col_right = st.columns([1.1, 1])
    
    # --- LEFT: PDF Viewer ---
    with col_pdf:
        uploaded_pdf = st.file_uploader("ê°•ì˜ë¡ PDF ì—´ê¸°", type="pdf", label_visibility="collapsed")
        
        if uploaded_pdf:
            # Load PDF & Analyze Hot Pages
            if st.session_state.lecture_filename != uploaded_pdf.name:
                st.session_state.lecture_doc = fitz.open(stream=uploaded_pdf.read(), filetype="pdf")
                st.session_state.lecture_filename = uploaded_pdf.name
                st.session_state.current_page = 0
                st.session_state.hot_pages_analyzed = False
                st.session_state.chat_history = []
            
            doc = st.session_state.lecture_doc
            
            # Hot Page Analysis Trigger
            if not st.session_state.hot_pages_analyzed:
                with st.spinner("ğŸš€ ê°•ì˜ë¡ ì „ì²´ ë¶„ì„ ì¤‘ (ì ì¤‘ ì˜ˆìƒ í˜ì´ì§€ ì°¾ëŠ” ì¤‘)..."):
                    st.session_state.hot_pages = analyze_hot_pages(doc, st.session_state.selected_subject)
                    st.session_state.hot_pages_analyzed = True
                st.rerun()

            # PDF Navigation
            c_prev, c_page, c_next = st.columns([1, 2, 1])
            with c_prev:
                if st.button("â—€ ì´ì „", use_container_width=True, disabled=(st.session_state.current_page <= 0)):
                    st.session_state.current_page -= 1
                    st.rerun()
            with c_page:
                st.markdown(f"<div style='text-align:center; font-weight:bold;'>Page {st.session_state.current_page + 1} / {len(doc)}</div>", unsafe_allow_html=True)
            with c_next:
                if st.button("ë‹¤ìŒ â–¶", use_container_width=True, disabled=(st.session_state.current_page >= len(doc)-1)):
                    st.session_state.current_page += 1
                    st.rerun()

            # Render Page
            page = doc.load_page(st.session_state.current_page)
            pix = page.get_pixmap(dpi=150)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            st.image(img, use_container_width=True, output_format="JPEG")
            current_text = page.get_text().strip()
        else:
            st.markdown("""
            <div style="padding:40px; text-align:center; border:2px dashed #ccc; border-radius:12px; color:#888;">
                <h3>ğŸ“‚ ê°•ì˜ë¡ PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”</h3>
            </div>
            """, unsafe_allow_html=True)
            current_text = ""

    # --- RIGHT: Multi-Function Panel ---
    with col_right:
        # Integrated Tabs for all functionalities
        r_tab1, r_tab2, r_tab3, r_tab4 = st.tabs(["ğŸ¯ ê´€ë ¨ ë¬¸ì œ", "ğŸ’¬ AI íŠœí„°", "ğŸ”¥ í•µì‹¬ í˜ì´ì§€", "ğŸ“‚ ì „ì²´ ë¬¸ì œ"])
        
        # Tab 1: Related Questions (Main Feature)
        with r_tab1:
            if not current_text:
                st.info("ê°•ì˜ë¡ì„ ì—´ë©´ ê´€ë ¨ ë¬¸ì œê°€ í‘œì‹œë©ë‹ˆë‹¤.")
            else:
                # Matching Logic
                page_sig = hash(current_text)
                if st.session_state.last_page_sig != page_sig:
                    with st.spinner("ğŸ” ë¶„ì„ ì¤‘..."):
                        st.session_state.current_related_qs = find_relevant_questions(
                            current_text, 
                            st.session_state.selected_subject,
                            threshold=0.65  # Strict matching restored
                        )
                        st.session_state.last_page_sig = page_sig

                questions = st.session_state.current_related_qs
                
                if not questions:
                    st.markdown("<div style='text-align:center; padding:30px; color:#888;'>ê´€ë ¨ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.</div>", unsafe_allow_html=True)
                else:
                    st.success(f"ğŸ”¥ {len(questions)}ê°œì˜ ì ì¤‘ ë¬¸ì œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    for idx, item in enumerate(questions):
                        q_content = item["content"]["text"]
                        score = item["score"]
                        q_id = f"q_{page_sig}_{idx}"
                        
                        st.markdown(f"""
                        <div class="q-card">
                            <div class="q-meta">
                                <span class="q-badge">ìœ ì‚¬ë„ {int(score*100)}%</span>
                                <span>{item['content']['source']} (P.{item['content']['page']})</span>
                            </div>
                            <div class="q-text">{q_content[:300]}...</div>
                        </div>
                        """, unsafe_allow_html=True)

                        c_act1, c_act2 = st.columns([1, 2])
                        show_ans_key = f"show_ans_{q_id}"
                        if show_ans_key not in st.session_state: st.session_state[show_ans_key] = False

                        if c_act1.button("â˜… ì €ì¥", key=f"bk_{q_id}"):
                            st.session_state.bookmarks.append(q_content)
                            st.toast("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

                        if c_act2.button("ì •ë‹µ ë° í•´ì„¤ í™•ì¸", key=f"btn_ans_{q_id}", type="primary"):
                            st.session_state[show_ans_key] = not st.session_state[show_ans_key]
                            if q_id not in st.session_state.analyzed_data:
                                with st.spinner("AI ë¶„ì„ ì¤‘..."):
                                    analysis = generate_ai_analysis(q_content)
                                    if analysis: st.session_state.analyzed_data[q_id] = analysis

                        if st.session_state[show_ans_key]:
                            data = st.session_state.analyzed_data.get(q_id)
                            if data:
                                # Render Answer Box
                                st.markdown(f"""
                                <div class="ans-box">
                                    <strong>âœ… ì •ë‹µ: {data.get('answer')}</strong><br><br>
                                    {data.get('explanation')}
                                </div>
                                """, unsafe_allow_html=True)
                                
                                # Render Twin Problem
                                with st.expander("ğŸ§© ìŒë‘¥ì´(ë³€í˜•) ë¬¸ì œ ë„ì „í•˜ê¸°"):
                                    st.markdown(f"""
                                    <div class="twin-card">
                                        <div class="twin-badge">TWIN PROBLEM</div>
                                        <div>{data.get('twin_problem')}</div>
                                    </div>
                                    """, unsafe_allow_html=True)
                                    if st.button("ë³€í˜• ë¬¸ì œ ë‹µ ë³´ê¸°", key=f"twin_{q_id}"):
                                        st.info(f"ì •ë‹µ: {data.get('twin_answer')}\n\ní•´ì„¤: {data.get('twin_explanation')}")

        # Tab 2: AI Tutor (Chat)
        with r_tab2:
            st.caption("í˜„ì¬ ê°•ì˜ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”.")
            for msg in st.session_state.chat_history:
                with st.chat_message(msg["role"]): st.write(msg["content"])
            
            if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥..."):
                if not st.session_state.api_key:
                    st.error("API Key í•„ìš”")
                else:
                    st.session_state.chat_history.append({"role": "user", "content": prompt})
                    with st.chat_message("user"): st.write(prompt)
                    
                    with st.chat_message("assistant"):
                        with st.spinner("ìƒê° ì¤‘..."):
                            # Context building
                            context_str = f"Current Lecture Page:\n{current_text[:1000]}\n"
                            if st.session_state.current_related_qs:
                                context_str += "\nRelated Exams:\n" + "\n".join([x["content"]["text"][:300] for x in st.session_state.current_related_qs[:2]])
                            
                            full_prompt = f"Context:\n{context_str}\n\nUser Question: {prompt}\nAnswer as a medical tutor."
                            
                            genai.configure(api_key=st.session_state.api_key)
                            model = genai.GenerativeModel("gemini-1.5-flash")
                            res = model.generate_content(full_prompt)
                            st.write(res.text)
                            st.session_state.chat_history.append({"role": "assistant", "content": res.text})

        # Tab 3: Hot Pages
        with r_tab3:
            st.markdown("##### ğŸ”¥ ì¶œì œ ì˜ˆìƒ í˜ì´ì§€")
            if not st.session_state.hot_pages:
                st.caption("ë¶„ì„ëœ ì¤‘ìš” í˜ì´ì§€ê°€ ì—†ê±°ë‚˜ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.")
            else:
                st.caption(f"{len(st.session_state.hot_pages)}ê°œì˜ ì¤‘ìš” í˜ì´ì§€ ë°œê²¬")
                cols = st.columns(3)
                for i, item in enumerate(st.session_state.hot_pages):
                    with cols[i % 3]:
                        if st.button(f"P.{item['page']+1}", key=f"hot_{i}", help=f"ì ì¤‘ë¥  {int(item['score']*100)}%"):
                            st.session_state.current_page = item['page']
                            st.rerun()

        # Tab 4: View All
        with r_tab4:
            st.markdown("##### ğŸ“‚ ì „ì²´ ë¬¸ì œ ëª¨ì•„ë³´ê¸°")
            subject_db = [item for item in st.session_state.db if item.get("subject") == st.session_state.selected_subject]
            if not subject_db:
                st.caption("ë°ì´í„° ì—†ìŒ")
            else:
                for i, item in enumerate(subject_db):
                    with st.expander(f"P.{item['page']} - {item['text'][:30]}..."):
                        st.write(item['text'])

def management_ui():
    st.markdown("## ğŸ“‚ ë°ì´í„° ë° ì¡±ë³´ ê´€ë¦¬")
    t1, t2 = st.tabs(["ì¡±ë³´ ì—…ë¡œë“œ", "ë¶ë§ˆí¬(ì˜¤ë‹µë…¸íŠ¸)"])
    with t1:
        new_subj = st.text_input("ê³¼ëª©ëª…", placeholder="í•´ë¶€í•™")
        files = st.file_uploader("PDF íŒŒì¼ ì„ íƒ", accept_multiple_files=True, type="pdf")
        if st.button("í•™ìŠµ ì‹œì‘", type="primary"):
            if files and new_subj and st.session_state.api_key:
                bar = st.progress(0)
                for idx, f in enumerate(files):
                    doc = fitz.open(stream=f.read(), filetype="pdf")
                    for p_num, page in enumerate(doc):
                        txt = page.get_text().strip()
                        if len(txt) > 50:
                            emb = get_embedding(txt)
                            if emb:
                                st.session_state.db.append({
                                    "subject": new_subj, "source": f.name, "page": p_num+1, "text": txt, "embedding": emb
                                })
                    bar.progress((idx+1)/len(files))
                st.success("ì™„ë£Œ!")
    with t2:
        if st.session_state.bookmarks:
            for b in st.session_state.bookmarks:
                st.info(b)
                st.button("ì‚­ì œ", key=f"del_{hash(b)}")
        else:
            st.caption("ì €ì¥ëœ ë¬¸ì œ ì—†ìŒ")

def record_ui():
    st.markdown("## ğŸ™ï¸ ê°•ì˜ ë…¹ìŒ ë° ì‹¬ì¸µ ë¶„ì„")
    st.caption("ê°•ì˜ë¥¼ ë…¹ìŒí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´, ì¡±ë³´ ë°ì´í„°ì™€ ëŒ€ì¡°í•˜ì—¬ 'ì ì¤‘ í¬ì¸íŠ¸'ë¥¼ ì°¾ì•„ì¤ë‹ˆë‹¤.")
    
    with st.container(border=True):
        mode = st.radio("ì…ë ¥ ë°©ì‹", ["ğŸ¤ ìŒì„± ë…¹ìŒ", "ğŸ“ í…ìŠ¤íŠ¸/íŒŒì¼"], horizontal=True)
        target_text = ""
        
        if mode == "ğŸ¤ ìŒì„± ë…¹ìŒ":
            audio_val = st.audio_input("ë…¹ìŒ ì‹œì‘")
            if audio_val and st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary"):
                if not st.session_state.api_key: st.error("API Key í•„ìš”")
                else:
                    with st.spinner("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                        txt = transcribe_audio_gemini(audio_val.getvalue())
                        if txt:
                            st.session_state.transcribed_text = txt
                            target_text = txt
                        else:
                            st.error("ë³€í™˜ ì‹¤íŒ¨")
        else:
            txt_in = st.text_area("ê°•ì˜ ë‚´ìš© ì…ë ¥", height=150)
            if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary"):
                target_text = txt_in
                st.session_state.transcribed_text = txt_in

        # Analysis Logic
        if target_text:
            st.session_state.transcribed_text = target_text
            with st.spinner("ğŸ” ì¡±ë³´ ë°ì´í„°ì™€ ëŒ€ì¡°í•˜ì—¬ ì ì¤‘ ë…¸íŠ¸ ìƒì„± ì¤‘..."):
                # 1. Chunking
                chunks = chunk_transcript(target_text)[:10] # Limit to first 10 chunks to save tokens
                
                # 2. Find Related Questions for each chunk
                subject = st.session_state.selected_subject or "ì „ì²´"
                related_packs = []
                for chk in chunks:
                    rels = find_relevant_questions(chk, subject, threshold=0.55, top_k=3) # Lower threshold for broad context
                    related_packs.append(rels)
                
                # 3. Generate Report
                genai.configure(api_key=st.session_state.api_key)
                model = genai.GenerativeModel("gemini-1.5-flash")
                prompt = build_transcript_prompt(chunks, related_packs, subject)
                
                try:
                    res = model.generate_content(prompt)
                    st.session_state.tr_res = res.text
                except Exception as e:
                    st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

    # Result Display
    if st.session_state.tr_res:
        st.divider()
        st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸")
        st.info(st.session_state.tr_res)
        
        with st.expander("ì›ë³¸ í…ìŠ¤íŠ¸ ë³´ê¸°"):
            st.write(st.session_state.transcribed_text)

# ==========================================
# 4. Main Execution
# ==========================================
def main():
    if not st.session_state.logged_in:
        login_screen()
    else:
        sidebar_ui()
        menu = st.tabs(["ğŸ“ í•™ìŠµí•˜ê¸° (Study)", "âš™ï¸ ë°ì´í„° ê´€ë¦¬", "ğŸ™ï¸ ê°•ì˜ ë…¹ìŒ"])
        
        with menu[0]:
            main_study_ui()
        with menu[1]:
            management_ui()
        with menu[2]:
            record_ui()

if __name__ == "__main__":
    main()
