# app.py (UI: Yellow Box / Logic: Smart Model Discovery)
import time
import re
import random
import numpy as np
import fitz  # PyMuPDF
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st
import google.generativeai as genai
from google.api_core import retry, exceptions 

# ==========================================
# 0. Page config & Custom CSS
# ==========================================
st.set_page_config(page_title="Med-Study OS", layout="wide", page_icon="ğŸ©º")

# Custom CSS
st.markdown("""
<style>
    .stApp { background-color: #f8f9fa; } 
    h1, h2, h3, h4, h5, h6, p, span, div, label, .stMarkdown { color: #1c1c1e !important; }
    .gray-text, .text-sm, .login-desc, small { color: #8e8e93 !important; }
    div.stButton > button p { color: #007aff !important; }
    div.stButton > button[kind="primary"] p { color: #ffffff !important; }
    div[data-baseweb="input"] { background-color: #ffffff !important; border: 1px solid #d1d1d6 !important; color: #1c1c1e !important; }
    div[data-baseweb="input"] input { color: #1c1c1e !important; }
    .block-container { padding: 1rem 2rem !important; max-width: 100% !important; }
    header[data-testid="stHeader"] { display: none; }
    .stTabs [data-baseweb="tab-list"] { gap: 8px; background-color: transparent; padding: 4px; border-radius: 10px; margin-bottom: 15px; }
    .stTabs [data-baseweb="tab"] { height: 40px; border-radius: 20px; padding: 0 20px; background-color: #ffffff; border: 1px solid #e0e0e0; font-weight: 600; color: #8e8e93 !important; flex-grow: 0; box-shadow: 0 2px 4px rgba(0,0,0,0.02); }
    .stTabs [aria-selected="true"] { background-color: #007aff !important; color: #ffffff !important; box-shadow: 0 4px 8px rgba(0,122,255,0.2); border: none; }
    div[data-testid="stVerticalBlockBorderWrapper"] {
        border-radius: 20px; border: 1px solid #edf2f7; box-shadow: 0 4px 20px rgba(0,0,0,0.03); 
        background-color: white; padding: 20px; transition: transform 0.2s ease;
    }
    div[data-testid="stVerticalBlockBorderWrapper"]:hover { transform: translateY(-2px); border-color: #007aff; }
    div.stButton > button { border-radius: 12px; font-weight: 600; border: none; background-color: #f2f2f7; height: 3rem; }
    div.stButton > button:hover { background-color: #e5e5ea; transform: scale(0.98); }
    div.stButton > button[kind="primary"] { background-color: #007aff; box-shadow: 0 4px 10px rgba(0,122,255,0.2); }
    div.stButton > button[kind="primary"]:hover { background-color: #0062cc; }
    .login-logo { font-size: 5rem; margin-bottom: 10px; animation: bounce 2s infinite; }
    @keyframes bounce { 0%, 20%, 50%, 80%, 100% {transform: translateY(0);} 40% {transform: translateY(-20px);} 60% {transform: translateY(-10px);} }
    .jokbo-item { background-color: #fffde7; border: 1px solid #fff59d; border-radius: 12px; padding: 16px; margin-bottom: 12px; }
    .jokbo-source { font-size: 0.8rem; color: #f57f17; margin-bottom: 6px; font-weight: 800; }
    .sidebar-subject { padding: 10px 15px; background-color: white; border-radius: 10px; margin-bottom: 8px; font-weight: 600; color: #333; border: 1px solid #f0f0f0; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 1. Session State
# ==========================================
defaults = {
    "logged_in": False, "db": [], "api_key": None, "api_key_ok": False,
    "text_models": [], "embedding_models": [], "best_text_model": None, "best_embedding_model": None,
    "lecture_doc": None, "lecture_filename": None, "current_page": 0,
    "edit_target_subject": None, "subject_detail_view": None, "t2_selected_subject": None,
    "transcribed_text": "", "chat_history": [],
    "last_page_sig": None, "last_ai_sig": None, "last_ai_text": "", "last_related": []
}
for k, v in defaults.items():
    if k not in st.session_state: st.session_state[k] = v

# ==========================================
# 2. Login
# ==========================================
def login():
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        st.markdown("<div style='height: 15vh;'></div>", unsafe_allow_html=True)
        st.markdown("""<div style="text-align: center;"><div class="login-logo">ğŸ©º</div><h1 style="color:#1c1c1e;">Med-Study OS</h1></div>""", unsafe_allow_html=True)
        with st.container(border=True):
            st.markdown("#### ë¡œê·¸ì¸")
            if st.button("ì•± ì‹œì‘í•˜ê¸° (Demo)", type="primary", use_container_width=True):
                st.session_state.logged_in = True
                st.rerun()

def logout():
    st.session_state.logged_in = False
    st.rerun()

# ==========================================
# 3. Helpers & Smart Model Logic
# ==========================================
def ensure_configured():
    if st.session_state.get("api_key"):
        genai.configure(api_key=st.session_state["api_key"])

@st.cache_data(show_spinner=False)
def list_available_models(api_key: str):
    """API í‚¤ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ë° ì„ë² ë”© ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        genai.configure(api_key=api_key)
        all_models = list(genai.list_models())
        
        text_mods = [m.name for m in all_models if "generateContent" in getattr(m, "supported_generation_methods", [])]
        embed_mods = [m.name for m in all_models if "embedContent" in getattr(m, "supported_generation_methods", [])]
        
        return text_mods, embed_mods
    except Exception as e:
        return [], []

def get_best_model(models, keywords):
    """í‚¤ì›Œë“œê°€ í¬í•¨ëœ ìµœì‹  ëª¨ë¸ì„ ìš°ì„  ì„ íƒí•©ë‹ˆë‹¤."""
    if not models: return None
    for k in keywords:
        found = [m for m in models if k in m]
        if found: return found[0]
    return models[0]

# --- Smart Robust Embedding ---
def get_embedding_robust(text: str, status_placeholder=None):
    """
    1. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì„ë² ë”© ëª¨ë¸ì„ ì°¾ìŒ.
    2. Rate Limit(429) ë°œìƒ ì‹œ ì§€ëŠ¥ì ìœ¼ë¡œ ëŒ€ê¸°.
    3. ì—†ëŠ” ëª¨ë¸(404)ì€ ì‹œë„í•˜ì§€ ì•ŠìŒ.
    """
    text = (text or "").strip()
    if len(text) < 50: return None, "text_too_short"
    ensure_configured()
    
    # ì„¸ì…˜ì— ì €ì¥ëœ ì„ë² ë”© ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ í™œìš© (ì—†ìœ¼ë©´ ë‹¤ì‹œ ê²€ìƒ‰)
    if not st.session_state.embedding_models:
        _, embs = list_available_models(st.session_state.api_key)
        st.session_state.embedding_models = embs
    
    # ìš°ì„ ìˆœìœ„: text-embedding-004 > 004 > embedding-001 ìˆœìœ¼ë¡œ ê²€ìƒ‰
    candidates = st.session_state.embedding_models
    if not candidates:
        return None, "No embedding models available for this API key."
        
    # ìš°ì„ ìˆœìœ„ ì •ë ¬
    sorted_candidates = sorted(candidates, key=lambda x: 0 if 'text-embedding-004' in x else 1)
    
    max_retries = 5
    base_wait = 3
    last_error_msg = ""

    # ëª¨ë¸ í•˜ë‚˜ì”© ì‹œë„ (ë³´í†µ ì²«ë²ˆì§¸ì—ì„œ ì„±ê³µí•´ì•¼ í•¨)
    for model_name in sorted_candidates[:2]: # ìƒìœ„ 2ê°œë§Œ ì‹œë„
        for attempt in range(max_retries):
            try:
                # API í˜¸ì¶œ ì†ë„ ì¡°ì ˆ
                time.sleep(1.5) 
                
                # ëª¨ë¸ì— ë”°ë¥¸ íŒŒë¼ë¯¸í„° ì¡°ì •
                if "004" in model_name:
                    res = genai.embed_content(model=model_name, content=text, task_type="retrieval_document")
                else:
                    res = genai.embed_content(model=model_name, content=text)
                    
                if res and "embedding" in res:
                    return res["embedding"], None # ì„±ê³µ
            
            except Exception as e:
                err_msg = str(e)
                last_error_msg = f"{model_name}: {err_msg}"
                
                if "429" in err_msg or "Resource exhausted" in err_msg:
                    wait_time = base_wait * (2 ** attempt) + random.randint(1, 3)
                    if status_placeholder:
                        status_placeholder.warning(f"âš ï¸ ì‚¬ìš©ëŸ‰ ë§ìŒ ({model_name}). {wait_time}ì´ˆ ëŒ€ê¸° ì¤‘... ({attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                elif "404" in err_msg or "Not Found" in err_msg:
                    # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì¦‰ì‹œ ë‹¤ìŒ ëª¨ë¸ë¡œ
                    break
                else:
                    time.sleep(1)
                    
    return None, f"Fail: {last_error_msg}"

def extract_text_from_pdf(uploaded_file):
    try:
        data = uploaded_file.getvalue()
        doc = fitz.open(stream=data, filetype="pdf")
        pages = []
        for i, page in enumerate(doc):
            text = page.get_text() or ""
            pages.append({"page": i + 1, "text": text, "source": uploaded_file.name})
        return pages
    except: return []

def find_relevant_jokbo(query_text, db, top_k=5):
    if not db: return []
    q_emb, _ = get_embedding_robust(query_text)
    if not q_emb: return []
    
    valid = [x for x in db if x.get("embedding")]
    if not valid: return []
    
    sims = cosine_similarity([q_emb], [x["embedding"] for x in valid])[0]
    idxs = np.argsort(sims)[::-1][:top_k]
    return [{"score": float(sims[i]), "content": valid[i]} for i in idxs]

def generate_with_fallback(prompt, model_names):
    ensure_configured()
    # í…ìŠ¤íŠ¸ ëª¨ë¸ë„ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì„ íƒ
    target_model = st.session_state.best_text_model or "gemini-1.5-flash"
    try:
        model = genai.GenerativeModel(target_model)
        res = model.generate_content(prompt)
        return res.text, target_model
    except Exception as e:
        raise Exception(f"AI Error ({target_model}): {str(e)}")

# --- Prompts (Same as before) ---
def build_overview_prompt(txt, subj): return f"ë„ˆëŠ” ì˜ëŒ€ ìˆ˜ì„ ì¡°êµë‹¤. '{subj}' ê°•ì˜ë¡ ì²« í˜ì´ì§€ë¥¼ ë³´ê³  í•µì‹¬ ëª©í‘œ, ì¡±ë³´ ê¸°ë°˜ ê³µë¶€ ì „ëµ 3ê°€ì§€, ì£¼ì˜ì ì„ ìš”ì•½í•´ë¼.\n[ë‚´ìš©]\n{txt[:1500]}"
def build_page_analysis_prompt(txt, rel, subj): 
    jokbo = "\n".join([f"- {r['content']['text'][:300]}" for r in rel[:3]])
    return f"ì˜ëŒ€ ì¡°êµë¡œì„œ ë¶„ì„í•´ë¼. ê³¼ëª©:{subj}\n[ê´€ë ¨ì¡±ë³´]\n{jokbo}\n[ê°•ì˜ë‚´ìš©]\n{txt[:1500]}\nì¶œë ¥í˜•ì‹:\n[SECTION: DIRECTION] ê³µë¶€ë°©í–¥, í‚¤ì›Œë“œ\n[SECTION: TWIN_Q] ì¡±ë³´ ë³€í˜• ë¬¸ì œ 1ê°œ\n[SECTION: EXPLANATION] ì •ë‹µ ë° í•´ì„¤"
def build_chat_prompt(hist, ctx, rel, q): return f"ì˜ëŒ€ ì¡°êµì…ë‹ˆë‹¤. ê°•ì˜ë‚´ìš©: {ctx[:1000]}\nê´€ë ¨ì¡±ë³´: {rel}\nì§ˆë¬¸: {q}\në‹µë³€í•´ì£¼ì„¸ìš”."
def build_transcript_prompt(chunks, packs, subj): return f"ê°•ì˜ ë‚´ìš©ì„ ì¡±ë³´ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”. ê³¼ëª©:{subj}\n(ìƒëµ)"
def chunk_transcript(text): return [text[i:i+900] for i in range(0, len(text), 900)]
def get_subject_stats(): return {item.get("subject", "ê¸°íƒ€"): {"count": 0} for item in st.session_state.db} # Simplified
def get_subject_files(subj): 
    files = {}
    for x in st.session_state.db:
        if x.get("subject") == subj: files[x.get("source")] = files.get(x.get("source"), 0) + 1
    return files

# ==========================================
# 4. Main UI
# ==========================================
if not st.session_state.logged_in:
    login()
    st.stop()

with st.sidebar:
    st.markdown("### ğŸ‘¤ ë‚´ í”„ë¡œí•„")
    with st.container(border=True):
        st.markdown("**Student Admin** (ë³¸ê³¼ 2í•™ë…„)")
        if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True): logout()
    
    st.markdown("### âš™ï¸ ì„¤ì • (í•„ìˆ˜)")
    with st.container(border=True):
        api_key = st.text_input("Gemini API Key", type="password", key="api_key_input")
        if api_key:
            st.session_state.api_key = api_key
            
        if st.button("ğŸ”„ ëª¨ë¸ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° (ì—°ê²° í…ŒìŠ¤íŠ¸)", use_container_width=True):
            if not st.session_state.api_key:
                st.error("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with st.spinner("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì°¾ëŠ” ì¤‘..."):
                    t_mods, e_mods = list_available_models(st.session_state.api_key)
                    
                    if t_mods and e_mods:
                        st.session_state.api_key_ok = True
                        st.session_state.text_models = t_mods
                        st.session_state.embedding_models = e_mods
                        
                        # Best model selection
                        st.session_state.best_text_model = get_best_model(t_mods, ["flash", "pro"])
                        st.session_state.best_embedding_model = get_best_model(e_mods, ["text-embedding-004", "004"])
                        
                        st.success(f"âœ… ì—°ê²° ì„±ê³µ!")
                        st.caption(f"í…ìŠ¤íŠ¸ ëª¨ë¸: {st.session_state.best_text_model}")
                        st.caption(f"ì„ë² ë”© ëª¨ë¸: {st.session_state.best_embedding_model}")
                    else:
                        st.error("ğŸš« ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (API Key ê¶Œí•œ í™•ì¸)")

    st.markdown("### ğŸ“Š DB í˜„í™©")
    st.metric("ì´ í•™ìŠµ í˜ì´ì§€", len(st.session_state.db))
    if st.button("DB ì´ˆê¸°í™”"): 
        st.session_state.db = []
        st.rerun()

st.title("Med-Study OS")
tab1, tab2, tab3 = st.tabs(["ğŸ“‚ ì¡±ë³´ ê´€ë¦¬", "ğŸ“– ê°•ì˜ ë¶„ì„", "ğŸ™ï¸ ê°•ì˜ ë…¹ìŒ/ë¶„ì„"])

with tab1:
    col_up, col_list = st.columns([1, 2])
    with col_up:
        with st.container(border=True):
            st.markdown("#### â• ì¡±ë³´ í•™ìŠµ")
            subj = st.text_input("ê³¼ëª©ëª…", value="ì§ì ‘ì…ë ¥")
            files = st.file_uploader("PDF ì—…ë¡œë“œ", accept_multiple_files=True, type="pdf")
            
            if st.button("í•™ìŠµ ì‹œì‘", type="primary", use_container_width=True):
                if not st.session_state.api_key_ok: st.error("ì™¼ìª½ ì„¤ì •ì—ì„œ 'ëª¨ë¸ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°'ë¥¼ ë¨¼ì € í•´ì£¼ì„¸ìš”!")
                elif not files: st.warning("íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")
                else:
                    bar = st.progress(0)
                    log_area = st.empty()
                    
                    # Log display
                    logs = []
                    def log(m): 
                        logs.append(m)
                        log_area.markdown("\n".join([f"- {l}" for l in logs[-5:]]))

                    new_data = []
                    for i, f in enumerate(files):
                        log(f"ğŸ“‚ {f.name} ì²˜ë¦¬ ì¤‘...")
                        pages = extract_text_from_pdf(f)
                        
                        success = 0
                        for p in pages:
                            emb, err = get_embedding_robust(p["text"], st.empty())
                            if emb:
                                p["embedding"] = emb
                                p["subject"] = subj
                                new_data.append(p)
                                success += 1
                            elif "429" in str(err):
                                log(f"âš ï¸ {f.name} ì¼ë¶€ í˜ì´ì§€ ìŠ¤í‚µ (ì‚¬ìš©ëŸ‰ ì´ˆê³¼)")
                        
                        log(f"âœ… {f.name}: {success}í˜ì´ì§€ í•™ìŠµ ì™„ë£Œ")
                        bar.progress((i+1)/len(files))
                    
                    if new_data:
                        st.session_state.db.extend(new_data)
                        st.success(f"ì´ {len(new_data)}í˜ì´ì§€ ì €ì¥ ì™„ë£Œ!")
                        time.sleep(1)
                        st.rerun()

    with col_list:
        st.markdown("#### ğŸ“š í•™ìŠµëœ ë°ì´í„°")
        db_subjs = sorted({x["subject"] for x in st.session_state.db})
        if not db_subjs: st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        for s in db_subjs:
            cnt = len([x for x in st.session_state.db if x["subject"] == s])
            with st.container(border=True):
                c1, c2 = st.columns([5, 1])
                c1.markdown(f"**ğŸ“˜ {s}** ({cnt} pages)")
                if c2.button("ë³´ê¸°", key=f"v_{s}"):
                    st.session_state.t2_selected_subject = s
                    st.rerun()

# (Tab 2, Tab 3 omitted for brevity, logic remains similar but uses session state models)
with tab2:
    st.markdown("#### ğŸ“– ì‹¤ì‹œê°„ ê°•ì˜ ë¶„ì„")
    if not st.session_state.t2_selected_subject:
        st.info("ì¡±ë³´ ê´€ë¦¬ íƒ­ì—ì„œ ê³¼ëª©ì˜ [ë³´ê¸°] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        st.markdown(f"**ì„ íƒëœ ê³¼ëª©: {st.session_state.t2_selected_subject}**")
        l_file = st.file_uploader("ê°•ì˜ PDF ì—´ê¸°", type="pdf", key="l_pdf")
        if l_file and l_file.name != st.session_state.lecture_filename:
            st.session_state.lecture_doc = fitz.open(stream=l_file.getvalue(), filetype="pdf")
            st.session_state.lecture_filename = l_file.name
            st.session_state.current_page = 0
        
        if st.session_state.lecture_doc:
            doc = st.session_state.lecture_doc
            c_view, c_ai = st.columns([1.5, 1])
            with c_view:
                if st.button("â—€ ì´ì „"): st.session_state.current_page = max(0, st.session_state.current_page-1)
                st.image(doc.load_page(st.session_state.current_page).get_pixmap().tobytes(), use_container_width=True)
                if st.button("ë‹¤ìŒ â–¶"): st.session_state.current_page = min(len(doc)-1, st.session_state.current_page+1)
            
            with c_ai:
                txt = doc.load_page(st.session_state.current_page).get_text()
                if st.button("ì´ í˜ì´ì§€ ë¶„ì„ (AI)", type="primary"):
                    if not st.session_state.api_key_ok: st.error("API ì—°ê²° í•„ìš”")
                    else:
                        with st.spinner("ë¶„ì„ ì¤‘..."):
                            related = find_relevant_jokbo(txt, [x for x in st.session_state.db if x["subject"] == st.session_state.t2_selected_subject])
                            res, _ = generate_with_fallback(build_page_analysis_prompt(txt, related, st.session_state.t2_selected_subject), [])
                            st.markdown(res)
                            if related:
                                with st.expander("ì°¸ê³ í•œ ì¡±ë³´"):
                                    for r in related[:2]: st.caption(f"{r['content']['text'][:100]}...")

with tab3:
    st.info("ê°•ì˜ ë…¹ìŒ ê¸°ëŠ¥ì€ Tab 2ì™€ ë™ì¼í•œ AI ë¡œì§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
