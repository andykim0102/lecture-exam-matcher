# app.py (Strict Matching + View All Toggle + Clean UI)
# app.py (UI: Original Rich Style / Logic: Smart Model Discovery + OCR Fallback + Robust Parsing 2.0 + Hot Page Nav)
import time
import re
import random
import json
import numpy as np
import fitzÂ  # PyMuPDF
import fitz  # PyMuPDF
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st
@@ -19,166 +19,120 @@
# Custom CSS for UI Enhancement
st.markdown("""
<style>
Â  Â  /* 1. Force Light Mode & Colors */
Â  Â  .stApp { background-color: #f8f9fa; }Â 
Â  Â  h1, h2, h3, h4, h5, h6, p, span, div, label, .stMarkdown { color: #1c1c1e !important; }
Â  Â  .gray-text, .text-sm, .login-desc, small { color: #8e8e93 !important; }
Â  Â Â 
Â  Â  /* Button Text Colors */
Â  Â  div.stButton > button p { color: #007aff !important; }
Â  Â  div.stButton > button[kind="primary"] p { color: #ffffff !important; }

Â  Â  /* 2. Input Styles */
Â  Â  div[data-baseweb="input"] { background-color: #ffffff !important; border: 1px solid #d1d1d6 !important; color: #1c1c1e !important; }
Â  Â  div[data-baseweb="input"] input { color: #1c1c1e !important; }
Â  Â Â 
Â  Â  /* 3. Layout Adjustments */
Â  Â  .block-container {Â 
Â  Â  Â  Â  padding-top: 1rem !important;Â 
Â  Â  Â  Â  padding-bottom: 2rem !important;Â 
Â  Â  Â  Â  padding-left: 1rem !important;Â 
Â  Â  Â  Â  padding-right: 1rem !important;Â 
Â  Â  Â  Â  max-width: 100% !important;
Â  Â  }
Â  Â  header[data-testid="stHeader"] { display: none; }

Â  Â  /* 4. Tab Styles */
Â  Â  .stTabs [data-baseweb="tab-list"] { gap: 8px; background-color: transparent; padding: 4px; border-radius: 10px; margin-bottom: 15px; }
Â  Â  .stTabs [data-baseweb="tab"] { height: 40px; border-radius: 20px; padding: 0 20px; background-color: #ffffff; border: 1px solid #e0e0e0; font-weight: 600; color: #8e8e93 !important; flex-grow: 0; box-shadow: 0 2px 4px rgba(0,0,0,0.02); }
Â  Â  .stTabs [aria-selected="true"] { background-color: #007aff !important; color: #ffffff !important; box-shadow: 0 4px 8px rgba(0,122,255,0.2); border: none; }

Â  Â  /* 5. Card Containers */
Â  Â  div[data-testid="stVerticalBlockBorderWrapper"] {
Â  Â  Â  Â  border-radius: 20px;Â 
Â  Â  Â  Â  border: 1px solid #edf2f7;Â 
Â  Â  Â  Â  box-shadow: 0 4px 20px rgba(0,0,0,0.03);Â 
Â  Â  Â  Â  background-color: white;
Â  Â  Â  Â  transition: transform 0.2s ease, box-shadow 0.2s ease;
Â  Â  Â  Â  padding: 20px;
Â  Â  }
Â  Â  div[data-testid="stVerticalBlockBorderWrapper"]:hover {
Â  Â  Â  Â  transform: translateY(-2px);
Â  Â  Â  Â  box-shadow: 0 10px 30px rgba(0,0,0,0.06);
Â  Â  Â  Â  border-color: #007aff;
Â  Â  }

Â  Â  /* 6. Buttons */
Â  Â  div.stButton > button { border-radius: 12px; font-weight: 600; border: none; box-shadow: none; background-color: #f2f2f7; transition: all 0.2s; height: 3rem; }
Â  Â  div.stButton > button:hover { background-color: #e5e5ea; transform: scale(0.98); }
Â  Â  div.stButton > button[kind="primary"] { background-color: #007aff; box-shadow: 0 4px 10px rgba(0,122,255,0.2); }
Â  Â  div.stButton > button[kind="primary"]:hover { background-color: #0062cc; box-shadow: 0 6px 14px rgba(0,122,255,0.3); }

Â  Â  /* 7. Subject Title Button */
Â  Â  div.stButton > button h2 {
Â  Â  Â  Â  font-size: 1.8rem !important;
Â  Â  Â  Â  font-weight: 800 !important;
Â  Â  Â  Â  margin: 0 !important;
Â  Â  Â  Â  padding: 5px 0 !important;
Â  Â  Â  Â  color: #1c1c1e !important;
Â  Â  Â  Â  line-height: 1.2 !important;
Â  Â  }

Â  Â  /* 8. Login & Misc */
Â  Â  .login-logo { font-size: 5rem; margin-bottom: 10px; animation: bounce 2s infinite; }
Â  Â  @keyframes bounce { 0%, 20%, 50%, 80%, 100% {transform: translateY(0);} 40% {transform: translateY(-20px);} 60% {transform: translateY(-10px);} }
Â  Â  .text-bold { font-weight: 700; color: #1c1c1e !important; }
Â  Â  div[data-testid="stFileUploader"] { padding: 20px; border: 2px dashed #d1d1d6; border-radius: 16px; background-color: #fafafa; }
Â  Â Â 
Â  Â  /* 9. Chat Messages */
Â  Â  .stChatMessage { background-color: #f9f9f9; border-radius: 16px; padding: 15px; margin-bottom: 10px; border: 1px solid #f0f0f0; }
Â  Â  div[data-testid="stChatMessageContent"] p { font-size: 0.95rem; line-height: 1.5; }
Â  Â Â 
Â  Â  /* 10. Exam Card Style */
Â  Â  .exam-card {
Â  Â  Â  Â  background-color: #ffffff;
Â  Â  Â  Â  border: 1px solid #e0e0e0;
Â  Â  Â  Â  border-radius: 16px;
Â  Â  Â  Â  padding: 24px;
Â  Â  Â  Â  margin-bottom: 15px;
Â  Â  Â  Â  box-shadow: 0 4px 12px rgba(0,0,0,0.04);
Â  Â  Â  Â  position: relative;
Â  Â  }
Â  Â  .exam-meta {
Â  Â  Â  Â  font-size: 0.85rem;
Â  Â  Â  Â  color: #666;
Â  Â  Â  Â  margin-bottom: 12px;
Â  Â  Â  Â  display: flex;
Â  Â  Â  Â  justify-content: space-between;
Â  Â  Â  Â  align-items: center;
Â  Â  Â  Â  border-bottom: 1px solid #f0f0f0;
Â  Â  Â  Â  padding-bottom: 8px;
Â  Â  }
Â  Â  .exam-score-badge {
Â  Â  Â  Â  background-color: #fff3e0;
Â  Â  Â  Â  color: #f57c00;
Â  Â  Â  Â  padding: 4px 8px;
Â  Â  Â  Â  border-radius: 6px;
Â  Â  Â  Â  font-weight: 700;
Â  Â  Â  Â  font-size: 0.8rem;
Â  Â  }
Â  Â  .exam-question {
Â  Â  Â  Â  font-size: 1.05rem;
Â  Â  Â  Â  font-weight: 500;
Â  Â  Â  Â  color: #333;
Â  Â  Â  Â  line-height: 1.6;
Â  Â  }

Â  Â  /* 11. Twin Problem Card Style */
Â  Â  .twin-card {
Â  Â  Â  Â  background-color: #f5faff;
Â  Â  Â  Â  border: 1px solid #bbdefb;
Â  Â  Â  Â  border-radius: 16px;
Â  Â  Â  Â  padding: 24px;
Â  Â  Â  Â  margin-top: 15px;
Â  Â  Â  Â  margin-bottom: 15px;
Â  Â  Â  Â  box-shadow: 0 2px 8px rgba(33,150,243,0.08);
Â  Â  }
Â  Â  .twin-badge {
Â  Â  Â  Â  background-color: #2196f3;
Â  Â  Â  Â  color: white;
Â  Â  Â  Â  padding: 4px 8px;
Â  Â  Â  Â  border-radius: 6px;
Â  Â  Â  Â  font-weight: 700;
Â  Â  Â  Â  font-size: 0.8rem;
Â  Â  Â  Â  margin-bottom: 10px;
Â  Â  Â  Â  display: inline-block;
Â  Â  }

Â  Â  /* 12. Answer/Explanation Box */
Â  Â  .explanation-box {
Â  Â  Â  Â  background-color: #f1f8e9;
Â  Â  Â  Â  border-left: 5px solid #7cb342;
Â  Â  Â  Â  padding: 15px 20px;
Â  Â  Â  Â  border-radius: 4px;
Â  Â  Â  Â  margin-top: 15px;
Â  Â  Â  Â  margin-bottom: 25px;
Â  Â  }
Â  Â  .exp-title {
Â  Â  Â  Â  font-weight: 800;
Â  Â  Â  Â  color: #558b2f;
Â  Â  Â  Â  margin-bottom: 5px;
Â  Â  Â  Â  font-size: 0.9rem;
Â  Â  }
Â  Â  .exp-text {
Â  Â  Â  Â  font-size: 0.95rem;
Â  Â  Â  Â  color: #33691e;
Â  Â  Â  Â  line-height: 1.5;
Â  Â  }

Â  Â  /* 13. Sidebar Items */
Â  Â  .sidebar-subject {
Â  Â  Â  Â  padding: 10px 15px;
Â  Â  Â  Â  background-color: white;
Â  Â  Â  Â  border-radius: 10px;
Â  Â  Â  Â  margin-bottom: 8px;
Â  Â  Â  Â  font-weight: 600;
Â  Â  Â  Â  color: #333;
Â  Â  Â  Â  box-shadow: 0 1px 3px rgba(0,0,0,0.05);
Â  Â  Â  Â  border: 1px solid #f0f0f0;
Â  Â  Â  Â  display: flex;
Â  Â  Â  Â  align-items: center;
Â  Â  Â  Â  gap: 8px;
Â  Â  }
    /* 1. Force Light Mode & Colors */
    .stApp { background-color: #f8f9fa; } 
    h1, h2, h3, h4, h5, h6, p, span, div, label, .stMarkdown { color: #1c1c1e !important; }
    .gray-text, .text-sm, .login-desc, small { color: #8e8e93 !important; }
    
    /* Button Text Colors */
    div.stButton > button p { color: #007aff !important; }
    div.stButton > button[kind="primary"] p { color: #ffffff !important; }

    /* 2. Input Styles */
    div[data-baseweb="input"] { background-color: #ffffff !important; border: 1px solid #d1d1d6 !important; color: #1c1c1e !important; }
    div[data-baseweb="input"] input { color: #1c1c1e !important; }
    
    /* 3. Layout Adjustments */
    .block-container { 
        padding-top: 1rem !important; 
        padding-bottom: 2rem !important; 
        padding-left: 1rem !important; 
        padding-right: 1rem !important; 
        max-width: 100% !important;
    }
    header[data-testid="stHeader"] { display: none; }

    /* 4. Tab Styles */
    .stTabs [data-baseweb="tab-list"] { gap: 8px; background-color: transparent; padding: 4px; border-radius: 10px; margin-bottom: 15px; }
    .stTabs [data-baseweb="tab"] { height: 40px; border-radius: 20px; padding: 0 20px; background-color: #ffffff; border: 1px solid #e0e0e0; font-weight: 600; color: #8e8e93 !important; flex-grow: 0; box-shadow: 0 2px 4px rgba(0,0,0,0.02); }
    .stTabs [aria-selected="true"] { background-color: #007aff !important; color: #ffffff !important; box-shadow: 0 4px 8px rgba(0,122,255,0.2); border: none; }

    /* 5. Card Containers */
    div[data-testid="stVerticalBlockBorderWrapper"] {
        border-radius: 20px; 
        border: 1px solid #edf2f7; 
        box-shadow: 0 4px 20px rgba(0,0,0,0.03); 
        background-color: white;
        transition: transform 0.2s ease, box-shadow 0.2s ease;
        padding: 20px;
    }
    div[data-testid="stVerticalBlockBorderWrapper"]:hover {
        transform: translateY(-2px);
        box-shadow: 0 10px 30px rgba(0,0,0,0.06);
        border-color: #007aff;
    }

    /* 6. Buttons */
    div.stButton > button { border-radius: 12px; font-weight: 600; border: none; box-shadow: none; background-color: #f2f2f7; transition: all 0.2s; height: 3rem; }
    div.stButton > button:hover { background-color: #e5e5ea; transform: scale(0.98); }
    div.stButton > button[kind="primary"] { background-color: #007aff; box-shadow: 0 4px 10px rgba(0,122,255,0.2); }
    div.stButton > button[kind="primary"]:hover { background-color: #0062cc; box-shadow: 0 6px 14px rgba(0,122,255,0.3); }

    /* 7. Subject Title Button */
    div.stButton > button h2 {
        font-size: 1.8rem !important;
        font-weight: 800 !important;
        margin: 0 !important;
        padding: 5px 0 !important;
        color: #1c1c1e !important;
        line-height: 1.2 !important;
    }

    /* 8. Login & Misc */
    .login-logo { font-size: 5rem; margin-bottom: 10px; animation: bounce 2s infinite; }
    @keyframes bounce { 0%, 20%, 50%, 80%, 100% {transform: translateY(0);} 40% {transform: translateY(-20px);} 60% {transform: translateY(-10px);} }
    .text-bold { font-weight: 700; color: #1c1c1e !important; }
    div[data-testid="stFileUploader"] { padding: 20px; border: 2px dashed #d1d1d6; border-radius: 16px; background-color: #fafafa; }
    
    /* 9. Chat Messages */
    .stChatMessage { background-color: #f9f9f9; border-radius: 16px; padding: 15px; margin-bottom: 10px; border: 1px solid #f0f0f0; }
    div[data-testid="stChatMessageContent"] p { font-size: 0.95rem; line-height: 1.5; }
    
    /* 10. Jokbo Items (Yellow Box Style) */
    .jokbo-item {
        background-color: #fffde7;
        border: 1px solid #fff59d;
        border-radius: 12px;
        padding: 16px;
        margin-bottom: 12px;
        box-shadow: 0 2px 6px rgba(0,0,0,0.02);
    }
    .jokbo-source {
        font-size: 0.8rem;
        color: #f57f17;
        margin-bottom: 6px;
        font-weight: 800;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    
    /* 11. Sidebar Items */
    .sidebar-subject {
        padding: 10px 15px;
        background-color: white;
        border-radius: 10px;
        margin-bottom: 8px;
        font-weight: 600;
        color: #333;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        border: 1px solid #f0f0f0;
        display: flex;
        align-items: center;
        gap: 8px;
    }
    .sidebar-icon { font-size: 1.1rem; }
    
    /* 12. Hot Page Button */
    .hot-page-btn-score { font-size: 0.8em; color: #ff3b30; }

    /* 13. Answer Box */
    .answer-box {
        background-color: #e8f5e9;
        border-left: 4px solid #4caf50;
        padding: 10px;
        margin-top: 10px;
        border-radius: 4px;
    }
</style>
""", unsafe_allow_html=True)

@@ -187,616 +141,919 @@
# 1. Session state initialization
# ==========================================
defaults = {
Â  Â  "logged_in": False, "db": [], "api_key": None, "api_key_ok": False,
Â  Â  "text_models": [], "embedding_models": [], "best_text_model": None, "best_embedding_model": None,
Â  Â  "lecture_doc": None, "lecture_filename": None, "current_page": 0,
Â  Â  "edit_target_subject": None, "subject_detail_view": None, "t2_selected_subject": None,
Â  Â  "transcribed_text": "", "chat_history": [],
Â  Â  "last_page_sig": None, "last_ai_sig": None, "last_ai_text": "", "last_related": [],
Â  Â  # Interactive Parsing & Twin Gen
Â  Â  "parsed_items": {}, "twin_items": {},
Â  Â  # Hot Page Navigation
Â  Â  "hot_pages": [], "hot_pages_analyzed": False, "analyzing_progress": 0,
Â  Â  # Tab 3 Results
Â  Â  "tr_res": None
    "logged_in": False, "db": [], "api_key": None, "api_key_ok": False,
    "text_models": [], "embedding_models": [], "best_text_model": None, "best_embedding_model": None,
    "lecture_doc": None, "lecture_filename": None, "current_page": 0,
    "edit_target_subject": None, "subject_detail_view": None, "t2_selected_subject": None,
    "transcribed_text": "", "chat_history": [],
    "last_page_sig": None, "last_ai_sig": None, "last_ai_text": "", "last_related": [],
    # Interactive Parsing
    "parsed_items": {}, "twin_items": {},
    # Hot Page Navigation
    "hot_pages": [], "hot_pages_analyzed": False
}

for k, v in defaults.items():
Â  Â  if k not in st.session_state:
Â  Â  Â  Â  st.session_state[k] = v
    if k not in st.session_state:
        st.session_state[k] = v

# ==========================================
# 2. Login Logic
# ==========================================
def login():
Â  Â  col1, col2, col3 = st.columns([1, 1, 1])
Â  Â  with col2:
Â  Â  Â  Â  st.markdown("<div style='height: 15vh;'></div>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown(
Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  <div style="text-align: center;">
Â  Â  Â  Â  Â  Â  Â  Â  <div class="login-logo">ğŸ©º</div>
Â  Â  Â  Â  Â  Â  Â  Â  <h1 style="font-weight: 800; margin-bottom: 0; color: #1c1c1e;">Med-Study OS</h1>
Â  Â  Â  Â  Â  Â  Â  Â  <p class="login-desc" style="color: #8e8e93; margin-bottom: 30px;">ë‹¹ì‹ ì˜ ìŠ¤ë§ˆíŠ¸í•œ ì˜ëŒ€ í•™ìŠµ íŒŒíŠ¸ë„ˆ</p>
Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  Â  """,Â 
Â  Â  Â  Â  Â  Â  unsafe_allow_html=True
Â  Â  Â  Â  )
Â  Â  Â  Â  with st.container(border=True):
Â  Â  Â  Â  Â  Â  st.markdown("#### ë¡œê·¸ì¸")
Â  Â  Â  Â  Â  Â  username = st.text_input("ì•„ì´ë””", placeholder="admin")
Â  Â  Â  Â  Â  Â  password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", placeholder="1234")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if st.button("ì•± ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
Â  Â  Â  Â  Â  Â  Â  Â  if password == "1234":
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.logged_in = True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤. (Demo: 1234)")
Â  Â  Â  Â  Â  Â  st.markdown("<div style='text-align:center; margin-top:15px; font-size:0.8rem; color:#c7c7cc;'>Demo Access: admin / 1234</div>", unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        st.markdown("<div style='height: 15vh;'></div>", unsafe_allow_html=True)
        st.markdown(
            """
            <div style="text-align: center;">
                <div class="login-logo">ğŸ©º</div>
                <h1 style="font-weight: 800; margin-bottom: 0; color: #1c1c1e;">Med-Study OS</h1>
                <p class="login-desc" style="color: #8e8e93; margin-bottom: 30px;">ë‹¹ì‹ ì˜ ìŠ¤ë§ˆíŠ¸í•œ ì˜ëŒ€ í•™ìŠµ íŒŒíŠ¸ë„ˆ</p>
            </div>
            """, 
            unsafe_allow_html=True
        )
        with st.container(border=True):
            st.markdown("#### ë¡œê·¸ì¸")
            username = st.text_input("ì•„ì´ë””", placeholder="admin")
            password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", placeholder="1234")
            
            if st.button("ì•± ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
                if password == "1234":
                    st.session_state.logged_in = True
                    st.rerun()
                else:
                    st.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤. (Demo: 1234)")
            st.markdown("<div style='text-align:center; margin-top:15px; font-size:0.8rem; color:#c7c7cc;'>Demo Access: admin / 1234</div>", unsafe_allow_html=True)

def logout():
Â  Â  st.session_state.logged_in = False
Â  Â  st.rerun()
    st.session_state.logged_in = False
    st.rerun()


# ==========================================
# 3. Helpers & Data Logic
# 3. Helpers & Data Logic (Smart Model Update)
# ==========================================
def ensure_configured():
Â  Â  if st.session_state.get("api_key"):
Â  Â  Â  Â  genai.configure(api_key=st.session_state["api_key"])
    if st.session_state.get("api_key"):
        genai.configure(api_key=st.session_state["api_key"])

@st.cache_data(show_spinner=False)
def list_available_models(api_key: str):
Â  Â  try:
Â  Â  Â  Â  genai.configure(api_key=api_key)
Â  Â  Â  Â  all_models = list(genai.list_models())
Â  Â  Â  Â  text_mods = [m.name for m in all_models if "generateContent" in getattr(m, "supported_generation_methods", [])]
Â  Â  Â  Â  embed_mods = [m.name for m in all_models if "embedContent" in getattr(m, "supported_generation_methods", [])]
Â  Â  Â  Â  return text_mods, embed_mods
Â  Â  except Exception as e:
Â  Â  Â  Â  return [], []
    try:
        genai.configure(api_key=api_key)
        all_models = list(genai.list_models())
        text_mods = [m.name for m in all_models if "generateContent" in getattr(m, "supported_generation_methods", [])]
        embed_mods = [m.name for m in all_models if "embedContent" in getattr(m, "supported_generation_methods", [])]
        return text_mods, embed_mods
    except Exception as e:
        return [], []

def get_best_model(models, keywords):
Â  Â  if not models: return None
Â  Â  for k in keywords:
Â  Â  Â  Â  found = [m for m in models if k in m]
Â  Â  Â  Â  if found: return found[0]
Â  Â  return models[0]
    if not models: return None
    for k in keywords:
        found = [m for m in models if k in m]
        if found: return found[0]
    return models[0]

def get_embedding_robust(text: str, status_placeholder=None):
Â  Â  text = (text or "").strip()
Â  Â  if len(text) < 50:Â 
Â  Â  Â  Â  return None, "text_too_short"
Â  Â  Â  Â Â 
Â  Â  text = text[:10000]
Â  Â  ensure_configured()
Â  Â Â 
Â  Â  if not st.session_state.embedding_models:
Â  Â  Â  Â  _, embs = list_available_models(st.session_state.api_key)
Â  Â  Â  Â  st.session_state.embedding_models = embs
Â  Â Â 
Â  Â  candidates = st.session_state.embedding_models
Â  Â  if not candidates:
Â  Â  Â  Â  return None, "No embedding models available."
Â  Â  Â  Â Â 
Â  Â  sorted_candidates = sorted(candidates, key=lambda x: 0 if 'text-embedding-004' in x else 1)
Â  Â Â 
Â  Â  max_retries = 3
Â  Â  for model_name in sorted_candidates[:2]:
Â  Â  Â  Â  for attempt in range(max_retries):
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(0.5)Â 
Â  Â  Â  Â  Â  Â  Â  Â  if "004" in model_name:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  res = genai.embed_content(model=model_name, content=text, task_type="retrieval_document")
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  res = genai.embed_content(model=model_name, content=text)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  if res and "embedding" in res:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return res["embedding"], None
Â  Â  Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  return None, "Embedding failed"
    text = (text or "").strip()
    if len(text) < 50: 
        return None, "text_too_short"
        
    text = text[:10000]
    ensure_configured()
    
    if not st.session_state.embedding_models:
        _, embs = list_available_models(st.session_state.api_key)
        st.session_state.embedding_models = embs
    
    candidates = st.session_state.embedding_models
    if not candidates:
        return None, "No embedding models available."
        
    sorted_candidates = sorted(candidates, key=lambda x: 0 if 'text-embedding-004' in x else 1)
    
    max_retries = 5
    base_wait = 3
    last_error_msg = ""

    for model_name in sorted_candidates[:2]:
        for attempt in range(max_retries):
            try:
                time.sleep(1.0) 
                if "004" in model_name:
                    res = genai.embed_content(model=model_name, content=text, task_type="retrieval_document")
                else:
                    res = genai.embed_content(model=model_name, content=text)
                    
                if res and "embedding" in res:
                    return res["embedding"], None
            
            except Exception as e:
                err_msg = str(e)
                last_error_msg = f"{model_name}: {err_msg}"
                
                if "429" in err_msg or "Resource exhausted" in err_msg:
                    wait_time = base_wait * (2 ** attempt) + random.randint(1, 3)
                    if status_placeholder:
                        status_placeholder.caption(f"âš ï¸ ì‚¬ìš©ëŸ‰ ë§ìŒ ({model_name}). {wait_time}ì´ˆ ëŒ€ê¸° ì¤‘... ({attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                elif "404" in err_msg or "Not Found" in err_msg:
                    break
                else:
                    time.sleep(1)
                    
    return None, f"Fail: {last_error_msg}"

def filter_db_by_subject(subject: str, db: list[dict]):
Â  Â  if not db: return []
Â  Â  if subject in ["ì „ì²´", "ALL", ""]: return db
Â  Â  return [x for x in db if x.get("subject") == subject]

def find_relevant_jokbo(query_text: str, db: list[dict], top_k: int = 5, threshold: float = 0.65):
Â  Â  if not db: return []
Â  Â  query_emb, _ = get_embedding_robust(query_text)
Â  Â  if not query_emb: return []
Â  Â Â 
Â  Â  valid_items = [item for item in db if item.get("embedding")]
Â  Â  if not valid_items: return []
Â  Â  db_embs = [item["embedding"] for item in valid_items]
Â  Â Â 
Â  Â  if len(db_embs) == 0: return []
Â  Â Â 
Â  Â  sims = cosine_similarity([query_emb], db_embs)[0]
Â  Â  top_idxs = np.argsort(sims)[::-1][:top_k]
Â  Â Â 
Â  Â  # [STRICT FILTERING] Threshold set to 0.65 (Adjustable)
Â  Â  # Only return items that are actually relevant
Â  Â  results = [{"score": float(sims[i]), "content": valid_items[i]} for i in top_idxs if sims[i] > threshold]
Â  Â  return results
    if not db: return []
    if subject in ["ì „ì²´", "ALL", ""]: return db
    return [x for x in db if x.get("subject") == subject]

def find_relevant_jokbo(query_text: str, db: list[dict], top_k: int = 5):
    if not db: return []
    query_emb, _ = get_embedding_robust(query_text)
    if not query_emb: return []
    
    valid_items = [item for item in db if item.get("embedding")]
    if not valid_items: return []
    db_embs = [item["embedding"] for item in valid_items]
    
    if len(db_embs) == 0: return []
    
    sims = cosine_similarity([query_emb], db_embs)[0]
    top_idxs = np.argsort(sims)[::-1][:top_k]
    return [{"score": float(sims[i]), "content": valid_items[i]} for i in top_idxs]

def generate_with_fallback(prompt: str, model_names: list[str]):
Â  Â  ensure_configured()
Â  Â  target_model = st.session_state.best_text_model or "gemini-1.5-flash"
Â  Â  candidates = [target_model]
Â  Â  if model_names: candidates.extend(model_names)
Â  Â  candidates = list(dict.fromkeys(candidates))
Â  Â  config = genai.GenerationConfig(temperature=0.3)
Â  Â Â 
Â  Â  for name in candidates:
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  model = genai.GenerativeModel(name, generation_config=config)
Â  Â  Â  Â  Â  Â  res = model.generate_content(prompt)
Â  Â  Â  Â  Â  Â  if res.text: return res.text, name
Â  Â  Â  Â  except Exception:Â 
Â  Â  Â  Â  Â  Â  continue
Â  Â  raise Exception("AI ì‘ë‹µ ì‹¤íŒ¨")
    ensure_configured()
    target_model = st.session_state.best_text_model or "gemini-1.5-flash"
    
    candidates = [target_model]
    if model_names: candidates.extend(model_names)
    candidates = list(dict.fromkeys(candidates))
    
    last_err = None
    config = genai.GenerationConfig(temperature=0.3)
    
    for name in candidates:
        try:
            model = genai.GenerativeModel(name, generation_config=config)
            res = model.generate_content(prompt)
            if res.text: return res.text, name
        except Exception as e: 
            last_err = e
            continue
    raise Exception(f"AI ì‘ë‹µ ì‹¤íŒ¨: {str(last_err)}")

def transcribe_audio_gemini(audio_bytes, api_key):
Â  Â  try:
Â  Â  Â  Â  genai.configure(api_key=api_key)
Â  Â  Â  Â  model = genai.GenerativeModel("gemini-1.5-flash")
Â  Â  Â  Â  response = model.generate_content([
Â  Â  Â  Â  Â  Â  "Please transcribe the following audio file into text accurately.",
Â  Â  Â  Â  Â  Â  {"mime_type": "audio/wav", "data": audio_bytes}
Â  Â  Â  Â  ])
Â  Â  Â  Â  return response.text
Â  Â  except Exception: return None
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content([
            "Please transcribe the following audio file into text accurately. Do not add any conversational text, just the transcription.",
            {"mime_type": "audio/wav", "data": audio_bytes}
        ])
        return response.text
    except Exception as e:
        st.error(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
        return None

def transcribe_image_to_text(image, api_key):
Â  Â  try:
Â  Â  Â  Â  genai.configure(api_key=api_key)
Â  Â  Â  Â  model = genai.GenerativeModel("gemini-1.5-flash")
Â  Â  Â  Â  response = model.generate_content(["Extract text.", image])
Â  Â  Â  Â  return response.text
Â  Â  except Exception: return None
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content([
            "Extract all text from this image exactly as is. Just the text, no comments.",
            image
        ])
        return response.text
    except Exception:
        return None

# ==========================================
# 4. LLM Logic (Parser & Generator)
# 4. New LLM Logic (Parser & Generator)
# ==========================================

def split_jokbo_text(text):
Â  Â  if not text: return []
Â  Â  pattern = r'(?:\n|^)\s*(?=\d+[\.\)])'
Â  Â  parts = re.split(pattern, text)
Â  Â  questions = [p.strip() for p in parts if p.strip()]
Â  Â  return questions
    """
    ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸í•­ ë²ˆí˜¸(1. 24. 15) ë“±ì„ ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    (ì˜ˆ: 24. DNA... -> [24. DNA...])
    """
    if not text: return []
    # Pattern: Start of line or text + whitespace + Number + dot or parenthesis
    # Uses Lookahead to split BEFORE the number, keeping the number in the resulting chunks
    pattern = r'(?:\n|^)\s*(?=\d+[\.\)])'
    
    parts = re.split(pattern, text)
    # Filter empty strings and strip whitespace
    questions = [p.strip() for p in parts if p.strip()]
    return questions

def parse_raw_jokbo_llm(raw_text):
Â  Â  prompt = f"""
Â  Â  Analyze this exam question text. Structure it into JSON.
Â  Â  [Text] {raw_text}
Â  Â  [Format] JSON with keys: question, choices(list), answer, explanation.
Â  Â  """
Â  Â  try:
Â  Â  Â  Â  res_text, _ = generate_with_fallback(prompt, st.session_state.text_models)
Â  Â  Â  Â  clean_text = re.sub(r"```json|```", "", res_text).strip()
Â  Â  Â  Â  parsed = json.loads(clean_text)
Â  Â  Â  Â  return {"success": True, "data": parsed}
Â  Â  except Exception as e:
Â  Â  Â  Â  return {"success": False, "error": str(e)}
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ì—‰ë§ì¸ ì¡±ë³´ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜
    """
    prompt = f"""
    You are an expert exam data parser.
    Analyze the following raw text which may contain a mix of questions, choices, answers, and explanations.
    Structure it into a clean JSON object.
    
    [Raw Text]
    {raw_text}
    
    [Requirements]
    1. Extract the 'question' (main problem text).
    2. Extract 'choices' as a list of strings if it's a multiple choice question.
    3. Extract 'answer' if present.
    4. Extract 'explanation' if present.
    5. Detect 'type' ("ê°ê´€ì‹" or "ì£¼ê´€ì‹").
    6. Return ONLY the JSON object. Do not include markdown formatting like ```json.
    """
    
    try:
        res_text, _ = generate_with_fallback(prompt, st.session_state.text_models)
        # Clean up code blocks if model adds them
        clean_text = re.sub(r"```json|```", "", res_text).strip()
        parsed = json.loads(clean_text)
        return {"success": True, "data": parsed}
    except Exception as e:
        return {"success": False, "error": str(e)}

def generate_twin_problem_llm(parsed_data, subject):
Â  Â  data = parsed_data["data"]
Â  Â  prompt = f"""
Â  Â  Create a 'Twin Problem' (similar logic, different values/scenario) for:
Â  Â  Subject: {subject}
Â  Â  Original: {json.dumps(data, ensure_ascii=False)}
Â  Â  Output Format (Markdown):
Â  Â  ### Question
Â  Â  ...
Â  Â  ### Answer
Â  Â  ...
Â  Â  ### Explanation
Â  Â  ...
Â  Â  """
Â  Â  try:
Â  Â  Â  Â  res_text, _ = generate_with_fallback(prompt, st.session_state.text_models)
Â  Â  Â  Â  return res_text
Â  Â  except Exception as e:
Â  Â  Â  Â  return f"ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {str(e)}"
    """
    êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìŒë‘¥ì´ ë¬¸ì œ(ë³€í˜• ë¬¸ì œ) ìƒì„±
    """
    data = parsed_data["data"]
    prompt = f"""
    Create a 'Twin Problem' for medical students based on the following exam data.
    Subject: {subject}
    
    [Original Problem Data]
    {json.dumps(data, ensure_ascii=False)}
    
    [Instructions]
    1. Create a NEW problem with the same logic, difficulty, and concept.
    2. Change the scenario, values, or clinical case slightly so it's not identical.
    3. Provide the correct answer and a detailed logic explanation.
    
    [Output Format]
    **[ë³€í˜• ë¬¸ì œ]**
    (Question Text)
    (Choices if applicable)
    
    **[ì •ë‹µ ë° í•´ì„¤]**
    **ì •ë‹µ:** (Answer)
    **í•´ì„¤:** (Detailed Logic)
    """
    
    try:
        res_text, _ = generate_with_fallback(prompt, st.session_state.text_models)
        return res_text
    except Exception as e:
        return f"ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {str(e)}"

# ==========================================
# 5. Prompts
# ==========================================
def build_chat_prompt(history, context, related, q):
Â  Â  ctx = "\n".join([f"- {r['content']['text'][:200]}" for r in related[:2]])
Â  Â  return f"""
Â  Â  [ê°•ì˜] {context[:800]}
Â  Â  [ì¡±ë³´] {ctx}
Â  Â  [ì§ˆë¬¸] {q}
Â  Â  ë‹µë³€í•´.
Â  Â  """

def build_transcript_prompt(chunks, related_packs, subject):
Â  Â  packed = ""
Â  Â  for idx, (chunk, rel) in enumerate(zip(chunks, related_packs), 1):
Â  Â  Â  Â  if not rel or rel[0]["score"] < 0.6: continue
Â  Â  Â  Â  ctx = "\n".join([f"- {r['content']['text'][:200]}" for r in rel[:2]])
Â  Â  Â  Â  packed += f"\n(êµ¬ê°„ {idx})\n[ê°•ì˜] {chunk}\n[ì¡±ë³´ê·¼ê±°] {ctx}\n"
Â  Â  return f"ê°•ì˜ ì „ì‚¬ ë‚´ìš©ì„ ì¡±ë³´ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n{packed}"

def chunk_transcript(text):
Â  Â  return [text[i:i+900] for i in range(0, len(text), 900)]
# --- Prompt Builders (Improved with Persona) ---
def build_overview_prompt(first_page_text, subject):
    return f"""
    ë„ˆëŠ” ì˜ëŒ€ ìˆ˜ì„ ì¡°êµë‹¤. ì§€ê¸ˆ í•™ìƒì´ '{subject}' ê°•ì˜ë¡ì˜ ì²« í˜ì´ì§€(í‘œì§€/ëª©ì°¨)ë¥¼ ë³´ê³  ìˆë‹¤.
    ì´ ê°•ì˜ë¡ ì „ì²´ë¥¼ ê³µë¶€í•  ë•Œ ì–´ë–¤ ë§ˆìŒê°€ì§ê³¼ ì „ëµì„ ê°€ì ¸ì•¼ í•˜ëŠ”ì§€, ì¡±ë³´(ê¸°ì¶œ) íŒ¨í„´ì„ ê³ ë ¤í•˜ì—¬ ì¡°ì–¸í•´ë¼.
    
    [ê°•ì˜ë¡ ì²« í˜ì´ì§€ ë‚´ìš©]
    {first_page_text[:1500]}
    
    ì¶œë ¥ í˜•ì‹:
    1. ğŸ ì´ ê°•ì˜ì˜ í•µì‹¬ ëª©í‘œ (í•œ ì¤„)
    2. ğŸš© ì¡±ë³´ ê¸°ë°˜ ê³µë¶€ ì „ëµ (3ê°€ì§€ í¬ì¸íŠ¸)
    3. âš ï¸ ì£¼ì˜í•´ì•¼ í•  ì 
    """

def build_chat_prompt(history: list, context_text: str, related_jokbo: list, question: str):
    jokbo_ctx = "\n".join([f"- {r['content']['text'][:300]}" for r in related_jokbo[:3]])
    return f"""
    ë‹¹ì‹ ì€ ì˜ëŒ€ ì¡°êµì…ë‹ˆë‹¤. í•™ìƒì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
    [í˜„ì¬ ë³´ê³  ìˆëŠ” ê°•ì˜ ë‚´ìš©] {context_text[:1000]}
    [ê´€ë ¨ ì¡±ë³´/ê¸°ì¶œ ë‚´ìš©] {jokbo_ctx}
    [í•™ìƒ ì§ˆë¬¸] {question}
    ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ, ì¡±ë³´ ë‚´ìš©ì´ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ê·¼ê±°ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    """

def build_transcript_prompt(chunks: list[str], related_packs: list[list[dict]], subject: str):
    packed = ""
    for idx, (chunk, rel) in enumerate(zip(chunks, related_packs), 1):
        if not has_jokbo_evidence(rel): continue
        ctx = "\n".join([f"- {r['content']['text'][:200]}" for r in rel[:2]])
        packed += f"\n(êµ¬ê°„ {idx})\n[ê°•ì˜] {chunk}\n[ì¡±ë³´ê·¼ê±°] {ctx}\n"
    if not packed: return "ì¡±ë³´ì™€ ê´€ë ¨ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
    return f"""
    ë‹¹ì‹ ì€ ì˜ëŒ€ ì¡°êµì…ë‹ˆë‹¤. ê°•ì˜ ì „ì‚¬ ë‚´ìš©ì„ ì¡±ë³´ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
    ê³¼ëª©: {subject}
    {packed}
    ì¶œë ¥: [ì¡±ë³´ ì ì¤‘ ë…¸íŠ¸] í˜•ì‹ìœ¼ë¡œ ìš”ì•½.
    """

def chunk_transcript(text: str, max_chars: int = 900):
    parts = [p.strip() for p in re.split(r"\n\s*\n", text) if p.strip()]
    chunks = []
    for p in parts:
        if len(p) <= max_chars: chunks.append(p)
        else:
            for i in range(0, len(p), max_chars):
                chunks.append(p[i:i+max_chars])
    return chunks

def format_jokbo_text(text):
    if not text: return ""
    formatted = re.sub(r'(?<!\d)(\d+\.)\s+', r'\n\n**\1** ', text)
    return formatted.strip()

def rename_subject(old_name, new_name):
    count = 0
    for item in st.session_state.db:
        if item.get("subject") == old_name:
            item["subject"] = new_name
            count += 1
    return count

def get_subject_stats():
Â  Â  stats = {}
Â  Â  for item in st.session_state.db:
Â  Â  Â  Â  subj = item.get("subject", "ê¸°íƒ€")
Â  Â  Â  Â  if subj not in stats: stats[subj] = {"count": 0, "last_updated": "ë°©ê¸ˆ ì „"}
Â  Â  Â  Â  stats[subj]["count"] += 1
Â  Â  return stats
    stats = {}
    for item in st.session_state.db:
        subj = item.get("subject", "ê¸°íƒ€")
        if subj not in stats:
            rand_min = random.randint(1, 59)
            stats[subj] = {"count": 0, "last_updated": f"{rand_min}ë¶„ ì „"}
        stats[subj]["count"] += 1
    return stats

def get_subject_files(subject):
Â  Â  files = {}
Â  Â  for item in st.session_state.db:
Â  Â  Â  Â  if item.get("subject") == subject:
Â  Â  Â  Â  Â  Â  src = item.get("source", "Unknown")
Â  Â  Â  Â  Â  Â  files[src] = files.get(src, 0) + 1
Â  Â  return files
    files = {}
    for item in st.session_state.db:
        if item.get("subject") == subject:
            src = item.get("source", "Unknown")
            files[src] = files.get(src, 0) + 1
    return files

def has_jokbo_evidence(related: list[dict]) -> bool:
    return bool(related) and related[0]["score"] >= 0.70


# ==========================================
# 6. Main App UI
# 4. Main App UI
# ==========================================

# ë¡œê·¸ì¸ ì²´í¬
if not st.session_state.logged_in:
Â  Â  login()
Â  Â  st.stop()
    login()
    st.stop()

# --- Sidebar ---
# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
Â  Â  st.markdown("### ğŸ‘¤ ë‚´ í”„ë¡œí•„")
Â  Â  with st.container(border=True):
Â  Â  Â  Â  st.markdown("## ğŸ‘¨â€âš•ï¸ **Student Admin**")
Â  Â  Â  Â  if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True): logout()

Â  Â  st.markdown("### ğŸ“š ë‚´ í•™ìŠµ ê³¼ëª©")
Â  Â  my_subjects = sorted({x.get("subject", "ê¸°íƒ€") for x in st.session_state.db})
Â  Â  if my_subjects:
Â  Â  Â  Â  for s in my_subjects:
Â  Â  Â  Â  Â  Â  st.markdown(f"<div class='sidebar-subject'>ğŸ“˜ {s}</div>", unsafe_allow_html=True)
Â  Â  else: st.caption("ë“±ë¡ëœ ê³¼ëª© ì—†ìŒ")
Â  Â  st.divider()

Â  Â  st.markdown("### âš™ï¸ ì„¤ì •")
Â  Â  with st.container(border=True):
Â  Â  Â  Â  api_key_input = st.text_input("Gemini API Key", type="password", key="api_key_input")
Â  Â  Â  Â  if api_key_input: st.session_state.api_key = api_key_input.strip()
Â  Â  Â  Â  if st.button("ğŸ”„ ì—°ê²° í…ŒìŠ¤íŠ¸", use_container_width=True):
Â  Â  Â  Â  Â  Â  if st.session_state.api_key:
Â  Â  Â  Â  Â  Â  Â  Â  t_mods, e_mods = list_available_models(st.session_state.api_key)
Â  Â  Â  Â  Â  Â  Â  Â  if t_mods:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.api_key_ok = True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.text_models = t_mods
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.embedding_models = e_mods
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.best_text_model = get_best_model(t_mods, ["flash", "pro"])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("ì—°ê²° ì„±ê³µ!")
Â  Â  Â  Â  Â  Â  Â  Â  else: st.error("ëª¨ë¸ ê²€ìƒ‰ ì‹¤íŒ¨")

Â  Â  st.markdown("### ğŸ“Š DB í˜„í™©")
Â  Â  with st.container(border=True):
Â  Â  Â  Â  st.metric("ì´ í•™ìŠµ í˜ì´ì§€", len(st.session_state.db))
Â  Â  Â  Â  if st.button("DB ì´ˆê¸°í™”"):
Â  Â  Â  Â  Â  Â  st.session_state.db = []
Â  Â  Â  Â  Â  Â  st.rerun()

# --- Main ---
    st.markdown("### ğŸ‘¤ ë‚´ í”„ë¡œí•„")
    with st.container(border=True):
        col_p1, col_p2 = st.columns([1, 3])
        with col_p1: st.markdown("## ğŸ‘¨â€âš•ï¸")
        with col_p2:
            st.markdown("**Student Admin**")
            st.caption("ë³¸ê³¼ 2í•™ë…„")
        if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True): logout()

    # --- ë‚´ í•™ìŠµ ê³¼ëª© ë¦¬ìŠ¤íŠ¸ ---
    st.markdown("### ğŸ“š ë‚´ í•™ìŠµ ê³¼ëª©")
    my_subjects = sorted({x.get("subject", "ê¸°íƒ€") for x in st.session_state.db})
    if my_subjects:
        for s in my_subjects:
            st.markdown(
                f"""
                <div class="sidebar-subject">
                    <span class="sidebar-icon">ğŸ“˜</span> {s}
                </div>
                """, 
                unsafe_allow_html=True
            )
    else:
        st.caption("ì•„ì§ ë“±ë¡ëœ ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.divider()

    st.markdown("### âš™ï¸ ì„¤ì •")
    with st.container(border=True):
        api_key_input = st.text_input("Gemini API Key", type="password", key="api_key_input")
        if api_key_input:
            st.session_state.api_key = api_key_input.strip()
            
        if st.button("ğŸ”„ ëª¨ë¸ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° (ì—°ê²° í…ŒìŠ¤íŠ¸)", use_container_width=True):
            if not st.session_state.api_key:
                st.error("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with st.spinner("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì°¾ëŠ” ì¤‘..."):
                    t_mods, e_mods = list_available_models(st.session_state.api_key)
                    
                    if t_mods and e_mods:
                        st.session_state.api_key_ok = True
                        st.session_state.text_models = t_mods
                        st.session_state.embedding_models = e_mods
                        
                        st.session_state.best_text_model = get_best_model(t_mods, ["flash", "pro"])
                        st.session_state.best_embedding_model = get_best_model(e_mods, ["text-embedding-004", "004"])
                        
                        st.success(f"âœ… ì—°ê²° ì„±ê³µ!")
                        st.caption(f"í…ìŠ¤íŠ¸ ëª¨ë¸: {st.session_state.best_text_model}")
                        st.caption(f"ì„ë² ë”© ëª¨ë¸: {st.session_state.best_embedding_model}")
                    else:
                        st.error("ğŸš« ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (API Key ê¶Œí•œ í™•ì¸)")
            
    st.markdown("### ğŸ“Š DB í˜„í™©")
    with st.container(border=True):
        st.metric("ì´ í•™ìŠµ í˜ì´ì§€", len(st.session_state.db))
        if st.button("DB ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.db = []
            st.rerun()

# --- ë©”ì¸ ì½˜í…ì¸  ---
st.title("Med-Study OS")
tab1, tab2, tab3 = st.tabs(["ğŸ“‚ ì¡±ë³´ ê´€ë¦¬", "ğŸ“– ê°•ì˜ ë¶„ì„", "ğŸ™ï¸ ê°•ì˜ ë…¹ìŒ"])

tab1, tab2, tab3 = st.tabs(["ğŸ“‚ ì¡±ë³´ ê´€ë¦¬", "ğŸ“– ê°•ì˜ ë¶„ì„", "ğŸ™ï¸ ê°•ì˜ ë…¹ìŒ/ë¶„ì„"])

# --- TAB 1: ì¡±ë³´ ê´€ë¦¬ ---
with tab1:
Â  Â  col_u, col_l = st.columns([1, 2])
Â  Â  with col_u:
Â  Â  Â  Â  with st.container(border=True):
Â  Â  Â  Â  Â  Â  st.markdown("#### â• ì¡±ë³´ ì¶”ê°€")
Â  Â  Â  Â  Â  Â  subj = st.text_input("ê³¼ëª©ëª…", "í•´ë¶€í•™")
Â  Â  Â  Â  Â  Â  files = st.file_uploader("PDF ì—…ë¡œë“œ", accept_multiple_files=True, type="pdf")
Â  Â  Â  Â  Â  Â  if st.button("í•™ìŠµ ì‹œì‘", type="primary", use_container_width=True):
Â  Â  Â  Â  Â  Â  Â  Â  if not st.session_state.api_key_ok: st.error("API Key í•„ìš”")
Â  Â  Â  Â  Â  Â  Â  Â  elif files:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prog = st.progress(0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for i, f in enumerate(files):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  doc = fitz.open(stream=f.getvalue(), filetype="pdf")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for p_idx, page in enumerate(doc):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  txt = page.get_text().strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if len(txt) < 50:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pix = page.get_pixmap()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ocr = transcribe_image_to_text(img, st.session_state.api_key)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if ocr: txt = ocr
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except: pass
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  emb, _ = get_embedding_robust(txt)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if emb:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.db.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "page": p_idx+1, "text": txt, "source": f.name, "embedding": emb, "subject": subj
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prog.progress((i+1)/len(files))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("í•™ìŠµ ì™„ë£Œ!")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  with col_l:
Â  Â  Â  Â  st.markdown("#### ğŸ“š í•™ìŠµëœ ë°ì´í„°")
Â  Â  Â  Â  stats = get_subject_stats()
Â  Â  Â  Â  cols = st.columns(3)
Â  Â  Â  Â  for i, (s, d) in enumerate(stats.items()):
Â  Â  Â  Â  Â  Â  with cols[i%3]:
Â  Â  Â  Â  Â  Â  Â  Â  st.metric(label=s, value=f"{d['count']} pages")

# --- TAB 2: ê°•ì˜ ë¶„ì„ (Clean & Strict) ---
    if st.session_state.subject_detail_view:
        target_subj = st.session_state.subject_detail_view
        c_back, c_title = st.columns([1, 5])
        with c_back:
            if st.button("â† ëª©ë¡", use_container_width=True):
                st.session_state.subject_detail_view = None
                st.rerun()
        with c_title: st.markdown(f"### ğŸ“‚ {target_subj} - íŒŒì¼ ëª©ë¡")
        st.divider()
        file_map = get_subject_files(target_subj)
        if not file_map: st.info("ì´ ê³¼ëª©ì— ë“±ë¡ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for fname, count in file_map.items():
                with st.container(border=True):
                    c_f1, c_f2 = st.columns([4, 1])
                    with c_f1: st.markdown(f"**ğŸ“„ {fname}**")
                    with c_f2: st.caption(f"{count} pages")
    else:
        col_upload, col_list = st.columns([1, 2])
        with col_upload:
            with st.container(border=True):
                st.markdown("#### â• ì¡±ë³´ ì¶”ê°€")
                st.caption("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ AI í•™ìŠµ")
                up_subj = st.selectbox("ê³¼ëª©", ["í•´ë¶€í•™", "ìƒë¦¬í•™", "ì•½ë¦¬í•™", "ì§ì ‘ì…ë ¥"], key="up_subj")
                if up_subj == "ì§ì ‘ì…ë ¥":
                    up_subj_custom = st.text_input("ê³¼ëª©ëª… ì…ë ¥", placeholder="ì˜ˆ: ë³‘ë¦¬í•™")
                    final_subj = up_subj_custom if up_subj_custom else "ê¸°íƒ€"
                else: final_subj = up_subj
                
                files = st.file_uploader("PDF ì„ íƒ", accept_multiple_files=True, type="pdf", label_visibility="collapsed")
                
                if st.button("í•™ìŠµ ì‹œì‘", type="primary", use_container_width=True):
                    if not st.session_state.api_key_ok: st.error("ì™¼ìª½ ì„¤ì •ì—ì„œ 'ëª¨ë¸ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°'ë¥¼ ë¨¼ì € í•´ì£¼ì„¸ìš”!")
                    elif not files: st.warning("íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    else:
                        prog_bar = st.progress(0)
                        
                        with st.expander("ğŸ“ ì²˜ë¦¬ ë¡œê·¸ ë³´ê¸° (í´ë¦­í•˜ì—¬ í¼ì¹˜ê¸°)", expanded=True):
                            log_container = st.empty()
                            logs = []
                            
                            def log(msg):
                                logs.append(msg)
                                log_container.markdown("\n".join([f"- {l}" for l in logs[-5:]]))

                            new_db = []
                            total_files = len(files)
                            
                            for i, f in enumerate(files):
                                try:
                                    log(f"ğŸ“‚ **{f.name}** ë¶„ì„ ì‹œì‘...")
                                    doc = fitz.open(stream=f.getvalue(), filetype="pdf")
                                    total_pages = len(doc)
                                    success_cnt = 0
                                    skip_cnt = 0
                                    
                                    for p_idx, page in enumerate(doc):
                                        log_container.markdown(f"â³ **{f.name}** ì²˜ë¦¬ ì¤‘... ({p_idx + 1}/{total_pages} í˜ì´ì§€)")
                                        
                                        text = page.get_text().strip()
                                        
                                        if len(text) < 50:
                                            try:
                                                pix = page.get_pixmap()
                                                img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                                                ocr_text = transcribe_image_to_text(img, st.session_state.api_key)
                                                if ocr_text:
                                                    text = ocr_text
                                                    log(f"âœ¨ P.{p_idx+1}: ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ!")
                                            except Exception:
                                                pass

                                        emb, err_msg = get_embedding_robust(text, status_placeholder=st.empty())
                                        
                                        if emb:
                                            p_data = {
                                                "page": p_idx + 1,
                                                "text": text,
                                                "source": f.name,
                                                "embedding": emb,
                                                "subject": final_subj
                                            }
                                            new_db.append(p_data)
                                            success_cnt += 1
                                        elif err_msg == "text_too_short":
                                            skip_cnt += 1
                                            log(f"âš ï¸ P.{p_idx+1}: ë‚´ìš© ì—†ìŒ (ìŠ¤í‚µ)")
                                        else:
                                            log(f"âŒ P.{p_idx+1} ì„ë² ë”© ì‹¤íŒ¨ ({err_msg})")
                                    
                                    log(f"âœ… **{f.name}** ì™„ë£Œ: ì„±ê³µ {success_cnt}, ìŠ¤í‚µ {skip_cnt}")
                                    
                                except Exception as e:
                                    log(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                                
                                prog_bar.progress((i + 1) / total_files)
                            
                            if new_db:
                                st.session_state.db.extend(new_db)
                                st.success(f"ğŸ‰ ì´ {len(new_db)} í˜ì´ì§€ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                                time.sleep(1.5)
                                st.rerun()
                            else:
                                st.warning("ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë¬¸ì„œì— í…ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.)")
                        
        with col_list:
            st.markdown("#### ğŸ“š ë‚´ í•™ìŠµ ë°ì´í„°")
            stats = get_subject_stats()
            if not stats: st.info("ë“±ë¡ëœ ì¡±ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ì™¼ìª½ì—ì„œ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            subjects = sorted(stats.keys())
            
            for i in range(0, len(subjects), 2):
                cols = st.columns(2)
                for j in range(2):
                    if i + j < len(subjects):
                        subj_name = subjects[i+j]
                        subj_data = stats[subj_name]
                        with cols[j]:
                            with st.container(border=True):
                                c_head_1, c_head_2 = st.columns([4, 1])
                                is_editing = (st.session_state.edit_target_subject == subj_name)
                                with c_head_1:
                                    if is_editing: new_name_input = st.text_input("ìƒˆ ì´ë¦„", value=subj_name, key=f"edit_in_{subj_name}", label_visibility="collapsed")
                                    else:
                                        if st.button(f"## {subj_name}", key=f"btn_view_{subj_name}", help="í´ë¦­í•˜ì—¬ íŒŒì¼ ëª©ë¡ ë³´ê¸°"):
                                            st.session_state.subject_detail_view = subj_name
                                            st.rerun()
                                with c_head_2:
                                    if is_editing:
                                        if st.button("ğŸ’¾", key=f"save_{subj_name}"):
                                            if new_name_input and new_name_input != subj_name:
                                                rename_subject(subj_name, new_name_input)
                                            st.session_state.edit_target_subject = None
                                            st.rerun()
                                    else:
                                        if st.button("âœï¸", key=f"edit_btn_{subj_name}"):
                                            st.session_state.edit_target_subject = subj_name
                                            st.rerun()
                                if not is_editing:
                                    st.markdown("---")
                                    st.markdown(f"**âš¡ ë¶„ì„ëœ íŒ¨í„´:** {subj_data['count']}ê±´")
                                    st.markdown(f"<span class='gray-text'>ğŸ•’ {subj_data['last_updated']}</span>", unsafe_allow_html=True)

# --- TAB 2: ê°•ì˜ ë¶„ì„ (Original Rich UI + New Logic) ---
with tab2:
Â  Â  if st.session_state.t2_selected_subject is None:
Â  Â  Â  Â  st.markdown("#### ğŸ“– í•™ìŠµí•  ê³¼ëª© ì„ íƒ")
Â  Â  Â  Â  subjects = sorted(list({x["subject"] for x in st.session_state.db}))
Â  Â  Â  Â  if not subjects: st.info("ì¡±ë³´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
Â  Â  Â  Â  cols = st.columns(3)
Â  Â  Â  Â  for i, s in enumerate(subjects):
Â  Â  Â  Â  Â  Â  with cols[i%3]:
Â  Â  Â  Â  Â  Â  Â  Â  if st.button(f"ğŸ“˜ {s}", use_container_width=True):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.t2_selected_subject = s
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  else:
Â  Â  Â  Â  # Header
Â  Â  Â  Â  c_bk, c_hd = st.columns([1, 5])
Â  Â  Â  Â  if c_bk.button("â† ë’¤ë¡œ"):Â 
Â  Â  Â  Â  Â  Â  st.session_state.t2_selected_subject = None
Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  c_hd.markdown(f"#### ğŸ“– {st.session_state.t2_selected_subject} - ìë™ ë¶„ì„ ëª¨ë“œ")

Â  Â  Â  Â  # PDF Upload
Â  Â  Â  Â  with st.expander("ğŸ“‚ ê°•ì˜ PDF íŒŒì¼ ì—´ê¸°", expanded=not st.session_state.lecture_doc):
Â  Â  Â  Â  Â  Â  l_file = st.file_uploader("ê°•ì˜ë¡ ì„ íƒ", type="pdf", key="l_pdf")
Â  Â  Â  Â  Â  Â  if l_file and l_file.name != st.session_state.lecture_filename:
Â  Â  Â  Â  Â  Â  Â  Â  # Reset State for new file
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.lecture_doc = fitz.open(stream=l_file.getvalue(), filetype="pdf")
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.lecture_filename = l_file.name
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.current_page = 0
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.last_page_sig = None
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.parsed_items = {}
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.twin_items = {}
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.hot_pages = []
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.hot_pages_analyzed = False
Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()

Â  Â  Â  Â  if st.session_state.lecture_doc:
Â  Â  Â  Â  Â  Â  doc = st.session_state.lecture_doc
Â  Â  Â  Â  Â  Â  target_subj = st.session_state.t2_selected_subject

Â  Â  Â  Â  Â  Â  # --- Hot Page Analysis (Background) ---
Â  Â  Â  Â  Â  Â  if not st.session_state.hot_pages_analyzed:
Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("ğŸš€ íŒŒì¼ ë¡œë“œ ì™„ë£Œ. ì ì¤‘ í˜ì´ì§€ ë¶„ì„ ì¤‘..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sub_db = filter_db_by_subject(target_subj, st.session_state.db)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if sub_db:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  valid_items = [x for x in sub_db if x.get("embedding")]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  db_embs = [x["embedding"] for x in valid_items]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  results = []
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for p_idx in range(len(doc)):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  page = doc.load_page(p_idx)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  txt = page.get_text().strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if len(txt) > 30:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  emb, _ = get_embedding_robust(txt)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if emb:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sims = cosine_similarity([emb], db_embs)[0]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  max_score = max(sims)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if max_score >= 0.75: # High threshold
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  results.append({"page": p_idx, "score": max_score})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except: pass
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.hot_pages = sorted(results, key=lambda x: x["score"], reverse=True)[:20]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.hot_pages_analyzed = True
Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()

Â  Â  Â  Â  Â  Â  # --- Hot Page Navigation (Hidden by default to be cleaner) ---
Â  Â  Â  Â  Â  Â  with st.expander(f"ğŸ”¥ ì ì¤‘ í˜ì´ì§€ íƒìƒ‰ê¸° ({len(st.session_state.hot_pages)} pages found)", expanded=False):
Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.hot_pages:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cols = st.columns(10)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for i, item in enumerate(st.session_state.hot_pages):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if i < 20:Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with cols[i%10]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.button(f"P.{item['page']+1}", key=f"nav_{item['page']}", help=f"ì ì¤‘ë¥  {item['score']:.0%}"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.current_page = item['page']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.caption("ì ì¤‘ë¥  ë†’ì€ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

Â  Â  Â  Â  Â  Â  st.divider()

Â  Â  Â  Â  Â  Â  # --- Main Viewer ---
Â  Â  Â  Â  Â  Â  col_view, col_ai = st.columns([1, 1])
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # LEFT: Viewer
Â  Â  Â  Â  Â  Â  with col_view:
Â  Â  Â  Â  Â  Â  Â  Â  c1, c2, c3 = st.columns([1, 2, 1])
Â  Â  Â  Â  Â  Â  Â  Â  if c1.button("â—€ Prev"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.current_page > 0:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.current_page -= 1
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  c2.markdown(f"<div style='text-align:center;'>Page {st.session_state.current_page+1}</div>", unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  if c3.button("Next â–¶"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.current_page < len(doc)-1:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.current_page += 1
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  page = doc.load_page(st.session_state.current_page)
Â  Â  Â  Â  Â  Â  Â  Â  pix = page.get_pixmap(dpi=150)
Â  Â  Â  Â  Â  Â  Â  Â  img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
Â  Â  Â  Â  Â  Â  Â  Â  p_text = page.get_text().strip()
Â  Â  Â  Â  Â  Â  Â  Â  st.image(img, use_container_width=True)

Â  Â  Â  Â  Â  Â  # RIGHT: Analysis
Â  Â  Â  Â  Â  Â  with col_ai:
Â  Â  Â  Â  Â  Â  Â  Â  ai_tab_match, ai_tab_chat = st.tabs(["ğŸ“ ì¡±ë³´ ë§¤ì¹­", "ğŸ’¬ AI íŠœí„°"])
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  with ai_tab_match:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # 1. Calculate Relevant Items
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not p_text:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” í˜ì´ì§€ì…ë‹ˆë‹¤.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  psig = hash(p_text)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if psig != st.session_state.last_page_sig:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.last_page_sig = psig
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sub_db = filter_db_by_subject(target_subj, st.session_state.db)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # STRICT THRESHOLD: 0.65
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.last_related = find_relevant_jokbo(p_text, sub_db, threshold=0.65)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rel = st.session_state.last_related
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # 2. Toggle to Show ALL
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  show_all = st.checkbox("ğŸ“‚ ì „ì²´ ì¡±ë³´ ë³´ê¸° (View All Questions)", value=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if show_all:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Show all items for this subject
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_db = filter_db_by_subject(target_subj, st.session_state.db)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"**ì „ì²´ ë¬¸í•­ ({len(all_db)}ê°œ)**")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for item in all_db:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  raw_txt = item['text']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  questions = split_jokbo_text(raw_txt)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not questions: questions = [raw_txt]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for q in questions:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"""
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div style="border:1px solid #ddd; padding:10px; border-radius:8px; margin-bottom:5px; background:white;">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <small>{item['source']} P.{item['page']}</small><br>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {q[:200]}...
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  """, unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # 3. Default View: Only Relevant Items
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not rel:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("ğŸ’¡ ì´ í˜ì´ì§€ì™€ ì§ì ‘ ì—°ê´€ëœ ì¡±ë³´ ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.caption("(ìš°ì¸¡ ìƒë‹¨ 'ì „ì²´ ì¡±ë³´ ë³´ê¸°'ë¥¼ ì²´í¬í•˜ë©´ ëª¨ë“  ë¬¸ì œë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"ğŸ”¥ **{len(rel)}ê°œì˜ ê´€ë ¨ ì¡±ë³´ ë¬¸í•­ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.**")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for i, r in enumerate(rel):Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  content = r['content']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  score = r['score']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  raw_txt = content['text']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  questions = split_jokbo_text(raw_txt)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not questions: questions = [raw_txt]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for q_idx, q_txt in enumerate(questions):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  item_id = f"{psig}_{i}_{q_idx}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Display Card
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"""
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="exam-card">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="exam-meta">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span><span class="exam-score-badge">ìœ ì‚¬ë„ {score:.0%}</span> &nbsp; {content['source']} (P.{content['page']})</span>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="exam-question">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {q_txt[:500] + ('...' if len(q_txt)>500 else '')}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  """, unsafe_allow_html=True)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Instant Auto-Analysis
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if item_id not in st.session_state.parsed_items:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner(f"âš¡ ë¬¸í•­ ë¶„ì„ ì¤‘..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parsed = parse_raw_jokbo_llm(q_txt)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.parsed_items[item_id] = parsed
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if parsed["success"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  twin = generate_twin_problem_llm(parsed, target_subj)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.twin_items[item_id] = twin
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Render Results
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if item_id in st.session_state.parsed_items:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parsed = st.session_state.parsed_items[item_id]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if parsed["success"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  d = parsed["data"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  t_ans, t_twin = st.tabs(["ğŸ’¡ ì •ë‹µ ë° í•´ì„¤", "ğŸ§© ìŒë‘¥ì´(ë³€í˜•) ë¬¸ì œ"])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with t_ans:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"""
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="explanation-box">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="exp-title">âœ… ì •ë‹µ</div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="exp-text">{d.get('answer','ì •ë³´ ì—†ìŒ')}</div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <br>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="exp-title">ğŸ“˜ ìƒì„¸ í•´ì„¤</div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="exp-text">{d.get('explanation','ì •ë³´ ì—†ìŒ')}</div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  """, unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with t_twin:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  twin_content = st.session_state.twin_items.get(item_id, "ìƒì„± ì‹¤íŒ¨")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"""
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="twin-card">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="twin-badge">TWIN PROBLEM</div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="exam-question">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {twin_content}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  """, unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("ë¶„ì„ ì‹¤íŒ¨")

Â  Â  Â  Â  Â  Â  Â  Â  # --- Chat Tab ---
Â  Â  Â  Â  Â  Â  Â  Â  with ai_tab_chat:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.caption("ì§ˆë¬¸í•˜ê¸°")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for msg in st.session_state.chat_history:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.chat_message(msg["role"]): st.markdown(msg["content"])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.api_key_ok:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.chat_history.append({"role": "user", "content": prompt})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.chat_message("user"): st.markdown(prompt)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.chat_message("assistant"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  p_context = p_text if p_text else "No text"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rel_context = st.session_state.last_related
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  chat_prmt = build_chat_prompt(st.session_state.chat_history, p_context, rel_context, prompt)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  response_text, _ = generate_with_fallback(chat_prmt, st.session_state.text_models)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(response_text)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.chat_history.append({"role": "assistant", "content": response_text})

# --- TAB 3: ë…¹ìŒ (Restored) ---
    if st.session_state.t2_selected_subject is None:
        st.markdown("#### ğŸ“– í•™ìŠµí•  ê³¼ëª©ì„ ì„ íƒí•˜ì„¸ìš”")
        stats = get_subject_stats()
        subjects = sorted(stats.keys())
        if not subjects: st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¡±ë³´ ê´€ë¦¬ íƒ­ì—ì„œ ì¶”ê°€í•˜ì„¸ìš”.")
        else:
             cols = st.columns(3)
             for i, subj in enumerate(subjects):
                 with cols[i % 3]:
                     btn_label = f"## {subj}\n\nğŸ“„ {stats[subj]['count']} pages"
                     if st.button(btn_label, key=f"t2_sel_{subj}", use_container_width=True):
                         st.session_state.t2_selected_subject = subj
                         st.rerun()
    else:
        target_subj = st.session_state.t2_selected_subject
        c_back, c_header = st.columns([1, 5])
        with c_back:
            if st.button("â† ê³¼ëª© ë³€ê²½", key="t2_back_btn"):
                st.session_state.t2_selected_subject = None
                st.rerun()
        with c_header: st.markdown(f"#### ğŸ“– {target_subj} - ì‹¤ì‹œê°„ ê°•ì˜ ë¶„ì„")
        
        with st.expander("ğŸ“‚ ê°•ì˜ PDF íŒŒì¼ ì—…ë¡œë“œ / ë³€ê²½", expanded=(st.session_state.lecture_doc is None)):
            l_file = st.file_uploader("PDF íŒŒì¼ ì„ íƒ", type="pdf", key="t2_f", label_visibility="collapsed")
            if l_file:
                if st.session_state.lecture_filename != l_file.name:
                    st.session_state.lecture_doc = fitz.open(stream=l_file.getvalue(), filetype="pdf")
                    st.session_state.lecture_filename = l_file.name
                    st.session_state.current_page = 0
                    st.session_state.last_page_sig = None
                    st.session_state.chat_history = [] 
                    st.session_state.parsed_items = {}
                    st.session_state.twin_items = {}
                    # Hot Pages Reset
                    st.session_state.hot_pages = []
                    st.session_state.hot_pages_analyzed = False

        if st.session_state.lecture_doc:
            doc = st.session_state.lecture_doc
            
            # --- [NEW] Hot Page Discovery ---
            with st.expander("ğŸ”¥ ì¡±ë³´ ì ì¤‘ í˜ì´ì§€ íƒìƒ‰ê¸°", expanded=not st.session_state.hot_pages_analyzed):
                if not st.session_state.hot_pages_analyzed:
                    st.markdown("ê°•ì˜ë¡ ì „ì²´ë¥¼ ìŠ¤ìº”í•˜ì—¬ ì¡±ë³´ì™€ ì—°ê´€ì„±ì´ ë†’ì€ **'ì ì¤‘ í˜ì´ì§€'**ë¥¼ ì°¾ì•„ëƒ…ë‹ˆë‹¤.")
                    if st.button("ğŸš€ ì „ì²´ í˜ì´ì§€ ë¶„ì„ ì‹œì‘ (AI Scan)", type="primary"):
                        if not st.session_state.api_key_ok:
                            st.error("ì„¤ì • íƒ­ì—ì„œ API Keyë¥¼ ë¨¼ì € ì—°ê²°í•´ì£¼ì„¸ìš”.")
                        else:
                            # 1. Prepare DB Check
                            sub_db = filter_db_by_subject(target_subj, st.session_state.db)
                            if not sub_db:
                                st.warning(f"'{target_subj}' ê³¼ëª©ì˜ ì¡±ë³´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                results = []
                                valid_db_items = [x for x in sub_db if x.get("embedding")]
                                db_embs = [x["embedding"] for x in valid_db_items]
                                
                                if not db_embs:
                                    st.warning("ì¡±ë³´ ë°ì´í„°ì— ì„ë² ë”© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                else:
                                    # 2. Scanning Loop
                                    prog_bar = st.progress(0)
                                    status_txt = st.empty()
                                    
                                    total_pages = len(doc)
                                    
                                    for p_idx in range(total_pages):
                                        status_txt.caption(f"Analyzing Page {p_idx+1}/{total_pages}...")
                                        try:
                                            page = doc.load_page(p_idx)
                                            txt = page.get_text().strip()
                                            
                                            # Optimization: Skip empty pages, limit text length
                                            if len(txt) > 30: 
                                                emb, _ = get_embedding_robust(txt)
                                                if emb:
                                                    sims = cosine_similarity([emb], db_embs)[0]
                                                    max_score = max(sims)
                                                    
                                                    # Threshold for "Hot Page" (INCREASED to 0.75 for better accuracy)
                                                    if max_score >= 0.75:
                                                        results.append({"page": p_idx, "score": max_score})
                                        except Exception:
                                            pass
                                        
                                        # Update progress
                                        prog_bar.progress((p_idx+1)/total_pages)
                                    
                                    # 3. Store Results (Limit to Top 20)
                                    sorted_results = sorted(results, key=lambda x: x["score"], reverse=True)
                                    st.session_state.hot_pages = sorted_results[:20]
                                    st.session_state.hot_pages_analyzed = True
                                    st.rerun()
                else:
                    # Display Navigation
                    c_head, c_reset = st.columns([4, 1])
                    with c_head:
                        if not st.session_state.hot_pages:
                            st.info("ë§¤ì¹­ë˜ëŠ” ì ì¤‘ í˜ì´ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì„ê³„ê°’ 0.75 ë¯¸ë§Œ)")
                        else:
                            st.markdown(f"**ğŸ”¥ ì´ {len(st.session_state.hot_pages)}ê°œì˜ ì ì¤‘ í˜ì´ì§€ ë°œê²¬!** (í´ë¦­í•˜ì—¬ ì´ë™)")
                    with c_reset:
                        if st.button("ì¬ë¶„ì„"):
                            st.session_state.hot_pages_analyzed = False
                            st.rerun()
                    
                    if st.session_state.hot_pages:
                        # Grid Layout for Buttons
                        cols = st.columns(6)
                        for i, item in enumerate(st.session_state.hot_pages):
                            p_num = item['page']
                            score = item['score']
                            with cols[i % 6]:
                                btn_label = f"P.{p_num+1}"
                                if st.button(btn_label, key=f"nav_{p_num}", help=f"ì ì¤‘ë¥  {score:.0%}"):
                                    st.session_state.current_page = p_num
                                    st.session_state.last_page_sig = None
                                    st.rerun()
                                st.markdown(f"<div style='text-align:center; font-size:0.75rem; color:#ff3b30; margin-top:-10px;'>{score:.0%}</div>", unsafe_allow_html=True)
            
            st.divider()

            col_view, col_ai = st.columns([1.8, 1.2])
            
            # --- Left: Viewer (Standard Image) ---
            with col_view:
                with st.container(border=True):
                    # Nav Toolbar
                    c1, c2, c3 = st.columns([1, 2, 1])
                    with c1:
                        if st.button("â—€", use_container_width=True):
                            if st.session_state.current_page > 0: 
                                st.session_state.current_page -= 1
                                st.session_state.chat_history = [] 
                                st.rerun()
                    with c2:
                        st.markdown(f"<div style='text-align:center; font-weight:bold; padding-top:8px;'>Page {st.session_state.current_page+1} / {len(doc)}</div>", unsafe_allow_html=True)
                    with c3:
                        if st.button("â–¶", use_container_width=True):
                            if st.session_state.current_page < len(doc)-1: 
                                st.session_state.current_page += 1
                                st.session_state.chat_history = []
                                st.rerun()
                    
                    # Prepare Image
                    page = doc.load_page(st.session_state.current_page)
                    pix = page.get_pixmap(dpi=150)
                    pil_image = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                    p_text = page.get_text() or ""
                    
                    st.image(pil_image, use_container_width=True)

            # --- Right: AI Assistant (Clean Version) ---
            with col_ai:
                with st.container(border=True):
                    ai_tab1, ai_tab2 = st.tabs(["ğŸ“ ì¡±ë³´ ë¶„ì„", "ğŸ’¬ ì§ˆì˜ì‘ë‹µ"])
                    
                    if not p_text.strip():
                        analysis_ready = False
                        with ai_tab1: st.caption("í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ì´ë¯¸ì§€ í˜ì´ì§€ì…ë‹ˆë‹¤.")
                    else:
                        analysis_ready = True
                        psig = hash(p_text)
                        
                        if psig != st.session_state.last_page_sig:
                            st.session_state.last_page_sig = psig
                            sub_db = filter_db_by_subject(target_subj, st.session_state.db)
                            st.session_state.last_related = find_relevant_jokbo(p_text, sub_db)
                            st.session_state.last_ai_sig = None
                        
                        rel = st.session_state.last_related
                    
                    with ai_tab1:
                        if analysis_ready:
                            if st.session_state.current_page == 0:
                                st.markdown("##### ğŸ ì „ì²´ ê°•ì˜ í•™ìŠµ ì „ëµ")
                                aisig = ("overview", target_subj, psig)
                                if aisig != st.session_state.last_ai_sig and st.session_state.api_key_ok:
                                    with st.spinner("ê°•ì˜ ì „ì²´ ë°©í–¥ì„± ë¶„ì„ ì¤‘..."):
                                        prmt = build_overview_prompt(p_text, target_subj)
                                        res, _ = generate_with_fallback(prmt, st.session_state.text_models)
                                        st.session_state.last_ai_text = res
                                        st.session_state.last_ai_sig = aisig
                                st.markdown(st.session_state.last_ai_text)
                            else:
                                st.markdown(f"##### ğŸ”¥ ì—°ê´€ ì¡±ë³´ TOP {len(rel[:3])}")
                                
                                if not rel:
                                    st.caption("ê´€ë ¨ëœ ì¡±ë³´ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
                                
                                # Loop through related items
                                for i, r in enumerate(rel[:3]):
                                    content = r['content']
                                    score = r['score']
                                    raw_txt = content['text']
                                    
                                    with st.container(border=True):
                                        st.markdown(f"**#{i+1} ìœ ì‚¬ë„ {score:.2f}** <small>({content['source']} P.{content['page']})</small>", unsafe_allow_html=True)
                                        
                                        # Split the raw text into potential questions
                                        split_questions = split_jokbo_text(raw_txt)
                                        
                                        if not split_questions:
                                            # Fallback if no numbered questions found
                                            split_questions = [raw_txt]

                                        st.caption(f"ğŸ” ë°œê²¬ëœ ë¬¸í•­: {len(split_questions)}ê°œ")
                                        
                                        # Render each split question as a separate card
                                        for seq_idx, question_txt in enumerate(split_questions):
                                            item_id = f"{psig}_{i}_{seq_idx}" # Unique ID per segment
                                            
                                            st.markdown(f"""
                                            <div class="jokbo-item">
                                                {question_txt}
                                            </div>
                                            """, unsafe_allow_html=True)

                                            # [NEW] Single Button for Analysis & Generation
                                            with st.expander(f"âœ¨ ì •ë‹µ/í•´ì„¤ ë° ìŒë‘¥ì´ ë¬¸ì œ", expanded=False):
                                                # Check if already parsed/generated
                                                if item_id in st.session_state.parsed_items:
                                                    # Show Cached Results
                                                    parsed_res = st.session_state.parsed_items[item_id]
                                                    if parsed_res["success"]:
                                                        data = parsed_res["data"]
                                                        st.markdown(f"""
                                                        <div class="answer-box">
                                                            <strong>âœ… ì •ë‹µ:</strong> {data.get('answer', 'ì •ë³´ ì—†ìŒ')}<br><br>
                                                            <strong>ğŸ’¡ í•´ì„¤:</strong> {data.get('explanation', 'ì •ë³´ ì—†ìŒ')}
                                                        </div>
                                                        """, unsafe_allow_html=True)
                                                        
                                                        # Show Twin Problem
                                                        if item_id in st.session_state.twin_items:
                                                            st.divider()
                                                            st.markdown(st.session_state.twin_items[item_id])
                                                    else:
                                                        st.error("ë¶„ì„ ì‹¤íŒ¨")
                                                else:
                                                    # One Button to Trigger All
                                                    if st.button("ğŸš€ AI ì •ë‹µ/í•´ì„¤ ë° ë³€í˜• ë¬¸ì œ ìƒì„±", key=f"btn_all_{item_id}", type="primary", use_container_width=True):
                                                        with st.spinner("AIê°€ ë¬¸ì œë¥¼ ë¶„ì„í•˜ê³  ë³€í˜• ë¬¸ì œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                                                            # 1. Parse
                                                            parsed = parse_raw_jokbo_llm(question_txt)
                                                            st.session_state.parsed_items[item_id] = parsed
                                                            
                                                            # 2. Generate Twin (if parse success)
                                                            if parsed["success"]:
                                                                twin_res = generate_twin_problem_llm(parsed, st.session_state.t2_selected_subject)
                                                                st.session_state.twin_items[item_id] = twin_res
                                                                st.rerun()
                                                            else:
                                                                st.error("í…ìŠ¤íŠ¸ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.info("ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

                    with ai_tab2:
                        for msg in st.session_state.chat_history:
                            with st.chat_message(msg["role"]):
                                st.markdown(msg["content"])
                        
                        if prompt := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš” (ì˜ˆ: ì´ê±° ì‹œí—˜ì— ë‚˜ì™€?)"):
                            if not st.session_state.api_key_ok: st.error("API Key í•„ìš”")
                            else:
                                st.session_state.chat_history.append({"role": "user", "content": prompt})
                                with st.chat_message("user"): st.markdown(prompt)
                                
                                with st.chat_message("assistant"):
                                    with st.spinner("ìƒê° ì¤‘..."):
                                        if analysis_ready:
                                            chat_prmt = build_chat_prompt(st.session_state.chat_history, p_text, rel, prompt)
                                            response_text, _ = generate_with_fallback(chat_prmt, st.session_state.text_models)
                                        else: response_text = "ì´ í˜ì´ì§€ì—ëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ì–´ ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."
                                        st.markdown(response_text)
                                        st.session_state.chat_history.append({"role": "assistant", "content": response_text})

        else:
            st.markdown("""
                <div style="height: 400px; display: flex; align-items: center; justify-content: center; color: #ccc; border: 2px dashed #eee; border-radius: 12px; margin-top: 20px;">
                    <h3>ìƒë‹¨ì—ì„œ ê°•ì˜ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš” ğŸ“‚</h3>
                </div>
            """, unsafe_allow_html=True)


# --- TAB 3: ê°•ì˜ ë…¹ìŒ/ë¶„ì„ (Original Rich UI + New Logic) ---
with tab3:
Â  Â  with st.container(border=True):
Â  Â  Â  Â  st.markdown("#### ğŸ™ï¸ ê°•ì˜ ë…¹ìŒ/ë¶„ì„")
Â  Â  Â  Â  c_in, c_out = st.columns(2)
Â  Â  Â  Â  with c_in:
Â  Â  Â  Â  Â  Â  sub_t3 = st.selectbox("ê³¼ëª©", ["ì „ì²´"] + sorted({x.get("subject", "") for x in st.session_state.db}), key="t3_s")
Â  Â  Â  Â  Â  Â  t3_mode = st.radio("ì…ë ¥ ë°©ì‹", ["ğŸ¤ ì§ì ‘ ë…¹ìŒ", "ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ"], horizontal=True)
Â  Â  Â  Â  Â  Â  target_text = ""
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if t3_mode == "ğŸ¤ ì§ì ‘ ë…¹ìŒ":
Â  Â  Â  Â  Â  Â  Â  Â  audio_value = st.audio_input("ë…¹ìŒ ì‹œì‘")
Â  Â  Â  Â  Â  Â  Â  Â  if audio_value and st.button("ğŸš€ ë¶„ì„"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.api_key_ok:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("ë³€í™˜ ì¤‘..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  transcript = transcribe_audio_gemini(audio_value.getvalue(), st.session_state.api_key)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if transcript:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.transcribed_text = transcript
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target_text = transcript
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  f_txt = st.file_uploader("ì „ì‚¬ íŒŒì¼", type="txt")
Â  Â  Â  Â  Â  Â  Â  Â  if f_txt and st.button("ë¶„ì„"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target_text = f_txt.getvalue().decode().strip()
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if target_text and st.session_state.api_key_ok:
Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("ë¶„ì„ ì¤‘..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sdb = filter_db_by_subject(sub_t3, st.session_state.db)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  chks = chunk_transcript(target_text)[:10]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rels = [find_relevant_jokbo(c, sdb, threshold=0.6) for c in chks]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pmt = build_transcript_prompt(chks, rels, sub_t3)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  res, _ = generate_with_fallback(pmt, st.session_state.text_models)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.tr_res = res
Â  Â  Â  Â  Â  Â  Â  Â  st.success("ì™„ë£Œ!")

Â  Â  Â  Â  with c_out:
Â  Â  Â  Â  Â  Â  st.caption("ê²°ê³¼")
Â  Â  Â  Â  Â  Â  if st.session_state.tr_res:
Â  Â  Â  Â  Â  Â  Â  Â  st.info(st.session_state.tr_res)
Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.transcribed_text:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ì „ì²´ í…ìŠ¤íŠ¸"): st.text(st.session_state.transcribed_text)
    with st.container(border=True):
        st.markdown("#### ğŸ™ï¸ ê°•ì˜ ë…¹ìŒ/ë¶„ì„")
        
        c_in, c_out = st.columns(2)
        with c_in:
            sub_t3 = st.selectbox("ê³¼ëª©", ["ì „ì²´"] + sorted({x.get("subject", "") for x in st.session_state.db}), key="t3_s")
            t3_mode = st.radio("ì…ë ¥ ë°©ì‹", ["ğŸ¤ ì§ì ‘ ë…¹ìŒ", "ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ / í…ìŠ¤íŠ¸"], horizontal=True, label_visibility="collapsed")
            target_text = ""
            
            if t3_mode == "ğŸ¤ ì§ì ‘ ë…¹ìŒ":
                audio_value = st.audio_input("ë…¹ìŒ ì‹œì‘")
                if audio_value:
                    if st.button("ğŸš€ ë…¹ìŒ ë‚´ìš© ë¶„ì„í•˜ê¸°", type="primary", use_container_width=True, key="btn_audio_analyze"):
                        if not st.session_state.api_key_ok: st.error("API Key í•„ìš”")
                        else:
                            with st.spinner("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                                transcript = transcribe_audio_gemini(audio_value.getvalue(), st.session_state.api_key)
                                if transcript:
                                    st.session_state.transcribed_text = transcript
                                    target_text = transcript
                                else: st.error("ë³€í™˜ ì‹¤íŒ¨")
            else:
                f_txt = st.file_uploader("ì „ì‚¬ íŒŒì¼(.txt)", type="txt", key="t3_f")
                area_txt = st.text_area("ì§ì ‘ ì…ë ¥", height=200, placeholder="ê°•ì˜ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”...")
                if st.button("ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True):
                    target_text = (f_txt.getvalue().decode() if f_txt else area_txt).strip()
            
            if target_text:
                if not st.session_state.api_key_ok: st.error("API Key í•„ìš”")
                else:
                    with st.spinner("ì¡±ë³´ ë°ì´í„°ì™€ ëŒ€ì¡°í•˜ì—¬ ë¶„ì„ ì¤‘..."):
                        sdb = filter_db_by_subject(sub_t3, st.session_state.db)
                        chks = chunk_transcript(target_text)[:10]
                        rels = [find_relevant_jokbo(c, sdb, top_k=3) for c in chks]
                        pmt = build_transcript_prompt(chks, rels, sub_t3)
                        res, _ = generate_with_fallback(pmt, st.session_state.text_models)
                        st.session_state.tr_res = res
                    st.success("ë¶„ì„ ì™„ë£Œ!")

        with c_out:
            st.caption("ë¶„ì„ ê²°ê³¼")
            if "tr_res" in st.session_state:
                st.info(st.session_state.tr_res)
                if st.session_state.transcribed_text:
                    with st.expander("ğŸ“ ë³€í™˜ëœ ì „ì²´ í…ìŠ¤íŠ¸ ë³´ê¸°"):
                        st.text(st.session_state.transcribed_text)
            else:
                st.markdown("""<div style="height: 300px; background: #f9f9f9; border-radius: 10px; display: flex; align-items: center; justify-content: center; color: #aaa;">ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</div>""", unsafe_allow_html=True)
