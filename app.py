import streamlit as st
import pandas as pd
import os
import time
from pypdf import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from streamlit_mic_recorder import mic_recorder

# =========================
# 1. ì´ˆê¸° ì„¤ì • ë° ì—ëŸ¬ ë°©ì§€ (ì„¸ì…˜ ê´€ë¦¬)
# =========================
st.set_page_config(page_title="ì˜ëŒ€ìƒ ì‹¤ì‹œê°„ ì¡±ë³´ ë¹„ì„œ", layout="wide")

# NameError ë°©ì§€ë¥¼ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'pre_analysis' not in st.session_state: st.session_state.pre_analysis = []
if 'exam_db' not in st.session_state: st.session_state.exam_db = []
if 'vectorizer' not in st.session_state: st.session_state.vectorizer = None
if 'matrix' not in st.session_state: st.session_state.matrix = None

def get_pdf_text(file):
    reader = PdfReader(file)
    return [page.extract_text() or "" for page in reader.pages]

# =========================
# 2. ë©”ì¸ UI ë° ê¸°ëŠ¥
# =========================
st.title("ğŸ©º Med-Study OS: ì‹¤ì‹œê°„ ì¡±ë³´ ë§¤ì¹­ & ë…¹ìŒ")

tab1, tab2, tab3 = st.tabs(["ğŸ“… ìˆ˜ì—… ì „: ìë™ ì •ë¦¬", "ğŸ™ï¸ ìˆ˜ì—… ì¤‘: ì‹¤ì‹œê°„ ë…¹ìŒ/ì•Œë¦¼", "ğŸ¯ ìˆ˜ì—… í›„: ë‹¨ê¶Œí™” ë¦¬í¬íŠ¸"])

# --- [Tab 1: ìˆ˜ì—… ì „ ì‚¬ì „ ë¶„ì„] ---
with tab1:
    st.header("ê°•ì˜ì‹¤ ê°€ê¸° ì „: ì¡±ë³´ í¬ì¸íŠ¸ ë¯¸ë¦¬ë³´ê¸°")
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("1. ì¡±ë³´ PDF ë“±ë¡")
        exam_files = st.file_uploader("ê³¼ê±° ì¡±ë³´ íŒŒì¼ë“¤ì„ ì˜¬ë ¤ì£¼ì„¸ìš”", type="pdf", accept_multiple_files=True)
        if st.button("ì¡±ë³´ ë°ì´í„° ë¶„ì„ ì‹œì‘"):
            all_exams = []
            for f in exam_files:
                pages = get_pdf_text(f)
                for i, text in enumerate(pages):
                    if text.strip():
                        all_exams.append({"info": f"{f.name} (p.{i+1})", "text": text})
            
            if all_exams:
                st.session_state.exam_db = all_exams
                vec = TfidfVectorizer(ngram_range=(1, 2))
                st.session_state.matrix = vec.fit_transform([e['text'] for e in all_exams])
                st.session_state.vectorizer = vec
                st.success(f"{len(all_exams)}ê°œì˜ ì¡±ë³´ í˜ì´ì§€ ì¸ë±ì‹± ì™„ë£Œ!")

    with col2:
        st.subheader("2. ì˜¤ëŠ˜ ê°•ì˜ë¡ ë§¤ì¹­")
        lec_file = st.file_uploader("ì˜¤ëŠ˜ ìˆ˜ì—…ìš© ê°•ì˜ë¡ PDF", type="pdf")
        if lec_file and st.button("ìˆ˜ì—… ì „ ìë™ ë‹¨ê¶Œí™” ë¶„ì„"):
            if st.session_state.vectorizer:
                lec_pages = get_pdf_text(lec_file)
                results = []
                for i, p_text in enumerate(lec_pages):
                    if not p_text.strip(): continue
                    qv = st.session_state.vectorizer.transform([p_text])
                    sims = cosine_similarity(qv, st.session_state.matrix).flatten()
                    if sims.max() > 0.2:
                        best_idx = sims.argmax()
                        results.append({
                            "page": i+1, 
                            "score": sims.max(), 
                            "exam_info": st.session_state.exam_db[best_idx]['info'],
                            "exam_text": st.session_state.exam_db[best_idx]['text']
                        })
                st.session_state.pre_analysis = results
                st.success(f"ë¶„ì„ ì™„ë£Œ! {len(results)}ê°œ í˜ì´ì§€ì—ì„œ ì¡±ë³´ ì ì¤‘ ì˜ˆìƒ.")
            else:
                st.error("ë¨¼ì € ì¡±ë³´ ë°ì´í„°ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")

# --- [Tab 2: ìˆ˜ì—… ì¤‘ ì‹¤ì‹œê°„ ë§¤ì¹­ & ë…¹ìŒ] ---
with tab2:
    st.header("ğŸ§ ì‹¤ì‹œê°„ ê°•ì˜ íŠ¸ë˜í‚¹")
    if not st.session_state.pre_analysis:
        st.warning("ìˆ˜ì—… ì „ ë¶„ì„ì„ ë¨¼ì € ì™„ë£Œí•´ì•¼ ì‹¤ì‹œê°„ ë§¤ì¹­ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        st.info("êµìˆ˜ë‹˜ ì„¤ëª…ì„ ë…¹ìŒí•˜ë©´, ë¶„ì„ëœ ì¡±ë³´ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëŒ€ì¡°í•˜ì—¬ ì•Œë ¤ì¤ë‹ˆë‹¤.")
        
        # ì‹¤ì œ ìŒì„± ë…¹ìŒ ë„êµ¬ (ì´ë¯¸ì§€ ì—ëŸ¬ í•´ê²°ì±…)
        audio = mic_recorder(start_prompt="ğŸ”´ ê°•ì˜ ë…¹ìŒ ì‹œì‘", stop_prompt="â¹ï¸ ì¤‘ì§€ ë° ì‹¤ì‹œê°„ ë¶„ì„", key='recorder')
        
        if audio:
            st.audio(audio['bytes'])
            st.success("ê°•ì˜ ë…¹ìŒ ì™„ë£Œ ë° í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘... (Whisper ì‹œë®¬ë ˆì´ì…˜)")
            
            # ë°ëª¨ìš© ì‹œë®¬ë ˆì´ì…˜: ì‹¤ì œë¡œëŠ” ë…¹ìŒëœ audio['bytes']ë¥¼ Whisper APIë¡œ ì „ì†¡
            # ì˜ˆì‹œ: êµìˆ˜ë‹˜ì´ ì‹¬ê·¼ê²½ìƒ‰(MI) ê´€ë ¨ ì¡±ë³´ ë‚´ìš©ì„ ì„¤ëª…í–ˆë‹¤ê³  ê°€ì •
            simulated_speech = "ì‹¬ê·¼ê²½ìƒ‰ í™˜ìê°€ ì‘ê¸‰ì‹¤ì— ì˜¤ë©´ ê°€ì¥ ë¨¼ì € STë¶„ì ˆ ìƒìŠ¹ ì—¬ë¶€ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤."
            st.subheader(f"ğŸ—£ï¸ êµìˆ˜ë‹˜ ë°œì–¸ ì¸ì‹: \"{simulated_speech}\"")
            
            # ì‹¤ì‹œê°„ ë§¤ì¹­ ë¡œì§ (ì‚¬ì „ ë¶„ì„ ë°ì´í„° ê¸°ë°˜)
            hits = [item for item in st.session_state.pre_analysis if any(word in item['exam_text'] for word in simulated_speech.split()[:4])]
            
            if hits:
                for hit in hits:
                    st.toast(f"ğŸš¨ ì¡±ë³´ ì ì¤‘ ì•Œë¦¼! ê°•ì˜ë¡ {hit['page']}p ê´€ë ¨", icon="ğŸ”¥")
                    with st.warning():
                        st.markdown(f"### ğŸš© ì‹¤ì‹œê°„ ê¸°ì¶œ ì ì¤‘ (ê°•ì˜ë¡ {hit['page']}í˜ì´ì§€)")
                        st.write(f"**ê³¼ê±° ì¶œì œ ì •ë³´:** {hit['exam_info']}")
                        st.write(f"**ê³¼ê±° ì§€ë¬¸ ë‚´ìš©:** {hit['exam_text'][:250]}...")
                        st.caption("ğŸ’¡ êµìˆ˜ë‹˜ì´ ë°©ê¸ˆ ì„¤ëª…í•˜ì‹  ë‚´ìš©ì€ ê³¼ê±° ê¸°ì¶œ ì§€ë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œì™€ ì¼ì¹˜í•©ë‹ˆë‹¤.")
            else:
                st.info("í˜„ì¬ ë°œì–¸ ì¤‘ì—ëŠ” ì¼ì¹˜í•˜ëŠ” ê³¼ê±° ê¸°ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# --- [Tab 3: ìˆ˜ì—… í›„ ë³µìŠµ ë¦¬í¬íŠ¸] ---
with tab3:
    st.header("ğŸ¯ ì˜¤ëŠ˜ì˜ ìŠ¤ë§ˆíŠ¸ ë‹¨ê¶Œí™” ë¦¬í¬íŠ¸")
    if st.session_state.pre_analysis:
        df = pd.DataFrame(st.session_state.pre_analysis)
        st.subheader("ë§¤ì¹­ ê²°ê³¼ ìš”ì•½")
        st.dataframe(df[['page', 'exam_info', 'score']])
        
        # Anki ì¹´ë“œ ìƒì„± ê¸°ëŠ¥
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button("ğŸ“¥ ì˜¤ëŠ˜ ê¸°ì¶œ ê¸°ë°˜ Anki ì¹´ë“œ ë‹¤ìš´ë¡œë“œ", csv, "anki_cards.csv", "text/csv")
    else:
        st.write("í‘œì‹œí•  ë¶„ì„ ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
