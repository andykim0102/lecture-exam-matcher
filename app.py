import streamlit as st
import pandas as pd
import base64
import os
from pypdf import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from streamlit_mic_recorder import mic_recorder

# =========================
# 1. ì´ˆê¸° ì„¤ì • ë° ì„¸ì…˜ ê´€ë¦¬ (ì—ëŸ¬ ë°©ì§€ ë° ë°ì´í„° ìœ ì§€)
# =========================
st.set_page_config(page_title="Med-Study OS Alpha", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'pre_analysis' not in st.session_state: st.session_state.pre_analysis = []
if 'exam_db' not in st.session_state: st.session_state.exam_db = []
if 'vectorizer' not in st.session_state: st.session_state.vectorizer = None
if 'matrix' not in st.session_state: st.session_state.matrix = None
if 'pdf_bytes' not in st.session_state: st.session_state.pdf_bytes = None
if 'notebook' not in st.session_state: st.session_state.notebook = [] # ë‹¨ê¶Œí™” ë°”êµ¬ë‹ˆ

def get_pdf_text_by_page(file):
    reader = PdfReader(file)
    return [page.extract_text() or "" for page in reader.pages]

def display_pdf(file_bytes, page_num):
    base64_pdf = base64.b64encode(file_bytes).decode('utf-8')
    pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}#page={page_num}" width="100%" height="800" type="application/pdf"></iframe>'
    st.markdown(pdf_display, unsafe_allow_html=True)

def get_match_label(score):
    """ì†Œìˆ˜ì  ì ìˆ˜ë¥¼ ì§ê´€ì ì¸ ì§€í‘œë¡œ ë³€í™˜"""
    percent = int(score * 100)
    if score > 0.4: return f"ğŸ”¥ {percent}% (ì¡±ë³´ ì ì¤‘ í™•ì‹¤)"
    if score > 0.25: return f"âœ… {percent}% (ì—°ê´€ì„± ë†’ìŒ)"
    return f"âš ï¸ {percent}% (í™•ì¸ ê¶Œì¥)"

# =========================
# 2. ë©”ì¸ ì„œë¹„ìŠ¤ ë ˆì´ì•„ì›ƒ
# =========================
st.title("ğŸ©º Med-Study OS: í†µí•© ë‹¨ê¶Œí™” ì†”ë£¨ì…˜")

tab1, tab2, tab3 = st.tabs(["ğŸ“‚ 1. ìˆ˜ì—… ì „ (ì‚¬ì „ ë¶„ì„)", "ğŸ™ï¸ 2. ìˆ˜ì—… ì¤‘ (ë·°ì–´ & ì‹¤ì‹œê°„)", "ğŸ¯ 3. ìˆ˜ì—… í›„ (ë‚˜ë§Œì˜ ì •ë¦¬ë³¸)"])

# --- [Tab 1: ìˆ˜ì—… ì „ ì‚¬ì „ ë¶„ì„] ---
with tab1:
    st.header("ê°•ì˜ ì „ ë°ì´í„° ì¤€ë¹„")
    col_ex, col_lec = st.columns(2)
    
    with col_ex:
        st.subheader("ğŸ“š ì¡±ë³´ ì•„ì¹´ì´ë¸Œ ë“±ë¡")
        exam_files = st.file_uploader("ì¡±ë³´ PDFë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf", accept_multiple_files=True)
        if st.button("ì¡±ë³´ ë°ì´í„° ê³ ë„í™” ì¸ë±ì‹±"):
            all_exams = []
            for f in exam_files:
                pages = get_pdf_text_by_page(f)
                # í…ìŠ¤íŠ¸ë¥¼ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ìª¼ê°œì–´(Chunking) ì •í™•ë„ í–¥ìƒ ì‹œë„ ê°€ëŠ¥
                for i, text in enumerate(pages):
                    if len(text.strip()) > 20: # ì˜ë¯¸ ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                        all_exams.append({"source": f"{f.name} (p.{i+1})", "content": text})
            
            if all_exams:
                st.session_state.exam_db = all_exams
                vec = TfidfVectorizer(ngram_range=(1, 2), stop_words=None) # ì˜í•™ ìš©ì–´ ë³´ì¡´ì„ ìœ„í•´ stop_words ë¯¸ì‚¬ìš©
                st.session_state.matrix = vec.fit_transform([e['content'] for e in all_exams])
                st.session_state.vectorizer = vec
                st.success("ì¡±ë³´ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì™„ë£Œ!")

    with col_lec:
        st.subheader("ğŸ“– ì˜¤ëŠ˜ ê°•ì˜ë¡ ë¶„ì„")
        lec_file = st.file_uploader("ì˜¤ëŠ˜ ìˆ˜ì—…ìš© ê°•ì˜ë¡ PDF", type="pdf")
        if lec_file:
            st.session_state.pdf_bytes = lec_file.getvalue()
            if st.button("AI ì‚¬ì „ ë§¤ì¹­ ì‹¤í–‰"):
                if st.session_state.vectorizer:
                    lec_pages = get_pdf_text_by_page(lec_file)
                    results = []
                    for i, p_text in enumerate(lec_pages):
                        if not p_text.strip(): continue
                        qv = st.session_state.vectorizer.transform([p_text])
                        sims = cosine_similarity(qv, st.session_state.matrix).flatten()
                        if sims.max() > 0.22: # ì—­ì¹˜(Threshold) ì¡°ì • ê°€ëŠ¥
                            best_idx = sims.argmax()
                            results.append({
                                "page": i+1, 
                                "score": sims.max(), 
                                "exam_info": st.session_state.exam_db[best_idx]['source'],
                                "exam_text": st.session_state.exam_db[best_idx]['content']
                            })
                    st.session_state.pre_analysis = results
                    st.success(f"ë¶„ì„ ì™„ë£Œ! ì´ {len(results)}ê°œì˜ í•µì‹¬ ê¸°ì¶œ í˜ì´ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                else:
                    st.error("ë¨¼ì € ì¡±ë³´ ë°ì´í„°ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")

# --- [Tab 2: ìˆ˜ì—… ì¤‘ ì‹œê°ì  ë·°ì–´ & ì‹¤ì‹œê°„ ë‹¨ê¶Œí™”] ---
with tab2:
    if st.session_state.pdf_bytes is None:
        st.warning("ë¨¼ì € ê°•ì˜ë¡ì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”.")
    else:
        # ì¢Œì¸¡: PDF ë·°ì–´ / ìš°ì¸¡: ì‹¤ì‹œê°„ ì•Œë¦¼ ë° ê°„í¸ ë…¸íŠ¸
        col_pdf, col_tool = st.columns([1.2, 0.8])
        
        with col_pdf:
            st.subheader("ğŸ“„ ê°•ì˜ë¡ ì‹¤ì‹œê°„ ë·°ì–´")
            current_page = st.select_slider("í˜ì´ì§€ ì´ë™", options=range(1, 101), value=1)
            display_pdf(st.session_state.pdf_bytes, current_page)

        with col_tool:
            st.subheader("âš¡ ì‹¤ì‹œê°„ ì–´ì‹œìŠ¤í„´íŠ¸")
            
            # ì‹¤ì‹œê°„ ë…¹ìŒ ë° ë¶„ì„ë¶€
            audio = mic_recorder(start_prompt="ğŸ¤ êµìˆ˜ë‹˜ ì„¤ëª… ë¶„ì„ ì‹œì‘", stop_prompt="â¹ï¸ ì¤‘ì§€ ë° ë§¤ì¹­", key='live_mic')
            if audio:
                st.audio(audio['bytes'])
                # ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤ìš© ì‹œë®¬ë ˆì´ì…˜ ë°œì–¸
                speech_text = "ì´ ì§ˆí™˜ì˜ ì§„ë‹¨ ê¸°ì¤€ì€ ì‘ë…„ êµ­ì‹œì—ë„ ë‚˜ì™”ê³  ì•„ì£¼ í•µì‹¬ì ì¸ ë‚´ìš©ì…ë‹ˆë‹¤."
                st.info(f"ğŸ—£ï¸ ì¸ì‹ëœ ê°•ì˜ ë‚´ìš©: \"{speech_text}\"")
                
                # ì‹¤ì‹œê°„ ë§¤ì¹­ ì•Œë¦¼ (ì „ì²´ DB ëŒ€ìƒ)
                if st.session_state.vectorizer:
                    qv_live = st.session_state.vectorizer.transform([speech_text])
                    sims_live = cosine_similarity(qv_live, st.session_state.matrix).flatten()
                    if sims_live.max() > 0.18:
                        hit = sims_live.argmax()
                        st.toast("ğŸš¨ ì¡±ë³´ ë§¤ì¹­ ë°œê²¬!", icon="ğŸ”¥")
                        with st.status("ğŸ”¥ ì‹¤ì‹œê°„ ì¡±ë³´ ë§¤ì¹­ ì„±ê³µ!", expanded=True):
                            st.write(f"**ê´€ë ¨ ì¡±ë³´:** {st.session_state.exam_db[hit]['source']}")
                            st.write(f"**ê¸°ì¶œ ì§€ë¬¸:** {st.session_state.exam_db[hit]['content'][:300]}...")
            
            st.divider()
            
            # í˜„ì¬ í˜ì´ì§€ ê¸°ë°˜ ì‚¬ì „ ì •ë³´ í‘œì‹œ ë° ê°„í¸ ì¶”ê°€
            st.subheader(f"ğŸ“ {current_page}p ê¸°ì¶œ í¬ì¸íŠ¸")
            page_hits = [h for h in st.session_state.pre_analysis if h['page'] == current_page]
            
            if page_hits:
                for h in page_hits:
                    with st.container(border=True):
                        st.markdown(f"**ì ì¤‘ë¥ :** {get_match_label(h['score'])}")
                        st.markdown(f"**ì¶œì²˜:** {h['exam_info']}")
                        # í•µì‹¬: ì¡±ë³´ ì›ë¬¸ í¬ì»¤ì‹± (ë¬¸ë‹¨ ì¶”ì¶œì€ í–¥í›„ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ê³ ë„í™” ê°€ëŠ¥)
                        st.caption(f"ë‚´ìš© ìš”ì•½: {h['exam_text'][:350]}...")
                        
                        # [í•´ê²° 4] ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€ ê¸°ëŠ¥
                        user_note = st.text_input("ë©”ëª¨ ì¶”ê°€", placeholder="êµìˆ˜ë‹˜ì´ ì´ ë¶€ë¶„ì—ì„œ ê°•ì¡°í•˜ì‹  ë§ì”€ì€?", key=f"note_{h['page']}")
                        
                        if st.button("ğŸ“Œ ì´ í˜ì´ì§€ ë‹¨ê¶Œí™” ì €ì¥", key=f"btn_{h['page']}"):
                            st.session_state.notebook.append({
                                "page": h['page'],
                                "exam_info": h['exam_info'],
                                "exam_text": h['exam_text'],
                                "user_note": user_note
                            })
                            st.toast("ë‚˜ë§Œì˜ ì •ë¦¬ë³¸ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                st.info("ì´ í˜ì´ì§€ì™€ ê´€ë ¨ëœ ê¸°ì¶œ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")

# --- [Tab 3: ìˆ˜ì—… í›„ ë‚˜ë§Œì˜ ì •ë¦¬ë³¸] ---
with tab3:
    st.header("ğŸ“ ë‚˜ë§Œì˜ ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ë³¸ (ë‹¨ê¶Œí™” ì™„ë£Œ)")
    
    if st.session_state.notebook:
        st.write(f"ì´ {len(st.session_state.notebook)}ê°œì˜ í•µì‹¬ í¬ì¸íŠ¸ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        for i, item in enumerate(st.session_state.notebook):
            with st.expander(f"ğŸ“” [ê°•ì˜ë¡ {item['page']}p] {item['exam_info']} ê´€ë ¨ ì •ë¦¬", expanded=True):
                col_res1, col_res2 = st.columns(2)
                with col_res1:
                    st.markdown("**ğŸ“‚ ê´€ë ¨ ì¡±ë³´ ì›ë¬¸**")
                    st.info(item['exam_text'])
                with col_res2:
                    st.markdown("**âœï¸ ìˆ˜ì—… ì¤‘ ë‚˜ì˜ ë©”ëª¨**")
                    st.success(item['user_note'] if item['user_note'] else "ì¶”ê°€ ë©”ëª¨ ì—†ìŒ")
                
                if st.button("ì‚­ì œ", key=f"del_{i}"):
                    st.session_state.notebook.pop(i)
                    st.rerun()
        
        # íŒŒì¼ ë‚´ë³´ë‚´ê¸°
        final_df = pd.DataFrame(st.session_state.notebook)
        csv_data = final_df.to_csv(index=False).encode('utf-8')
        st.download_button("ğŸ“¥ ìµœì¢… ì •ë¦¬ë³¸ CSV ë‹¤ìš´ë¡œë“œ (Anki í˜¸í™˜ ê°€ëŠ¥)", csv_data, "med_summary.csv", "text/csv")
    else:
        st.info("ìˆ˜ì—… ì¤‘ì— 'ë‹¨ê¶Œí™” ì €ì¥' ë²„íŠ¼ì„ ëˆ„ë¥¸ ë‚´ìš©ë“¤ì´ ì—¬ê¸°ì— ëª¨ì…ë‹ˆë‹¤.")
