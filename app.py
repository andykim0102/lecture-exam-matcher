import streamlit as st
import google.generativeai as genai
import fitz  # PyMuPDF
from PIL import Image
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import time
from streamlit_mic_recorder import mic_recorder

# ==========================================
# 1. ì„¤ì • ë° ì´ˆê¸°í™”
# ==========================================
st.set_page_config(page_title="Med-Study OS Final", layout="wide", page_icon="ğŸ©º")

if 'db' not in st.session_state: st.session_state.db = []
if 'lecture_doc' not in st.session_state: st.session_state.lecture_doc = None
if 'current_page' not in st.session_state: st.session_state.current_page = 0

# ==========================================
# 2. í•µì‹¬ í•¨ìˆ˜ (Logic)
# ==========================================
def extract_text_from_pdf(file):
    """PDFë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (fitz ì‚¬ìš©)"""
    doc = fitz.open(stream=file.read(), filetype="pdf")
    pages_content = []
    for page_num, page in enumerate(doc):
        text = page.get_text()
        if text.strip():
            pages_content.append({"page": page_num + 1, "text": text, "source": file.name})
    return pages_content

def get_embedding(text):
    """ì„ë² ë”© (Embedding-004 ì‚¬ìš©)"""
    try:
        return genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="retrieval_document"
        )['embedding']
    except Exception:
        try:
            return genai.embed_content(
                model="models/embedding-001",
                content=text,
                task_type="retrieval_document"
            )['embedding']
        except:
            return []

def find_relevant_jokbo(query_text, db, top_k=3):
    """ìœ ì‚¬ë„ ê²€ìƒ‰"""
    if not db: return []
    query_emb = get_embedding(query_text)
    if not query_emb: return []
    
    db_embs = [item['embedding'] for item in db]
    sims = cosine_similarity([query_emb], db_embs)[0]
    top_idxs = np.argsort(sims)[::-1][:top_k]
    
    return [{"score": sims[i], "content": db[i]} for i in top_idxs]

# ==========================================
# 3. ì‚¬ì´ë“œë°”
# ==========================================
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì •")
    api_key = st.text_input("Gemini API Key", type="password")
    if api_key:
        genai.configure(api_key=api_key)
        st.success("API Key ì…ë ¥ë¨")
            
    st.divider()
    st.write(f"ğŸ“š í•™ìŠµëœ ì¡±ë³´: {len(st.session_state.db)} í˜ì´ì§€")
    if st.button("ì´ˆê¸°í™”"):
        st.session_state.db = []
        st.rerun()

# ==========================================
# 4. ë©”ì¸ UI
# ==========================================
tab1, tab2 = st.tabs(["ğŸ“‚ ì¡±ë³´ í•™ìŠµ", "ğŸ“– ê°•ì˜ ê³µë¶€"])

# --- TAB 1: ì¡±ë³´ í•™ìŠµ ---
with tab1:
    st.header("1. ì¡±ë³´ ì—…ë¡œë“œ")
    files = st.file_uploader("ì¡±ë³´ PDF", accept_multiple_files=True, type="pdf")
    
    if st.button("í•™ìŠµ ì‹œì‘ ğŸš€") and files:
        if not api_key:
            st.error("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            bar = st.progress(0)
            status = st.empty()
            new_db = []
            total_files = len(files)
            
            for i, f in enumerate(files):
                status.text(f"ğŸ“– íŒŒì¼ ì½ëŠ” ì¤‘: {f.name}...")
                pages = extract_text_from_pdf(f)
                
                for j, p in enumerate(pages):
                    status.text(f"ğŸ§  í•™ìŠµ ì¤‘: {f.name} ({j+1}/{len(pages)} í˜ì´ì§€)...")
                    emb = get_embedding(p['text'])
                    if emb:
                        p['embedding'] = emb
                        new_db.append(p)
                    # [ì¤‘ìš”] ì†ë„ ì œí•œ ë°©ì§€ ëŒ€ê¸°
                    time.sleep(1.0) 
                
                bar.progress((i + 1) / total_files)
            
            st.session_state.db.extend(new_db)
            status.text("âœ… í•™ìŠµ ì™„ë£Œ!")
            st.success(f"{len(new_db)} í˜ì´ì§€ í•™ìŠµ ì™„ë£Œ!")

# --- TAB 2: ê°•ì˜ ë¶„ì„ ---
with tab2:
    st.header("2. ê°•ì˜ ë·°ì–´ & AI")
    lec_file = st.file_uploader("ê°•ì˜ë¡ PDF", type="pdf", key="lec")
    
    if lec_file:
        if st.session_state.lecture_doc is None or st.session_state.lecture_doc.name != lec_file.name:
            st.session_state.lecture_doc = fitz.open(stream=lec_file.read(), filetype="pdf")
            st.session_state.current_page = 0
            
        doc = st.session_state.lecture_doc
        col_view, col_ai = st.columns([6, 4])
        
        with col_view:
            c1, c2, c3 = st.columns([1, 2, 1])
            if c1.button("â—€"): 
                if st.session_state.current_page > 0: st.session_state.current_page -= 1
            c2.markdown(f"<center>{st.session_state.current_page + 1} / {len(doc)}</center>", unsafe_allow_html=True)
            if c3.button("â–¶"): 
                if st.session_state.current_page < len(doc) - 1: st.session_state.current_page += 1
            
            page = doc.load_page(st.session_state.current_page)
            pix = page.get_pixmap(dpi=150)
            st.image(Image.frombytes("RGB", [pix.width, pix.height], pix.samples), use_container_width=True)
            curr_text = page.get_text()

        with col_ai:
            if st.button("ë¶„ì„í•˜ê¸° âš¡"):
                if not api_key or not st.session_state.db:
                    st.error("API Key ë˜ëŠ” ì¡±ë³´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    if not curr_text.strip():
                        st.warning("í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” í˜ì´ì§€ì…ë‹ˆë‹¤.")
                    else:
                        with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                            try:
                                # 1. ê´€ë ¨ ì¡±ë³´ ì°¾ê¸°
                                related = find_relevant_jokbo(curr_text, st.session_state.db)
                                ctx_str = "\n".join([f"- {i['content']['text'][:100]}" for i in related])
                                
                                prompt = f"ê°•ì˜: {curr_text}\nì¡±ë³´: {ctx_str}\n\nì—°ê´€ì„±, í‚¤ì›Œë“œ, ë¬¸ì œ ìƒì„±í•´ì¤˜."

                                # [í•µì‹¬] ë¬´ë£Œ í•œë„ê°€ ë„‰ë„‰í•œ 1.5-flash ëª¨ë¸ ê°•ì œ ì‚¬ìš©
                                model = genai.GenerativeModel("gemini-1.5-flash")
                                
                                response = model.generate_content(prompt)
                                st.markdown(response.text)
                                    
                            except Exception as e:
                                if "429" in str(e):
                                    st.error("âš ï¸ ì‚¬ìš©ëŸ‰ì´ ë§ìŠµë‹ˆë‹¤. 30ì´ˆ ë’¤ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                                else:
                                    st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")

# [ì—…ë°ì´íŠ¸] ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ í•¨ìˆ˜ ì¶”ê°€
def process_audio_and_find_jokbo(audio_bytes, db):
    """ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ê´€ë ¨ ì¡±ë³´ë¥¼ ì°¾ìŒ"""
    if not db: return "í•™ìŠµëœ ì¡±ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.", []
    
    # 1. Geminiì—ê²Œ ì˜¤ë””ì˜¤ë¥¼ ì£¼ê³  í…ìŠ¤íŠ¸ ë³€í™˜ ìš”ì²­ (STT)
    # 1.5-flashëŠ” ë©€í‹°ëª¨ë‹¬ì´ë¼ ì˜¤ë””ì˜¤ ì§ì ‘ ì…ë ¥ ê°€ëŠ¥
    model = genai.GenerativeModel("gemini-1.5-flash")
    
    # ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ì²˜ë¦¬
    prompt = "ì´ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ì •í™•í•˜ê²Œ ë°›ì•„ì¨ì¤˜(Transcribe)."
    
    try:
        # ì˜¤ë””ì˜¤ ë°ì´í„°ëŠ” ë°”ì´íŠ¸ ê·¸ëŒ€ë¡œ ë„˜ê¸°ê¸°ë³´ë‹¤, ì„ì‹œ íŒŒì¼ ì²˜ë¦¬í•˜ê±°ë‚˜ 
        # API êµ¬ì¡°ì— ë§ê²Œ Part ê°ì²´ë¡œ ë„˜ê²¨ì•¼ í•˜ì§€ë§Œ, 
        # ê°„í¸í•˜ê²ŒëŠ” í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì²˜ë¦¬í•˜ê¸°ë³´ë‹¤ generate_contentì— 
        # mime_typeì„ ì§€ì •í•œ blob ë°ì´í„°ë¥¼ ë„˜ê¸°ëŠ” ë°©ì‹ì´ ì¢‹ìŠµë‹ˆë‹¤.
        
        response = model.generate_content([
            prompt,
            {"mime_type": "audio/wav", "data": audio_bytes}
        ])
        transcribed_text = response.text
    except Exception as e:
        return f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", []

    # 2. ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¡œ ì¡±ë³´ ê²€ìƒ‰
    related_jokbo = find_relevant_jokbo(transcribed_text, db)
    
    return transcribed_text, related_jokbo

# ... (ê¸°ì¡´ get_embedding, find_relevant_jokbo í•¨ìˆ˜ ë™ì¼) ...

# ==========================================
# 4. ë©”ì¸ UI
# ==========================================
# íƒ­ êµ¬ì¡° ë³€ê²½: ì˜¤ë””ì˜¤ ê¸°ëŠ¥ íƒ­ ì¶”ê°€
tab1, tab2, tab3 = st.tabs(["ğŸ“‚ ì¡±ë³´ í•™ìŠµ", "ğŸ“– ê°•ì˜ ê³µë¶€", "ğŸ™ï¸ ì‹¤ì‹œê°„ ê°•ì˜ ë¶„ì„"])

# ... (tab1, tab2 ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼ ìœ ì§€) ...

# --- TAB 3: ì‹¤ì‹œê°„ ê°•ì˜ ë¶„ì„ (ì‹ ê·œ ê¸°ëŠ¥) ---
with tab3:
    st.header("3. ì‹¤ì‹œê°„ ê°•ì˜ ë“£ê¸° & ì¡±ë³´ ë§¤ì¹­")
    st.info("ê°•ì˜ë¥¼ ë“£ë‹¤ê°€ 'ì´ê±° ë‚˜ì˜¬ ê²ƒ ê°™ì€ë°?' ì‹¶ì„ ë•Œ ë…¹ìŒí•˜ì„¸ìš”.")

    # 1. ë…¹ìŒê¸° ìœ„ì ¯
    # start_prompt: ë…¹ìŒ ì‹œì‘ ë²„íŠ¼ í…ìŠ¤íŠ¸, stop_prompt: ì •ì§€ ë²„íŠ¼ í…ìŠ¤íŠ¸
    audio = mic_recorder(
        start_prompt="ğŸ”´ ë…¹ìŒ ì‹œì‘ (êµìˆ˜ë‹˜ ë§ì”€)",
        stop_prompt="â¹ï¸ ë¶„ì„ ì‹œì‘",
        key='recorder',
        format="wav" # wav í¬ë§· ê¶Œì¥
    )

    if audio:
        st.divider()
        st.subheader("ğŸ”Š ë¶„ì„ ê²°ê³¼")
        
        if not api_key:
            st.error("ì„¤ì • íƒ­ì—ì„œ API Keyë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not st.session_state.db:
            st.warning("ë¨¼ì € 'ì¡±ë³´ í•™ìŠµ' íƒ­ì—ì„œ ì¡±ë³´ë¥¼ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        else:
            with st.spinner("êµìˆ˜ë‹˜ ë§ì”€ ë°›ì•„ì“°ê¸° & ì¡±ë³´ ë’¤ì§€ëŠ” ì¤‘..."):
                # ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ê°€ì ¸ì˜¤ê¸°
                audio_bytes = audio['bytes']
                
                # ë¡œì§ ìˆ˜í–‰
                transcript, related = process_audio_and_find_jokbo(audio_bytes, st.session_state.db)
                
                # ê²°ê³¼ ì¶œë ¥ 1: ìŠ¤í¬ë¦½íŠ¸
                st.markdown(f"**ğŸ—£ï¸ êµìˆ˜ë‹˜ ë§ì”€ (STT):**")
                st.write(f"> {transcript}")
                
                # ê²°ê³¼ ì¶œë ¥ 2: ë§¤ì¹­ëœ ì¡±ë³´
                st.markdown(f"**ğŸ“„ ê´€ë ¨ ì¡±ë³´ ë‚´ìš©:**")
                context_str = ""
                for idx, item in enumerate(related):
                    with st.expander(f"ê´€ë ¨ ì¡±ë³´ #{idx+1} (ìœ ì‚¬ë„: {item['score']:.4f})"):
                        st.write(f"í˜ì´ì§€: {item['content']['page']}")
                        st.write(item['content']['text'])
                        context_str += f"- (í˜ì´ì§€ {item['content']['page']}) {item['content']['text']}\n"

                # ê²°ê³¼ ì¶œë ¥ 3: ìµœì¢… ì¸ì‚¬ì´íŠ¸ (AI ë¶„ì„)
                st.divider()
                st.markdown("### ğŸ©º Med-Study AIì˜ í†µì°°")
                
                if context_str:
                    final_prompt = f"""
                    ìƒí™©: ì˜ëŒ€ ê°•ì˜ ì¤‘ì…ë‹ˆë‹¤.
                    êµìˆ˜ë‹˜ ë§ì”€: {transcript}
                    
                    ê´€ë ¨ëœ ê³¼ê±° ì¡±ë³´ ë‚´ìš©:
                    {context_str}
                    
                    ë¯¸ì…˜:
                    1. êµìˆ˜ë‹˜ì˜ ë§ì”€ì´ ì¡±ë³´ì˜ ì–´ë–¤ ë¶€ë¶„ê³¼ ì—°ê²°ë˜ëŠ”ì§€ ë¶„ì„í•´.
                    2. "ì´ ë‚´ìš©ì€ ì¡±ë³´ Oí˜ì´ì§€ì˜ ë‚´ìš© ë³€í˜•ì…ë‹ˆë‹¤" ë˜ëŠ” "ì¡±ë³´ì—ëŠ” ì—†ë˜ ìƒˆë¡œìš´ ê°•ì¡°ì ì…ë‹ˆë‹¤" ì²˜ëŸ¼ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì í•´.
                    3. ì‹œí—˜ì— ì–´ë–»ê²Œ ë‚˜ì˜¬ì§€ ì˜ˆì¸¡í•´ì¤˜.
                    """
                    
                    model = genai.GenerativeModel("gemini-1.5-flash")
                    res = model.generate_content(final_prompt)
                    st.markdown(res.text)
                else:
                    st.write("ê´€ë ¨ëœ ì¡±ë³´ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ë‚´ìš©ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
