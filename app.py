import streamlit as st
import google.generativeai as genai
import fitz  # PyMuPDF
from PIL import Image
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# ==========================================
# 1. ì„¤ì • ë° ì´ˆê¸°í™”
# ==========================================
st.set_page_config(page_title="Med-Study OS Fixed", layout="wide", page_icon="ğŸ§¬")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ìƒˆë¡œê³ ì¹¨ í•´ë„ ë°ì´í„° ìœ ì§€)
if 'db' not in st.session_state: st.session_state.db = []  # ì¡±ë³´ ë°ì´í„° ì €ì¥ì†Œ
if 'lecture_doc' not in st.session_state: st.session_state.lecture_doc = None
if 'current_page' not in st.session_state: st.session_state.current_page = 0

# ==========================================
# 2. í•µì‹¬ í•¨ìˆ˜ (Logic)
# ==========================================

def get_best_model():
    """
    í˜„ì¬ API Keyë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì¤‘ ê°€ì¥ ì í•©í•œ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤.
    (NotFound Error ë°©ì§€ìš©)
    """
    try:
        # ìƒì„±(generateContent)ì´ ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # 1ìˆœìœ„: Flash (ë¹ ë¦„), 2ìˆœìœ„: Pro (ë˜‘ë˜‘í•¨), 3ìˆœìœ„: ì•„ë¬´ê±°ë‚˜
        for m in models:
            if 'flash' in m.lower(): return m
        for m in models:
            if 'pro' in m.lower(): return m
        
        return models[0] if models else None
    except Exception as e:
        st.error(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

def extract_text_from_pdf(file):
    """PDFë¥¼ í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    doc = fitz.open(stream=file.read(), filetype="pdf")
    pages_content = []
    for page_num, page in enumerate(doc):
        text = page.get_text()
        if text.strip():  # ë¹ˆ í˜ì´ì§€ ì œì™¸
            pages_content.append({
                "page": page_num + 1,
                "text": text,
                "source": file.name
            })
    return pages_content

def get_embedding(text):
    """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (ìµœì‹  ëª¨ë¸ ì‚¬ìš©)"""
    try:
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="retrieval_document"
        )
        return result['embedding']
    except Exception:
        # êµ¬í˜• ëª¨ë¸ í´ë°±(Fallback)
        try:
            result = genai.embed_content(
                model="models/embedding-001",
                content=text,
                task_type="retrieval_document"
            )
            return result['embedding']
        except Exception as e:
            st.error(f"ì„ë² ë”© ì˜¤ë¥˜: {e}")
            return []

def find_relevant_jokbo(query_text, db, top_k=3):
    """í˜„ì¬ ê°•ì˜ ë‚´ìš©ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì¡±ë³´ ë‚´ìš© ê²€ìƒ‰"""
    if not db: return []
    
    query_embedding = get_embedding(query_text)
    if not query_embedding: return []

    db_embeddings = [item['embedding'] for item in db]
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = cosine_similarity([query_embedding], db_embeddings)[0]
    
    # ìƒìœ„ Kê°œ ì¶”ì¶œ
    top_indices = np.argsort(similarities)[::-1][:top_k]
    
    results = []
    for idx in top_indices:
        results.append({
            "score": similarities[idx],
            "content": db[idx]
        })
    return results

# ==========================================
# 3. ì‚¬ì´ë“œë°” (API ì„¤ì •)
# ==========================================
with st.sidebar:
    st.title("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
    api_key = st.text_input("Gemini API Key", type="password")
    
    if api_key:
        genai.configure(api_key=api_key)
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸ ë° ëª¨ë¸ í™•ì¸
        try:
            model_name = get_best_model()
            if model_name:
                st.success(f"âœ… ì—°ê²° ì„±ê³µ! \nì‚¬ìš© ëª¨ë¸: {model_name.split('/')[-1]}")
            else:
                st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        except:
            st.error("âš ï¸ API Keyê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    st.divider()
    st.write(f"ğŸ“Š í•™ìŠµëœ ì¡±ë³´ ë°ì´í„°: {len(st.session_state.db)} í˜ì´ì§€")
    if st.button("ë°ì´í„° ì´ˆê¸°í™”"):
        st.session_state.db = []
        st.experimental_rerun()

# ==========================================
# 4. ë©”ì¸ UI
# ==========================================
tab1, tab2 = st.tabs(["ğŸ“‚ 1. ì¡±ë³´ í•™ìŠµ (Knowledge Base)", "ğŸ“– 2. ê°•ì˜ í•™ìŠµ (Study Mode)"])

# --- TAB 1: ì¡±ë³´ ë°ì´í„° êµ¬ì¶• ---
with tab1:
    st.header("1. ì¡±ë³´(ê¸°ì¶œë¬¸ì œ) ì—…ë¡œë“œ")
    st.caption("AIê°€ ì°¸ê³ í•  'ì§€ì‹ ë² ì´ìŠ¤'ë¥¼ ë§Œë“œëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.")
    
    uploaded_jokbo = st.file_uploader("ì¡±ë³´ PDF íŒŒì¼ë“¤ì„ ë“œë˜ê·¸í•˜ì„¸ìš”", accept_multiple_files=True, type="pdf")
    
    if st.button("ì¡±ë³´ í•™ìŠµ ì‹œì‘ ğŸš€"):
        if not api_key:
            st.warning("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ API Keyë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not uploaded_jokbo:
            st.warning("íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        else:
            progress_bar = st.progress(0)
            status = st.empty()
            
            new_db = []
            total_files = len(uploaded_jokbo)
            
            for idx, file in enumerate(uploaded_jokbo):
                status.text(f"ğŸ“– Reading: {file.name}...")
                pages = extract_text_from_pdf(file)
                
                status.text(f"ğŸ§  Embedding: {file.name} ({len(pages)} pages)...")
                for p in pages:
                    emb = get_embedding(p['text'])
                    if emb:
                        p['embedding'] = emb
                        new_db.append(p)
                
                progress_bar.progress((idx + 1) / total_files)
            
            st.session_state.db.extend(new_db)
            status.text("âœ… í•™ìŠµ ì™„ë£Œ!")
            st.success(f"ì´ {len(new_db)} í˜ì´ì§€ê°€ ì§€ì‹ ë² ì´ìŠ¤ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- TAB 2: ê°•ì˜ ë·°ì–´ ë° ë¶„ì„ ---
with tab2:
    st.header("2. ê°•ì˜ë¡ ë·°ì–´ & AI íŠœí„°")
    
    lecture_file = st.file_uploader("ì˜¤ëŠ˜ ê³µë¶€í•  ê°•ì˜ë¡ PDF", type="pdf", key="lecture")
    
    if lecture_file:
        # íŒŒì¼ ë¡œë“œ (ì„¸ì…˜ ìµœì í™”)
        if st.session_state.lecture_doc is None or st.session_state.lecture_doc.name != lecture_file.name:
            st.session_state.lecture_doc = fitz.open(stream=lecture_file.read(), filetype="pdf")
            st.session_state.current_page = 0
            
        doc = st.session_state.lecture_doc
        total_pages = len(doc)
        
        # í™”ë©´ ë¶„í•  (ì¢Œ: ë·°ì–´, ìš°: AI)
        col_view, col_ai = st.columns([6, 4])
        
        with col_view:
            st.markdown("#### ğŸ“„ PDF Viewer")
            # í˜ì´ì§€ ì»¨íŠ¸ë¡¤
            c1, c2, c3 = st.columns([1, 2, 1])
            if c1.button("â—€ ì´ì „"):
                if st.session_state.current_page > 0: st.session_state.current_page -= 1
            c2.markdown(f"<div style='text-align: center;'>Page {st.session_state.current_page + 1} / {total_pages}</div>", unsafe_allow_html=True)
            if c3.button("ë‹¤ìŒ â–¶"):
                if st.session_state.current_page < total_pages - 1: st.session_state.current_page += 1
            
            # PDF ë Œë”ë§
            page = doc.load_page(st.session_state.current_page)
            pix = page.get_pixmap(dpi=150)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            st.image(img, use_container_width=True)
            
            current_text = page.get_text()

        with col_ai:
            st.markdown("#### ğŸ¤– AI Analysis")
            
            if st.button("ì´ í˜ì´ì§€ ë¶„ì„í•˜ê¸° âš¡", type="primary"):
                if not api_key:
                    st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                elif len(st.session_state.db) == 0:
                    st.error("ê²½ê³ : í•™ìŠµëœ ì¡±ë³´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (Tab 1ì—ì„œ í•™ìŠµ í•„ìš”)")
                elif not current_text.strip():
                    st.warning("í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ëŠ” í˜ì´ì§€ì…ë‹ˆë‹¤. (ì´ë¯¸ì§€ ìœ„ì£¼)")
                else:
                    with st.spinner("ì¡±ë³´ì™€ ì—°ê²°ê³ ë¦¬ë¥¼ ì°¾ëŠ” ì¤‘..."):
                        try:
                            # 1. ëª¨ë¸ ìë™ ì„ íƒ
                            target_model = get_best_model()
                            if not target_model:
                                raise Exception("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì—†ìŒ")

                            # 2. ê´€ë ¨ ì¡±ë³´ ê²€ìƒ‰
                            related = find_relevant_jokbo(current_text, st.session_state.db)
                            
                            # 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
                            context_str = ""
                            for item in related:
                                context_str += f"- [ì¶œì²˜: {item['content']['source']} p.{item['content']['page']}] (ìœ ì‚¬ë„: {item['score']:.2f})\n...{item['content']['text'][:150]}...\n\n"
                            
                            prompt = f"""
                            ë‹¹ì‹ ì€ ì˜ëŒ€ìƒ íŠœí„°ì…ë‹ˆë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
                            
                            [í˜„ì¬ ê°•ì˜ ë‚´ìš©]:
                            {current_text}
                            
                            [ê´€ë ¨ëœ ì¡±ë³´(ê¸°ì¶œ)]:
                            {context_str}
                            
                            [ìš”ì²­ì‚¬í•­]:
                            1. **ê¸°ì¶œ ì—°ê³„ì„±**: ì´ ê°•ì˜ ë‚´ìš©ì´ ê³¼ê±° ì¡±ë³´ì™€ ì–´ë–»ê²Œ ì—°ê²°ë˜ëŠ”ì§€ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
                            2. **í•µì‹¬ í¬ì¸íŠ¸**: ì‹œí—˜ì— ë‚˜ì˜¬ë§Œí•œ í‚¤ì›Œë“œ 3ê°œë¥¼ ë½‘ì•„ì£¼ì„¸ìš”.
                            3. **ì˜ˆìƒ ë¬¸ì œ**: ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§§ì€ ê°ê´€ì‹ ë¬¸ì œë¥¼
