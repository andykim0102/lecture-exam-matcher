import os
import re
import sqlite3
import joblib
import pandas as pd
import streamlit as st
from pypdf import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ìŒì„± ì¸ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì„¤ì¹˜ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
try:
    import speech_recognition as sr
except ImportError:
    sr = None

# =========================
# 1. í™˜ê²½ ì„¤ì • ë° ì„¸ì…˜ ì´ˆê¸°í™”
# =========================
st.set_page_config(page_title="Med-Study AI Assistant", layout="wide")
APP_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(APP_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)

# ë°ì´í„° íë¦„ì„ ìœ ì§€í•˜ê¸° ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì •ì˜
if 'pre_analysis' not in st.session_state: st.session_state.pre_analysis = []
if 'bundle' not in st.session_state: st.session_state.bundle = None

# =========================
# 2. í•µì‹¬ ë¡œì§ í•¨ìˆ˜
# =========================
def db_connect(user_id):
    path = os.path.join(DATA_DIR, f"{user_id}.db")
    conn = sqlite3.connect(path)
    conn.execute("CREATE TABLE IF NOT EXISTS exam_db (id INTEGER PRIMARY KEY, text TEXT)")
    return conn

def get_pdf_text(file):
    reader = PdfReader(file)
    return [page.extract_text() or "" for page in reader.pages]

def build_index(conn):
    rows = conn.execute("SELECT id, text FROM exam_db").fetchall()
    if not rows: return None
    texts = [r[1] for r in rows]
    vec = TfidfVectorizer(ngram_range=(1, 2))
    mat = vec.fit_transform(texts)
    return {"vectorizer": vec, "matrix": mat, "ids": [r[0] for r in rows]}

# =========================
# 3. ë©”ì¸ UI í™”ë©´
# =========================
st.title("ğŸ©º ìŠ¤ë§ˆíŠ¸ ê°•ì˜ë¡-ì¡±ë³´ ë§¤ì¹­ ë¹„ì„œ")
user_id = st.sidebar.text_input("ì‚¬ìš©ì ID", "demo_user")
conn = db_connect(user_id)

tab1, tab2, tab3 = st.tabs(["ğŸ“… ìˆ˜ì—… ì „: ìë™ ì •ë¦¬", "ğŸ¤ ìˆ˜ì—… ì¤‘: ì‹¤ì‹œê°„ ë§¤ì¹­", "ğŸ¯ ìˆ˜ì—… í›„: ë³µìŠµ ë¦¬í¬íŠ¸"])

# --- [Step 1: ìˆ˜ì—… ì „ ì‚¬ì „ ë¶„ì„] ---
with tab1:
    st.header("ì˜¤ëŠ˜ ìˆ˜ì—…í•  íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤")
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("1ë‹¨ê³„: ì¡±ë³´ ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬ì¶•")
        exam_files = st.file_uploader("ì¡±ë³´ PDF ë“±ë¡", type="pdf", accept_multiple_files=True)
        if st.button("ì¡±ë³´ DB ì €ì¥ ë° ì¸ë±ì‹±"):
            for f in exam_files:
                texts = get_pdf_text(f)
                conn.executemany("INSERT INTO exam_db (text) VALUES (?)", [(t,) for t in texts if t.strip()])
            conn.commit()
            st.session_state.bundle = build_index(conn)
            st.success("ì¡±ë³´ ì¸ë±ì‹±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    with col2:
        st.subheader("2ë‹¨ê³„: ì˜¤ëŠ˜ ê°•ì˜ë¡ ë¶„ì„")
        lec_file = st.file_uploader("ìˆ˜ì—…ìš© ê°•ì˜ë¡ PDF", type="pdf")
        if lec_file and st.button("ìˆ˜ì—… ì „ ìë™ ë‹¨ê¶Œí™” ì‹¤í–‰"):
            if st.session_state.bundle:
                lec_pages = get_pdf_text(lec_file)
                bundle = st.session_state.bundle
                
                analysis = []
                for i, p_text in enumerate(lec_pages):
                    if not p_text.strip(): continue
                    qv = bundle["vectorizer"].transform([p_text])
                    sims = cosine_similarity(qv, bundle["matrix"]).flatten()
                    if sims.max() > 0.2: # ìœ ì‚¬ë„ ê¸°ì¤€ê°’
                        best_idx = sims.argmax()
                        exam_txt = conn.execute("SELECT text FROM exam_db WHERE id=?", (bundle["ids"][best_idx],)).fetchone()[0]
                        analysis.append({"page": i+1, "score": sims.max(), "exam_text": exam_txt})
                
                st.session_state.pre_analysis = analysis
                st.success(f"ë¶„ì„ ì™„ë£Œ! {len(analysis)}ê°œ í˜ì´ì§€ì—ì„œ ê¸°ì¶œ í”ì  ë°œê²¬.")
            else:
                st.error("ë¨¼ì € ì¡±ë³´ ì¸ë±ì‹±ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”.")

# --- [Step 2: ìˆ˜ì—… ì¤‘ ì‹¤ì‹œê°„ ë§¤ì¹­] ---
with tab2:
    st.header("êµìˆ˜ë‹˜ ì„¤ëª… ì‹¤ì‹œê°„ íŠ¸ë˜í‚¹")
    if not st.session_state.pre_analysis:
        st.warning("ìˆ˜ì—… ì „ ë¶„ì„ì„ ë¨¼ì € ì™„ë£Œí•´ ì£¼ì„¸ìš”.")
    else:
        st.info("êµìˆ˜ë‹˜ì˜ ì„¤ëª…ì„ ë“£ê³  ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš© ì¤‘ ì¡±ë³´ ê´€ë ¨ ë‚´ìš©ì„ ì¦‰ì‹œ ë„ì›ë‹ˆë‹¤.")
        
        # ìŒì„± ì¸ì‹ UI
        if sr is None:
            st.error("SpeechRecognition ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            if st.button("ğŸ¤ êµìˆ˜ë‹˜ ì„¤ëª… ë“£ê¸° (10ì´ˆ)"):
                r = sr.Recognizer()
                with sr.Microphone() as source:
                    with st.spinner("ë“£ëŠ” ì¤‘..."):
                        try:
                            audio = r.listen(source, timeout=10)
                            text = r.recognize_google(audio, language='ko-KR')
                            st.subheader(f"ì¸ì‹ëœ ë‚´ìš©: {text}")
                            
                            # ì‹¤ì‹œê°„ ë§¤ì¹­ ë¡œì§
                            for item in st.session_state.pre_analysis:
                                if any(word in item['exam_text'] for word in text.split()):
                                    st.warning(f"ğŸš¨ **ì§€ê¸ˆ ì„¤ëª… ì¤‘ì¸ ë‚´ìš©ì´ {item['page']}í˜ì´ì§€ ì¡±ë³´ì™€ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤!**")
                                    st.write(f"ê¸°ì¶œ ìš”ì•½: {item['exam_text'][:200]}...")
                        except:
                            st.error("ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë§ˆì´í¬ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")

# --- [Step 3: ìˆ˜ì—… í›„ ë³µìŠµ ë¦¬í¬íŠ¸] ---
with tab3:
    st.header("ì˜¤ëŠ˜ì˜ ë‹¨ê¶Œí™” ìš”ì•½")
    if st.session_state.pre_analysis:
        df = pd.DataFrame(st.session_state.pre_analysis)
        st.table(df[['page', 'score']])
        
        # Ankiìš© ë°ì´í„° ì¶”ì¶œ
        anki_csv = df[['page', 'exam_text']].to_csv(index=False).encode('utf-8')
        st.download_button("ğŸ“¥ ì˜¤ëŠ˜ ê¸°ì¶œ ê¸°ë°˜ Anki ì¹´ë“œ ë‹¤ìš´ë¡œë“œ", anki_csv, "anki_cards.csv", "text/csv")
    else:
        st.write("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
