# app.py (UI: Photo-Like Card Style / Logic: Full Features Restored)
import time
import re
import random
import numpy as np
import fitz  # PyMuPDF
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st
import google.generativeai as genai
from google.api_core import retry, exceptions

# ==========================================
# 0. Page config & Custom CSS
# ==========================================
st.set_page_config(page_title="Med-Study OS", layout="wide", page_icon="ğŸ©º")

# Custom CSS for UI Enhancement
st.markdown("""
<style>
    /* 1. Global Settings */
    .stApp { background-color: #f8f9fa; } 
    h1, h2, h3, h4, h5, h6, p, span, div, label, .stMarkdown { color: #1c1c1e !important; }
    
    /* 2. Custom Badge Styles */
    .badge-base {
        padding: 4px 8px;
        border-radius: 6px;
        font-size: 0.75rem;
        font-weight: 700;
        margin-right: 6px;
        display: inline-block;
        white-space: nowrap;
    }
    .badge-blue { background-color: #e3f2fd; color: #1565c0; border: 1px solid #bbdefb; }
    .badge-red { background-color: #ffebee; color: #c62828; border: 1px solid #ffcdd2; }
    .badge-gray { background-color: #f5f5f5; color: #616161; border: 1px solid #e0e0e0; }
    .badge-green { background-color: #e8f5e9; color: #2e7d32; border: 1px solid #c8e6c9; }
    
    /* 3. Question Text Styles */
    .q-title {
        font-size: 1.1rem;
        font-weight: 700;
        color: #212121 !important;
        margin: 12px 0 8px 0;
        line-height: 1.5;
    }
    .q-body {
        font-size: 0.95rem;
        color: #424242 !important;
        background-color: #fafafa;
        padding: 12px;
        border-radius: 8px;
        line-height: 1.6;
        white-space: pre-wrap;
        border: 1px solid #f0f0f0;
    }
    
    /* 4. Dashed Divider */
    .dashed-line {
        border-top: 2px dashed #e0e0e0;
        margin: 16px 0;
    }

    /* 5. Sidebar & Buttons */
    div.stButton > button { border-radius: 10px; font-weight: 600; border: none; box-shadow: none; background-color: #f1f3f5; height: 2.8rem; }
    div.stButton > button:hover { background-color: #e9ecef; transform: scale(0.99); }
    div.stButton > button[kind="primary"] { background-color: #007aff; color: white; }
    div.stButton > button[kind="primary"] p { color: #ffffff !important; }
    
    /* 6. Layout Utils */
    .block-container { padding-top: 1.5rem !important; }
    header[data-testid="stHeader"] { display: none; }
    
    /* 7. Expander Styling Override */
    .streamlit-expanderHeader {
        font-size: 0.9rem;
        font-weight: 600;
        color: #555;
        background-color: #fff;
        border: 1px solid #eee;
        border-radius: 8px;
    }
</style>
""", unsafe_allow_html=True)


# ==========================================
# 1. Session state initialization
# ==========================================
defaults = {
    "logged_in": False, "db": [], "api_key": None, "api_key_ok": False,
    "text_models": [], "embedding_models": [], "best_text_model": None, "best_embedding_model": None,
    "lecture_doc": None, "lecture_filename": None, "current_page": 0,
    "edit_target_subject": None, "subject_detail_view": None, "t2_selected_subject": None,
    "transcribed_text": "", "chat_history": [],
    "last_page_sig": None, "last_ai_sig": None, "last_ai_text": "", "last_related": [],
    "tr_res": None # [Restored] Transcript Result Cache
}

for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

# ==========================================
# 2. Login Logic
# ==========================================
def login():
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        st.markdown("<div style='height: 15vh;'></div>", unsafe_allow_html=True)
        st.markdown(
            """
            <div style="text-align: center;">
                <div style="font-size: 5rem; margin-bottom: 10px;">ğŸ©º</div>
                <h1 style="font-weight: 800; margin-bottom: 0; color: #1c1c1e;">Med-Study OS</h1>
                <p style="color: #8e8e93; margin-bottom: 30px;">ìŠ¤ë§ˆíŠ¸í•œ ì˜ëŒ€ ì¡±ë³´ ë¶„ì„ê¸°</p>
            </div>
            """, 
            unsafe_allow_html=True
        )
        with st.container(border=True):
            st.markdown("#### ë¡œê·¸ì¸")
            username = st.text_input("ì•„ì´ë””", placeholder="admin")
            password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", placeholder="1234")
            
            if st.button("ì•± ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
                if password == "1234":
                    st.session_state.logged_in = True
                    st.rerun()
                else:
                    st.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤. (Demo: 1234)")
            st.markdown("<div style='text-align:center; margin-top:15px; font-size:0.8rem; color:#c7c7cc;'>Demo Access: admin / 1234</div>", unsafe_allow_html=True)

def logout():
    st.session_state.logged_in = False
    st.rerun()


# ==========================================
# 3. Helpers & Data Logic
# ==========================================
def ensure_configured():
    if st.session_state.get("api_key"):
        genai.configure(api_key=st.session_state["api_key"])

@st.cache_data(show_spinner=False)
def list_available_models(api_key: str):
    try:
        genai.configure(api_key=api_key)
        all_models = list(genai.list_models())
        text_mods = [m.name for m in all_models if "generateContent" in getattr(m, "supported_generation_methods", [])]
        embed_mods = [m.name for m in all_models if "embedContent" in getattr(m, "supported_generation_methods", [])]
        return text_mods, embed_mods
    except Exception as e:
        return [], []

def get_best_model(models, keywords):
    if not models: return None
    for k in keywords:
        found = [m for m in models if k in m]
        if found: return found[0]
    return models[0]

# [Robust Embedding]
def get_embedding_robust(text: str, status_placeholder=None):
    text = (text or "").strip()
    if len(text) < 50: return None, "text_too_short"
    ensure_configured()
    
    if not st.session_state.embedding_models:
        _, embs = list_available_models(st.session_state.api_key)
        st.session_state.embedding_models = embs
    
    candidates = st.session_state.embedding_models
    if not candidates: return None, "No embedding models available."
    sorted_candidates = sorted(candidates, key=lambda x: 0 if 'text-embedding-004' in x else 1)
    
    max_retries = 5
    base_wait = 2
    
    for model_name in sorted_candidates[:2]:
        for attempt in range(max_retries):
            try:
                time.sleep(1.2) 
                if "004" in model_name:
                    res = genai.embed_content(model=model_name, content=text, task_type="retrieval_document")
                else:
                    res = genai.embed_content(model=model_name, content=text)
                if res and "embedding" in res:
                    return res["embedding"], None
            except Exception as e:
                err_msg = str(e)
                if "429" in err_msg or "Resource exhausted" in err_msg:
                    wait_time = base_wait * (2 ** attempt) + random.randint(1, 3)
                    if status_placeholder:
                        status_placeholder.caption(f"âš ï¸ {model_name} ì‚¬ìš©ëŸ‰ ì´ˆê³¼. {wait_time}ì´ˆ ëŒ€ê¸° ì¤‘...")
                    time.sleep(wait_time)
                elif "404" in err_msg or "Not Found" in err_msg:
                    break
                else:
                    time.sleep(1)
    return None, f"Fail: API Error"

def filter_db_by_subject(subject: str, db: list[dict]):
    if not db: return []
    if subject in ["ì „ì²´", "ALL", ""]: return db
    return [x for x in db if x.get("subject") == subject]

def find_relevant_jokbo(query_text: str, db: list[dict], top_k: int = 10):
    if not db: return []
    query_emb, _ = get_embedding_robust(query_text)
    if not query_emb: return []
    
    valid_items = [item for item in db if item.get("embedding")]
    if not valid_items: return []
    db_embs = [item["embedding"] for item in valid_items]
    
    sims = cosine_similarity([query_emb], db_embs)[0]
    top_idxs = np.argsort(sims)[::-1][:top_k]
    return [{"score": float(sims[i]), "content": valid_items[i]} for i in top_idxs]

def generate_with_fallback(prompt: str, model_names: list[str]):
    ensure_configured()
    target_model = st.session_state.best_text_model or "gemini-1.5-flash"
    candidates = [target_model]
    if model_names: candidates.extend(model_names)
    candidates = list(dict.fromkeys(candidates))
    
    last_err = None
    config = genai.GenerationConfig(temperature=0.3)
    
    for name in candidates:
        try:
            model = genai.GenerativeModel(name, generation_config=config)
            res = model.generate_content(prompt)
            if res.text: return res.text, name
        except Exception as e: 
            last_err = e
            continue
    raise Exception(f"AI ì‘ë‹µ ì‹¤íŒ¨: {str(last_err)}")

def transcribe_image_to_text(image, api_key, model_name=None):
    try:
        genai.configure(api_key=api_key)
        target_model = model_name if model_name else "gemini-1.5-flash"
        model = genai.GenerativeModel(target_model)
        response = model.generate_content([
            "Extract all text from this image exactly as is. Organize by question number if possible.",
            image
        ])
        return response.text
    except Exception:
        return None

def transcribe_audio_gemini(audio_bytes, api_key):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content([
            "Please transcribe the following audio file into text accurately. Do not add any conversational text, just the transcription.",
            {"mime_type": "audio/wav", "data": audio_bytes}
        ])
        return response.text
    except Exception as e:
        return None

# [Metadata Parser]
def parse_metadata_from_filename(filename):
    """íŒŒì¼ëª…ì—ì„œ ì—°ë„, í•™ê¸°, ì‹œí—˜ ì¢…ë¥˜ ì¶”ì¶œ"""
    year = ""
    exam_type = ""
    
    year_match = re.search(r'(20\d{2})', filename)
    if year_match: year = year_match.group(1)
    
    if "ì¤‘ê°„" in filename: exam_type = "ì¤‘ê°„"
    elif "ê¸°ë§" in filename: exam_type = "ê¸°ë§"
    elif "ëª¨ì˜" in filename: exam_type = "ëª¨ì˜"
    elif "êµ­ì‹œ" in filename: exam_type = "êµ­ì‹œ"
    
    full_meta = f"{year} {exam_type}".strip()
    return full_meta if full_meta else "ê¸°ì¶œ"

# --- Prompts ---
def build_overview_prompt(first_page_text, subject):
    return f"ê³¼ëª©: {subject}\në‚´ìš©: {first_page_text[:1500]}\nì´ ê°•ì˜ì˜ í•µì‹¬ ëª©í‘œì™€ ì¡±ë³´ ê¸°ë°˜ ê³µë¶€ ì „ëµ 3ê°€ì§€ë¥¼ ìš”ì•½í•´ì¤˜."

def build_page_analysis_prompt(lecture_text, related_jokbo, subject):
    jokbo_ctx = "\n".join([f"- {r['content']['text'][:300]}" for r in related_jokbo[:3]])
    return f"""
    ë„ˆëŠ” ì˜ëŒ€ ìˆ˜ì„ ì¡°êµë‹¤. í•™ìƒì´ ê³µë¶€ ì¤‘ì¸ í˜ì´ì§€ì™€ ê´€ë ¨ëœ ì¡±ë³´ë¥¼ ë¶„ì„í•´ë¼.
    ê³¼ëª©: {subject}
    
    [ê´€ë ¨ ì¡±ë³´]
    {jokbo_ctx}
    
    [ê°•ì˜ ë‚´ìš©]
    {lecture_text[:1500]}
    
    ë‹¤ìŒ 3ê°€ì§€ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥í•˜ë¼.
    [SECTION: DIRECTION] ì´ í˜ì´ì§€ì—ì„œ ì‹œí—˜ì— ë‚˜ì˜¬ë§Œí•œ í•µì‹¬ í¬ì¸íŠ¸ (1~2ë¬¸ì¥)
    [SECTION: TWIN_Q] ì¡±ë³´ì™€ ìœ ì‚¬í•œ ë³€í˜• ë¬¸ì œ (ê°ê´€ì‹) í•˜ë‚˜ ë§Œë“¤ê¸°
    [SECTION: EXPLANATION] ìœ„ ë³€í˜• ë¬¸ì œì˜ ì •ë‹µ ë° ìƒì„¸ í•´ì„¤
    """

def build_chat_prompt(history, context_text, related_jokbo, question):
    jokbo_ctx = "\n".join([f"- {r['content']['text'][:300]}" for r in related_jokbo[:3]])
    return f"ì§ˆë¬¸: {question}\nê°•ì˜ë‚´ìš©: {context_text[:1000]}\nì¡±ë³´: {jokbo_ctx}\në‹µë³€í•´ì£¼ì„¸ìš”."

# [Restored] Transcript Prompt
def build_transcript_prompt(chunks, related_packs, subject):
    packed = ""
    for idx, (chunk, rel) in enumerate(zip(chunks, related_packs), 1):
        if not has_jokbo_evidence(rel): continue
        ctx = "\n".join([f"- {r['content']['text'][:200]}" for r in rel[:2]])
        packed += f"\n(êµ¬ê°„ {idx})\n[ê°•ì˜] {chunk}\n[ì¡±ë³´ê·¼ê±°] {ctx}\n"
    
    if not packed: return "ì¡±ë³´ì™€ ê´€ë ¨ëœ íŠ¹ë³„í•œ ë‚´ìš©ì€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ìš”ì•½ì…ë‹ˆë‹¤."
    
    return f"""
    ë‹¹ì‹ ì€ ì˜ëŒ€ ì¡°êµì…ë‹ˆë‹¤. ê°•ì˜ ì „ì‚¬ ë‚´ìš©ì„ ì¡±ë³´ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”.
    ê³¼ëª©: {subject}
    
    {packed}
    
    ì¶œë ¥ í˜•ì‹:
    [ì¡±ë³´ ì ì¤‘ ë…¸íŠ¸]
    1. í•µì‹¬ ì£¼ì œ (ê´€ë ¨ ì¡±ë³´ ì—°ê³„)
    2. êµìˆ˜ë‹˜ì´ ê°•ì¡°í•œ ë‚´ìš©
    """

def chunk_transcript(text: str, max_chars: int = 900):
    parts = [p.strip() for p in re.split(r"\n\s*\n", text) if p.strip()]
    chunks = []
    for p in parts:
        if len(p) <= max_chars: chunks.append(p)
        else:
            for i in range(0, len(p), max_chars):
                chunks.append(p[i:i+max_chars])
    return chunks

def extract_text_from_pdf(uploaded_file):
    try:
        data = uploaded_file.getvalue()
        doc = fitz.open(stream=data, filetype="pdf")
        return doc
    except: return None

# --- Stat Helpers ---
def get_subject_files(subject):
    files = {}
    for item in st.session_state.db:
        if item.get("subject") == subject:
            src = item.get("source", "Unknown")
            files[src] = files.get(src, 0) + 1
    return files

def get_subject_stats():
    stats = {}
    for item in st.session_state.db:
        subj = item.get("subject", "ê¸°íƒ€")
        if subj not in stats: stats[subj] = {"count": 0, "last_updated": "ë°©ê¸ˆ ì „"}
        stats[subj]["count"] += 1
    return stats

def has_jokbo_evidence(related: list[dict]) -> bool:
    return bool(related) and related[0]["score"] >= 0.70


# ==========================================
# 4. Main App UI
# ==========================================

if not st.session_state.logged_in:
    login()
    st.stop()

# --- Sidebar ---
with st.sidebar:
    st.markdown("### ğŸ‘¤ ë‚´ í”„ë¡œí•„")
    with st.container(border=True):
        c1, c2 = st.columns([1, 3])
        c1.markdown("## ğŸ‘¨â€âš•ï¸")
        c2.markdown("**Student Admin**\n\n<span style='color:gray; font-size:0.8em'>ë³¸ê³¼ 2í•™ë…„</span>", unsafe_allow_html=True)
        if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True): logout()

    st.markdown("### ğŸ“š ë‚´ í•™ìŠµ ê³¼ëª©")
    my_subjects = sorted({x.get("subject", "ê¸°íƒ€") for x in st.session_state.db})
    if my_subjects:
        for s in my_subjects:
            st.markdown(f"<div class='sidebar-subject'>ğŸ“˜ {s}</div>", unsafe_allow_html=True)
    else:
        st.caption("ë“±ë¡ëœ ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.divider()

    st.markdown("### âš™ï¸ ì„¤ì •")
    with st.container(border=True):
        api_key_input = st.text_input("Gemini API Key", type="password", key="api_key_input")
        if api_key_input: st.session_state.api_key = api_key_input.strip()
            
        if st.button("ğŸ”„ ëª¨ë¸ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° (ì—°ê²° í…ŒìŠ¤íŠ¸)", use_container_width=True):
            if not st.session_state.api_key:
                st.error("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with st.spinner("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì°¾ëŠ” ì¤‘..."):
                    t_mods, e_mods = list_available_models(st.session_state.api_key)
                    if t_mods and e_mods:
                        st.session_state.api_key_ok = True
                        st.session_state.text_models = t_mods
                        st.session_state.embedding_models = e_mods
                        st.session_state.best_text_model = get_best_model(t_mods, ["flash", "pro"])
                        st.session_state.best_embedding_model = get_best_model(e_mods, ["text-embedding-004", "004"])
                        st.success(f"âœ… ì—°ê²° ì„±ê³µ! ({st.session_state.best_text_model})")
                    else:
                        st.error("ğŸš« ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    st.markdown("### ğŸ“Š DB í˜„í™©")
    with st.container(border=True):
        st.metric("ì´ í•™ìŠµ í˜ì´ì§€", len(st.session_state.db))
        if st.button("DB ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.db = []
            st.rerun()

# --- Main Content ---
st.title("Med-Study OS")

tab1, tab2, tab3 = st.tabs(["ğŸ“‚ ì¡±ë³´ ê´€ë¦¬", "ğŸ“– ê°•ì˜ ë¶„ì„", "ğŸ™ï¸ ê°•ì˜ ë…¹ìŒ/ë¶„ì„"])

# --- TAB 1: ì¡±ë³´ ê´€ë¦¬ ---
with tab1:
    if st.session_state.subject_detail_view:
        target_subj = st.session_state.subject_detail_view
        c_back, c_title = st.columns([1, 5])
        with c_back:
            if st.button("â† ëª©ë¡"):
                st.session_state.subject_detail_view = None
                st.rerun()
        with c_title: st.markdown(f"### ğŸ“‚ {target_subj} íŒŒì¼ ëª©ë¡")
        st.divider()
        file_map = get_subject_files(target_subj)
        for fname, count in file_map.items():
            meta = parse_metadata_from_filename(fname)
            with st.container(border=True):
                c1, c2 = st.columns([5, 1])
                c1.markdown(f"**ğŸ“„ {fname}**")
                c1.markdown(f"<span class='badge-base badge-blue'>{meta}</span>", unsafe_allow_html=True)
                c2.caption(f"{count} pages")
    else:
        col_upload, col_list = st.columns([1, 2])
        with col_upload:
            with st.container(border=True):
                st.markdown("#### â• ì¡±ë³´ ì¶”ê°€")
                up_subj = st.selectbox("ê³¼ëª©", ["í•´ë¶€í•™", "ìƒë¦¬í•™", "ì•½ë¦¬í•™", "ì§ì ‘ì…ë ¥"], key="up_subj")
                if up_subj == "ì§ì ‘ì…ë ¥":
                    up_subj_custom = st.text_input("ê³¼ëª©ëª… ì…ë ¥", placeholder="ì˜ˆ: ë³‘ë¦¬í•™")
                    final_subj = up_subj_custom if up_subj_custom else "ê¸°íƒ€"
                else: final_subj = up_subj
                
                files = st.file_uploader("PDF ì„ íƒ", accept_multiple_files=True, type="pdf")
                
                if st.button("í•™ìŠµ ì‹œì‘", type="primary", use_container_width=True):
                    if not st.session_state.api_key_ok: st.error("ì™¼ìª½ ì„¤ì •ì—ì„œ ëª¨ë¸ ì—°ê²°ì„ ë¨¼ì € í•´ì£¼ì„¸ìš”!")
                    elif not files: st.warning("íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    else:
                        prog_bar = st.progress(0)
                        with st.expander("ğŸ“ ì²˜ë¦¬ ë¡œê·¸", expanded=True):
                            log_c = st.empty()
                            logs = []
                            def log(m):
                                logs.append(m)
                                log_c.markdown("\n".join([f"- {l}" for l in logs[-5:]]))

                            new_db = []
                            for i, f in enumerate(files):
                                try:
                                    log(f"ğŸ“‚ {f.name} ë¶„ì„ ì‹œì‘...")
                                    doc = fitz.open(stream=f.getvalue(), filetype="pdf")
                                    
                                    for p_idx, page in enumerate(doc):
                                        text = page.get_text().strip()
                                        # OCR Fallback
                                        if len(text) < 50:
                                            try:
                                                pix = page.get_pixmap()
                                                img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                                                ocr_text = transcribe_image_to_text(img, st.session_state.api_key, st.session_state.best_text_model)
                                                if ocr_text: text = ocr_text
                                            except: pass

                                        emb, err = get_embedding_robust(text, st.empty())
                                        if emb:
                                            new_db.append({
                                                "page": p_idx + 1, "text": text, "source": f.name,
                                                "embedding": emb, "subject": final_subj
                                            })
                                        elif err != "text_too_short":
                                            log(f"âš ï¸ P.{p_idx+1} ì‹¤íŒ¨ ({err})")
                                    
                                    log(f"âœ… {f.name} ì™„ë£Œ")
                                except Exception as e:
                                    log(f"âŒ ì˜¤ë¥˜: {str(e)}")
                                prog_bar.progress((i + 1) / len(files))
                            
                            if new_db:
                                st.session_state.db.extend(new_db)
                                st.success(f"{len(new_db)} í˜ì´ì§€ í•™ìŠµ ì™„ë£Œ!")
                                time.sleep(1)
                                st.rerun()
                            else: st.warning("ì €ì¥ëœ ë°ì´í„° ì—†ìŒ")

        with col_list:
            st.markdown("#### ğŸ“š í•™ìŠµ ë°ì´í„°")
            stats = get_subject_stats()
            subjects = sorted(stats.keys())
            for i in range(0, len(subjects), 2):
                cols = st.columns(2)
                for j in range(2):
                    if i + j < len(subjects):
                        s = subjects[i+j]
                        with cols[j]:
                            with st.container(border=True):
                                c1, c2 = st.columns([4, 1])
                                if c1.button(f"## {s}", key=f"v_{s}"):
                                    st.session_state.subject_detail_view = s
                                    st.rerun()
                                if c2.button("âœï¸", key=f"e_{s}"): pass
                                st.markdown(f"**{stats[s]['count']}** pages")

# --- TAB 2: ê°•ì˜ ë¶„ì„ (Photo-Like Card UI) ---
with tab2:
    if st.session_state.t2_selected_subject is None:
        st.info("ê³¼ëª©ì„ ì„ íƒí•˜ì„¸ìš”.")
        stats = get_subject_stats()
        cols = st.columns(3)
        for i, s in enumerate(stats):
            if cols[i%3].button(f"## {s}", key=f"t2_{s}", use_container_width=True):
                st.session_state.t2_selected_subject = s
                st.rerun()
    else:
        target_subj = st.session_state.t2_selected_subject
        c_back, c_head = st.columns([1, 5])
        if c_back.button("â† ë’¤ë¡œ"):
            st.session_state.t2_selected_subject = None
            st.rerun()
        c_head.markdown(f"#### ğŸ“– {target_subj} ë¶„ì„")
        
        with st.expander("ğŸ“‚ ê°•ì˜ PDF ì—´ê¸°", expanded=(st.session_state.lecture_doc is None)):
            l_file = st.file_uploader("PDF", type="pdf", key="t2_f", label_visibility="collapsed")
            if l_file and l_file.name != st.session_state.lecture_filename:
                st.session_state.lecture_doc = fitz.open(stream=l_file.getvalue(), filetype="pdf")
                st.session_state.lecture_filename = l_file.name
                st.session_state.current_page = 0
                st.session_state.last_page_sig = None

        if st.session_state.lecture_doc:
            doc = st.session_state.lecture_doc
            c_view, c_ai = st.columns([1.5, 1.2])
            
            with c_view:
                with st.container(border=True):
                    c1, c2, c3 = st.columns([1, 2, 1])
                    if c1.button("â—€"): st.session_state.current_page = max(0, st.session_state.current_page-1)
                    c2.markdown(f"<div style='text-align:center;'><b>Page {st.session_state.current_page+1}</b></div>", unsafe_allow_html=True)
                    if c3.button("â–¶"): st.session_state.current_page = min(len(doc)-1, st.session_state.current_page+1)
                    
                    page = doc.load_page(st.session_state.current_page)
                    pix = page.get_pixmap(dpi=150)
                    st.image(Image.frombytes("RGB", [pix.width, pix.height], pix.samples), use_container_width=True)
                    
                    p_text = page.get_text().strip()
                    if len(p_text) < 50:
                        try:
                            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                            with st.spinner("ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¸ì‹ ì¤‘..."):
                                ocr_res = transcribe_image_to_text(img, st.session_state.api_key, st.session_state.best_text_model)
                                if ocr_res: p_text = ocr_res
                        except: pass

            with c_ai:
                ai_tab1, ai_tab2 = st.tabs(["ğŸ“ ì¡±ë³´ ë§¤ì¹­", "ğŸ’¬ ì§ˆì˜ì‘ë‹µ"])
                
                with ai_tab1:
                    if not p_text:
                        st.info("í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        psig = hash(p_text)
                        if psig != st.session_state.last_page_sig:
                            st.session_state.last_page_sig = psig
                            sub_db = filter_db_by_subject(target_subj, st.session_state.db)
                            st.session_state.last_related = find_relevant_jokbo(p_text, sub_db, top_k=10)
                            st.session_state.last_ai_sig = None
                        
                        rel = st.session_state.last_related
                        
                        if has_jokbo_evidence(rel):
                            if st.session_state.api_key_ok:
                                aisig = (psig, target_subj)
                                if aisig != st.session_state.last_ai_sig:
                                    with st.spinner("AI ë¶„ì„ ì¤‘..."):
                                        prmt = build_page_analysis_prompt(p_text, rel, target_subj)
                                        raw, _ = generate_with_fallback(prmt, st.session_state.text_models)
                                        parsed = {"DIRECTION": "", "TWIN_Q": "", "EXPLANATION": ""}
                                        parts = raw.split("[SECTION:")
                                        for p in parts:
                                            if "DIRECTION]" in p: parsed["DIRECTION"] = p.replace("DIRECTION]", "").strip()
                                            elif "TWIN_Q]" in p: parsed["TWIN_Q"] = p.replace("TWIN_Q]", "").strip()
                                            elif "EXPLANATION]" in p: parsed["EXPLANATION"] = p.replace("EXPLANATION]", "").strip()
                                        st.session_state.last_ai_text = parsed
                                        st.session_state.last_ai_sig = aisig
                            
                            res_ai = st.session_state.last_ai_text
                            
                            high_rel_count = len([r for r in rel if r['score'] > 0.82])
                            
                            for i, r in enumerate(rel[:2]):
                                score = r['score']
                                src = r['content'].get('source', 'Unknown')
                                txt = r['content'].get('text', '')[:250]
                                meta = parse_metadata_from_filename(src)
                                
                                freq_html = ""
                                if i == 0 and high_rel_count >= 2:
                                    freq_html = f"<span class='badge-base badge-red'>â˜… ì¤‘ìš” ({high_rel_count}íšŒ ì¶œì œ)</span>"
                                elif score > 0.88:
                                    freq_html = "<span class='badge-base badge-red'>â˜… ë§¤ìš° ìœ ì‚¬</span>"
                                
                                with st.container(border=True):
                                    st.markdown(f"<div><span class='badge-base badge-blue'>ê¸°ì¶œ</span>{freq_html}<span class='badge-base badge-gray'>{meta}</span></div>", unsafe_allow_html=True)
                                    st.markdown(f"<div class='q-title'>Q. ë‹¤ìŒ ì¤‘... (ìë™ìš”ì•½)</div>", unsafe_allow_html=True)
                                    st.markdown(f"<div class='q-body'>{txt}...</div>", unsafe_allow_html=True)
                                    st.markdown("<div class='dashed-line'></div>", unsafe_allow_html=True)
                                    
                                    c1, c2, c3 = st.columns(3)
                                    with c1:
                                        with st.expander("ğŸ“ ì •ë‹µ/í•´ì„¤"):
                                            if i == 0 and isinstance(res_ai, dict): st.write(res_ai.get("EXPLANATION", "ìƒì„± ì¤‘..."))
                                            else: st.caption("AI í•´ì„¤ ë¯¸ì œê³µ")
                                    with c2:
                                        with st.expander("ğŸ¯ ì¶œì œí¬ì¸íŠ¸"):
                                            if i == 0 and isinstance(res_ai, dict): st.write(res_ai.get("DIRECTION", "ìƒì„± ì¤‘..."))
                                            else: st.caption("ë‚´ìš© ì—†ìŒ")
                                    with c3:
                                        with st.expander("ğŸ”„ ìŒë‘¥ì´ë¬¸ì œ"):
                                            if i == 0 and isinstance(res_ai, dict): st.info(res_ai.get("TWIN_Q", "ìƒì„± ì¤‘..."))
                                            else: st.caption("ë‚´ìš© ì—†ìŒ")
                        else:
                            st.info("ê´€ë ¨ ê¸°ì¶œ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")

                with ai_tab2:
                    for msg in st.session_state.chat_history:
                        with st.chat_message(msg["role"]): st.markdown(msg["content"])
                    if q := st.chat_input("ì§ˆë¬¸ ì…ë ¥..."):
                        if st.session_state.api_key_ok:
                            st.session_state.chat_history.append({"role":"user", "content":q})
                            with st.chat_message("user"): st.markdown(q)
                            with st.chat_message("assistant"):
                                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                                    prmt = build_chat_prompt(st.session_state.chat_history, p_text, rel, q)
                                    ans, _ = generate_with_fallback(prmt, st.session_state.text_models)
                                    st.markdown(ans)
                                    st.session_state.chat_history.append({"role":"assistant", "content":ans})

# --- TAB 3: ê°•ì˜ ë…¹ìŒ/ë¶„ì„ (Restored) ---
with tab3:
    with st.container(border=True):
        st.markdown("#### ğŸ™ï¸ ê°•ì˜ ë…¹ìŒ/ë¶„ì„")
        c_in, c_out = st.columns(2)
        
        with c_in:
            sub_t3 = st.selectbox("ê³¼ëª©", ["ì „ì²´"] + sorted({x.get("subject", "") for x in st.session_state.db}), key="t3_s")
            t3_mode = st.radio("ì…ë ¥ ë°©ì‹", ["ğŸ¤ ì§ì ‘ ë…¹ìŒ", "ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ / í…ìŠ¤íŠ¸"], horizontal=True, label_visibility="collapsed")
            target_text = ""
            
            if t3_mode == "ğŸ¤ ì§ì ‘ ë…¹ìŒ":
                audio_value = st.audio_input("ë…¹ìŒ ì‹œì‘")
                if audio_value and st.button("ë¶„ì„ ì‹¤í–‰", type="primary", key="btn_mic"):
                    if not st.session_state.api_key_ok: st.error("API Key í•„ìš”")
                    else:
                        with st.spinner("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                            transcript = transcribe_audio_gemini(audio_value.getvalue(), st.session_state.api_key)
                            if transcript:
                                st.session_state.transcribed_text = transcript
                                target_text = transcript
            else:
                f_txt = st.file_uploader("ì „ì‚¬ íŒŒì¼(.txt)", type="txt", key="t3_f")
                area_txt = st.text_area("ì§ì ‘ ì…ë ¥", height=150, placeholder="ê°•ì˜ ë‚´ìš©ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”...")
                if st.button("ë¶„ì„ ì‹¤í–‰", type="primary", key="btn_txt"):
                    target_text = (f_txt.getvalue().decode() if f_txt else area_txt).strip()
            
            if target_text:
                if not st.session_state.api_key_ok: st.error("API Key í•„ìš”")
                else:
                    with st.spinner("ì¡±ë³´ ë§¤ì¹­ ë° ë¶„ì„ ì¤‘..."):
                        sdb = filter_db_by_subject(sub_t3, st.session_state.db)
                        # Chunking & Retrieval
                        chunks = chunk_transcript(target_text)[:10] # Limit to 10 chunks for speed
                        rels = [find_relevant_jokbo(c, sdb, top_k=3) for c in chunks]
                        
                        # Generate RAG Summary
                        pmt = build_transcript_prompt(chunks, rels, sub_t3)
                        res, _ = generate_with_fallback(pmt, st.session_state.text_models)
                        st.session_state.tr_res = res
                    st.success("ë¶„ì„ ì™„ë£Œ!")

        with c_out:
            st.caption("ë¶„ì„ ê²°ê³¼")
            if "tr_res" in st.session_state and st.session_state.tr_res:
                with st.container(border=True):
                    st.markdown("##### ğŸ“ ì¡±ë³´ ê¸°ë°˜ ìš”ì•½ ë…¸íŠ¸")
                    st.info(st.session_state.tr_res)
                
                if st.session_state.transcribed_text:
                    with st.expander("ğŸ—£ï¸ ë³€í™˜ëœ ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ ë³´ê¸°"):
                        st.text(st.session_state.transcribed_text)
            else:
                st.markdown("""<div style="height: 300px; background: #f9f9f9; border-radius: 10px; display: flex; align-items: center; justify-content: center; color: #aaa;">ì™¼ìª½ì—ì„œ ë…¹ìŒ ë˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.</div>""", unsafe_allow_html=True)
