import os
import time
import tempfile

import streamlit as st
import google.generativeai as genai
import fitz  # PyMuPDF
from PIL import Image
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# ==========================================
# 0. íŽ˜ì´ì§€ ì„¤ì •
# ==========================================
st.set_page_config(page_title="Med-Study OS Final", layout="wide", page_icon="ðŸ©º")

# (ì„ íƒ) ë””ë²„ê¹…ìš©: SDK ë²„ì „ í‘œì‹œ
st.write(f"í˜„ìž¬ google-generativeai ë²„ì „: {getattr(genai, '__version__', 'unknown')}")

# ==========================================
# 1. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ==========================================
if "db" not in st.session_state:
    st.session_state.db = []

if "lecture_doc" not in st.session_state:
    st.session_state.lecture_doc = None

if "lecture_filename" not in st.session_state:
    st.session_state.lecture_filename = None

if "current_page" not in st.session_state:
    st.session_state.current_page = 0

if "text_models" not in st.session_state:
    st.session_state.text_models = []

if "best_text_model" not in st.session_state:
    st.session_state.best_text_model = None

if "api_key_ok" not in st.session_state:
    st.session_state.api_key_ok = False


# ==========================================
# 2. í•µì‹¬ í•¨ìˆ˜
# ==========================================
def extract_text_from_pdf(file) -> list[dict]:
    """PDFë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (fitz ì‚¬ìš©)"""
    doc = fitz.open(stream=file.read(), filetype="pdf")
    pages_content = []
    for page_num, page in enumerate(doc):
        text = page.get_text() or ""
        if text.strip():
            pages_content.append(
                {"page": page_num + 1, "text": text, "source": file.name}
            )
    return pages_content


def get_embedding(text: str):
    """ìž„ë² ë”© ìƒì„± (ê°€ëŠ¥í•˜ë©´ text-embedding-004, ì•„ë‹ˆë©´ embedding-001)"""
    text = (text or "").strip()
    if not text:
        return []

    # ë°ëª¨ ì•ˆì •ì„±: ê³¼ë„í•œ ê¸¸ì´ ì»·
    text = text[:12000]

    try:
        return genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="retrieval_document",
        )["embedding"]
    except Exception:
        try:
            return genai.embed_content(
                model="models/embedding-001",
                content=text,
                task_type="retrieval_document",
            )["embedding"]
        except Exception:
            return []


def find_relevant_jokbo(query_text: str, db: list[dict], top_k: int = 3):
    """ìœ ì‚¬ë„ ê²€ìƒ‰"""
    if not db:
        return []

    query_emb = get_embedding(query_text)
    if not query_emb:
        return []

    valid_items = [item for item in db if item.get("embedding")]
    if not valid_items:
        return []

    db_embs = [item["embedding"] for item in valid_items]
    sims = cosine_similarity([query_emb], db_embs)[0]
    top_idxs = np.argsort(sims)[::-1][:top_k]

    return [{"score": float(sims[i]), "content": valid_items[i]} for i in top_idxs]


@st.cache_data(show_spinner=False)
def list_text_models(api_key: str):
    """í˜„ìž¬ í‚¤ì—ì„œ generateContent ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜´"""
    genai.configure(api_key=api_key)
    models = genai.list_models()

    out = []
    for m in models:
        methods = getattr(m, "supported_generation_methods", []) or []
        if "generateContent" in methods:
            out.append(m.name)  # ë³´í†µ "models/..." í˜•íƒœ
    return out


def pick_best_text_model(model_names: list[str]):
    """flash ê³„ì—´ ìš°ì„  ì„ íƒ"""
    if not model_names:
        return None
    flash = [m for m in model_names if "flash" in m.lower()]
    return flash[0] if flash else model_names[0]


def generate_with_fallback(prompt: str, model_names: list[str]):
    """ëª¨ë¸ í›„ë³´ë¥¼ ìˆœì„œëŒ€ë¡œ ì‹œë„í•´ì„œ ì„±ê³µí•˜ë©´ ë°˜í™˜"""
    last_err = None
    for name in model_names:
        if not name:
            continue
        try:
            model = genai.GenerativeModel(name)
            res = model.generate_content(prompt)
            text = getattr(res, "text", None)
            if text:
                return text, name
            return str(res), name
        except Exception as e:
            last_err = e
            continue
    raise last_err


# ==========================================
# 3. ì‚¬ì´ë“œë°”
# ==========================================
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì •")

    api_key = st.text_input("Gemini API Key", type="password")

    if api_key:
        try:
            genai.configure(api_key=api_key)
            available_models = list_text_models(api_key)

            if not available_models:
                st.session_state.api_key_ok = False
                st.error("generateContent ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. (í‚¤/í”„ë¡œì íŠ¸ ê¶Œí•œ ë¬¸ì œ ê°€ëŠ¥)")
            else:
                st.session_state.api_key_ok = True
                st.session_state.text_models = available_models
                st.session_state.best_text_model = pick_best_text_model(available_models)
                st.caption(f"âœ… í…ìŠ¤íŠ¸ ëª¨ë¸ ìžë™ ì„ íƒ: {st.session_state.best_text_model}")

        except Exception as e:
            st.session_state.api_key_ok = False
            st.error(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    st.divider()
    st.write(f"ðŸ“š í•™ìŠµëœ ì¡±ë³´: {len(st.session_state.db)} íŽ˜ì´ì§€")

    if st.button("ì´ˆê¸°í™”"):
        st.session_state.db = []
        st.rerun()


# ==========================================
# 4. ë©”ì¸ UI
# ==========================================
tab1, tab2, tab3 = st.tabs(["ðŸ“‚ ì¡±ë³´ í•™ìŠµ", "ðŸ“– ê°•ì˜ ê³µë¶€", "âŒ¨ï¸ ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¶„ì„"])


# --------------------------
# TAB 1: ì¡±ë³´ í•™ìŠµ
# --------------------------
with tab1:
    st.header("1. ì¡±ë³´ ì—…ë¡œë“œ")
    files = st.file_uploader("ì¡±ë³´ PDF", accept_multiple_files=True, type="pdf")

    col_a, col_b = st.columns([1, 2])
    with col_a:
        max_pages_per_file = st.number_input(
            "íŒŒì¼ë‹¹ ìµœëŒ€ í•™ìŠµ íŽ˜ì´ì§€(ë°ëª¨ìš©)",
            min_value=1,
            max_value=200,
            value=30,
            step=1,
        )
    with col_b:
        st.caption("ë°ëª¨ ì•ˆì •ì„±ì„ ìœ„í•´ íŒŒì¼ë‹¹ í•™ìŠµ íŽ˜ì´ì§€ ìˆ˜ë¥¼ ì œí•œí•˜ëŠ” ê±¸ ì¶”ì²œí•´.")

    if st.button("í•™ìŠµ ì‹œìž‘ ðŸš€") and files:
        if not api_key:
            st.error("API Keyë¥¼ ìž…ë ¥í•˜ì„¸ìš”.")
            st.stop()

        bar = st.progress(0)
        status = st.empty()
        new_db = []
        total_files = len(files)

        for i, f in enumerate(files):
            status.text(f"ðŸ“– íŒŒì¼ ì½ëŠ” ì¤‘: {f.name}...")
            pages = extract_text_from_pdf(f)

            # ë°ëª¨ìš© íŽ˜ì´ì§€ ì œí•œ
            pages = pages[: int(max_pages_per_file)]

            for j, p in enumerate(pages):
                status.text(f"ðŸ§  ìž„ë² ë”© ì¤‘: {f.name} ({j+1}/{len(pages)} íŽ˜ì´ì§€)...")
                emb = get_embedding(p["text"])
                if emb:
                    p["embedding"] = emb
                    new_db.append(p)

                # ì†ë„ ì œí•œ ì™„í™”(429 ë°©ì§€)
                time.sleep(0.8)

            bar.progress((i + 1) / total_files)

        st.session_state.db.extend(new_db)
        status.text("âœ… í•™ìŠµ ì™„ë£Œ!")
        st.success(f"{len(new_db)} íŽ˜ì´ì§€ í•™ìŠµ ì™„ë£Œ!")


# --------------------------
# TAB 2: ê°•ì˜ ë·°ì–´ & AI
# --------------------------
with tab2:
    st.header("2. ê°•ì˜ ë·°ì–´ & AI")
    lec_file = st.file_uploader("ê°•ì˜ë¡ PDF", type="pdf", key="lec")

    if lec_file:
        # ìƒˆ íŒŒì¼ì´ë©´ ë¬¸ì„œ ìƒˆë¡œ ì—´ê¸°
        if (
            st.session_state.lecture_doc is None
            or st.session_state.lecture_filename != lec_file.name
        ):
            st.session_state.lecture_doc = fitz.open(
                stream=lec_file.read(), filetype="pdf"
            )
            st.session_state.lecture_filename = lec_file.name
            st.session_state.current_page = 0

        doc = st.session_state.lecture_doc
        col_view, col_ai = st.columns([6, 4])

        with col_view:
            c1, c2, c3 = st.columns([1, 2, 1])

            if c1.button("â—€"):
                if st.session_state.current_page > 0:
                    st.session_state.current_page -= 1

            c2.markdown(
                f"<center>{st.session_state.current_page + 1} / {len(doc)}</center>",
                unsafe_allow_html=True,
            )

            if c3.button("â–¶"):
                if st.session_state.current_page < len(doc) - 1:
                    st.session_state.current_page += 1

            page = doc.load_page(st.session_state.current_page)
            pix = page.get_pixmap(dpi=150)
            st.image(
                Image.frombytes("RGB", [pix.width, pix.height], pix.samples),
                use_container_width=True,
            )
            curr_text = (page.get_text() or "").strip()

        with col_ai:
            st.subheader("AI ë¶„ì„")
            if st.button("ë¶„ì„í•˜ê¸° âš¡", key="analyze_page"):
                if not api_key or not st.session_state.api_key_ok:
                    st.error("API Keyê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤(ì‚¬ì´ë“œë°” í™•ì¸).")
                    st.stop()

                if not st.session_state.db:
                    st.error("ì¡±ë³´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ì¡±ë³´ í•™ìŠµ' íƒ­ì—ì„œ í•™ìŠµí•˜ì„¸ìš”.")
                    st.stop()

                if not curr_text:
                    st.warning("í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” íŽ˜ì´ì§€ìž…ë‹ˆë‹¤(ìŠ¤ìº”ë³¸ ì´ë¯¸ì§€ì¼ ìˆ˜ ìžˆìŒ).")
                    st.stop()

                with st.spinner("AIê°€ ë¶„ì„ ì¤‘ìž…ë‹ˆë‹¤..."):
                    try:
                        related = find_relevant_jokbo(curr_text, st.session_state.db, top_k=3)
                        ctx_str = "\n".join(
                            [f"- (p{item['content']['page']}) {item['content']['text'][:200]}" for item in related]
                        )

                        prompt = f"""
ë„ˆëŠ” ì˜ëŒ€ ì‹œí—˜ ëŒ€ë¹„ ì¡°êµì•¼.

[ê°•ì˜ íŽ˜ì´ì§€ í…ìŠ¤íŠ¸]
{curr_text}

[ê´€ë ¨ ì¡±ë³´ ë°œì·Œ]
{ctx_str if ctx_str.strip() else "(ê´€ë ¨ ì¡±ë³´ë¥¼ ì°¾ì§€ ëª»í•¨)"}

ë¯¸ì…˜:
1) ì´ íŽ˜ì´ì§€ í•µì‹¬ ê°œë… 5ê°œë¥¼ ë½‘ì•„ì¤˜.
2) ì¡±ë³´ì™€ì˜ ì—°ê²°ì ì„ 'êµ¬ì²´ì ìœ¼ë¡œ' ë§í•´ì¤˜(ê°€ëŠ¥í•˜ë©´ íŽ˜ì´ì§€ ë²ˆí˜¸ ì–¸ê¸‰).
3) ì˜ˆìƒ ë¬¸ì œ 3ê°œ(ê°ê´€ì‹ 2 + ë‹¨ë‹µí˜• 1) ë§Œë“¤ì–´ì¤˜.
4) ê° ë¬¸ì œì˜ ì •ë‹µ/í•´ì„¤ê¹Œì§€ ì¨ì¤˜.
""".strip()

                        model_list = st.session_state.text_models or []
                        fallback_candidates = model_list + [
                            "models/gemini-1.5-flash-latest",
                            "models/gemini-1.5-pro-latest",
                        ]

                        text, used = generate_with_fallback(prompt, fallback_candidates)
                        st.caption(f"ì‚¬ìš© ëª¨ë¸: {used}")
                        st.markdown(text)

                    except Exception as e:
                        msg = str(e)
                        if "429" in msg:
                            st.error("âš ï¸ ì‚¬ìš©ëŸ‰ì´ ë§ŽìŠµë‹ˆë‹¤. ìž ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                        else:
                            st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")


# --------------------------
# TAB 3: ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¶„ì„ (ë§ˆì´í¬ ì œê±°)
# --------------------------
with tab3:
    st.header("3. ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¶„ì„ (ì•ˆì • ë²„ì „)")
    st.info("ê°•ì˜ ì¤‘ ì¤‘ìš”í•˜ë‹¤ê³  ëŠë‚€ êµìˆ˜ë‹˜ ë§ì„ ê·¸ëŒ€ë¡œ ìž…ë ¥í•˜ë©´, ì¡±ë³´ì™€ ì—°ê²°í•´ ë¶„ì„í•©ë‹ˆë‹¤.")

    if not api_key or not st.session_state.api_key_ok:
        st.warning("ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ API Keyë¥¼ ìž…ë ¥/í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    if not st.session_state.db:
        st.warning("ë¨¼ì € 'ì¡±ë³´ í•™ìŠµ' íƒ­ì—ì„œ ì¡±ë³´ë¥¼ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        st.stop()

    user_text = st.text_area(
        "êµìˆ˜ë‹˜ ë§ì”€ / ì¤‘ìš”í•œ ì„¤ëª…ì„ ê·¸ëŒ€ë¡œ ìž…ë ¥í•˜ì„¸ìš”",
        height=160,
        placeholder="ì˜ˆ) ì´ ë¶€ë¶„ì€ êµê³¼ì„œì—ëŠ” ì—†ì§€ë§Œ ì‹œí—˜ì— ë‚˜ì˜¬ ìˆ˜ ìžˆë‹¤...",
    )

    if st.button("ì¡±ë³´ ë§¤ì¹­ & ì¸ì‚¬ì´íŠ¸ ìƒì„±", key="live_analyze"):
        query = (user_text or "").strip()
        if not query:
            st.error("ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ìž…ë ¥í•˜ì„¸ìš”.")
            st.stop()

        with st.spinner("ì¡±ë³´ ë’¤ì§€ëŠ” ì¤‘..."):
            related = find_relevant_jokbo(query, st.session_state.db, top_k=3)

        st.subheader("ðŸ”Ž ê´€ë ¨ ì¡±ë³´")
        context_str = ""
        if not related:
            st.write("ê´€ë ¨ëœ ì¡±ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ìƒˆë¡œìš´ ê°•ì¡°ì ì¼ ìˆ˜ ìžˆìŒ)")
        else:
            for idx, item in enumerate(related):
                with st.expander(f"ê´€ë ¨ ì¡±ë³´ #{idx+1} (ìœ ì‚¬ë„ {item['score']:.3f})"):
                    st.write(f"íŽ˜ì´ì§€ {item['content']['page']}")
                    st.write(item["content"]["text"])
                context_str += f"- (íŽ˜ì´ì§€ {item['content']['page']}) {item['content']['text']}\n"

        st.divider()
        st.subheader("ðŸ©º Med-Study AI ë¶„ì„")

        final_prompt = f"""
ìƒí™©: ì˜ëŒ€ ê°•ì˜ ì¤‘ ì‹¤ì‹œê°„ ì‹œí—˜ ëŒ€ë¹„ ì •ë¦¬.

êµìˆ˜ë‹˜ ë§ì”€:
{query}

ê´€ë ¨ ì¡±ë³´ ë°œì·Œ:
{context_str if context_str else "(ê´€ë ¨ ì¡±ë³´ ì—†ìŒ)"}

ë¯¸ì…˜:
1. êµìˆ˜ë‹˜ ë§ì”€ì´ ì¡±ë³´ì˜ ì–´ë–¤ ë¶€ë¶„ê³¼ ì—°ê²°ë˜ëŠ”ì§€ ë¶„ì„.
2. ì‹œí—˜ì— ë‚˜ì˜¬ ê°€ëŠ¥ì„±ì´ ë†’ì€ í¬ì¸íŠ¸ë¥¼ ëª…í™•ížˆ ì§€ì .
3. ì˜ˆìƒ ë¬¸ì œ 3ê°œ + ì •ë‹µ/í•´ì„¤.
4. í•œëˆˆì— ì™¸ìš¸ ìˆ˜ ìžˆëŠ” ì•”ê¸° í¬ì¸íŠ¸ 5ì¤„.
""".strip()

        model_list = st.session_state.text_models or []
        fallback_candidates = model_list + [
            "models/gemini-1.5-flash-latest",
            "models/gemini-1.5-pro-latest",
        ]

        with st.spinner("AI ë¶„ì„ ì¤‘..."):
            try:
                text, used = generate_with_fallback(final_prompt, fallback_candidates)
                st.caption(f"ì‚¬ìš© ëª¨ë¸: {used}")
                st.markdown(text)
            except Exception as e:
                msg = str(e)
                if "429" in msg:
                    st.error("âš ï¸ ì‚¬ìš©ëŸ‰ì´ ë§ŽìŠµë‹ˆë‹¤. ìž ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                else:
                    st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")
